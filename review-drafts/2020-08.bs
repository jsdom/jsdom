<pre class=metadata>
Group: WHATWG
Date: 2020-08-17
H1: Streams
Shortname: streams
Text Macro: TWITTER streamsstandard
Abstract: This specification provides APIs for creating, composing, and consuming streams of data
Abstract: that map efficiently to low-level I/O primitives.
Translation: ja https://triple-underscore.github.io/Streams-ja.html
!Demos: <a href="https://streams.spec.whatwg.org/demos/">streams.spec.whatwg.org/demos</a>
Indent: 1
Markup Shorthands: markdown yes
</pre>

<pre class=link-defaults>
spec:webidl; type:dfn; text:resolve
spec:webidl; type:dfn; text:new
spec:infra; type:dfn; text:list
spec:html; type:dfn; text:entangle
spec:html; type:dfn; text:message port post message steps
spec:html; type:dfn; text:port message queue
</pre>

<pre class="anchors">
urlPrefix: https://tc39.es/ecma262/; spec: ECMASCRIPT
 type: constructor
  text: %Uint8Array%; url: #sec-typedarray-objects
  text: %DataView%; url: #sec-dataview-constructor
  text: %ArrayBuffer%; url: #sec-arraybuffer-constructor
 type: interface
  text: ArrayBuffer; url: #sec-arraybuffer-objects
  text: DataView; url: #sec-dataview-objects
  text: Number; url: #sec-ecmascript-language-types-number-type
  text: Uint8Array; url: #sec-typedarray-objects
  text: %Object.prototype%; url: #sec-properties-of-the-object-prototype-object
 type: dfn
  text: abstract operation; url: #sec-algorithm-conventions-abstract-operations
  text: completion record; url: #sec-completion-record-specification-type
  text: internal slot; url: #sec-object-internal-methods-and-internal-slots
  text: realm; url: #sec-code-realms
  text: the current Realm; url: #current-realm
  text: the typed array constructors table; url: #table-49
  text: typed array; url: #sec-typedarray-objects
  text: Number type; url: #sec-ecmascript-language-types-number-type
 type: abstract-op
  text: CloneArrayBuffer; url: #sec-clonearraybuffer
  text: CopyDataBlockBytes; url: #sec-copydatablockbytes
  text: CreateArrayFromList; url: #sec-createarrayfromlist
  text: CreateBuiltinFunction; url: #sec-createbuiltinfunction
  text: CreateDataProperty; url: #sec-createdataproperty
  text: Construct; url: #sec-construct
  text: DetachArrayBuffer; url: #sec-detacharraybuffer
  text: Get; url: #sec-get-o-p
  text: GetV; url: #sec-getv
  text: IsDetachedBuffer; url: #sec-isdetachedbuffer
  text: IsInteger; url: #sec-isinteger
  text: OrdinaryObjectCreate; url: #sec-ordinaryobjectcreate
  text: SetFunctionLength; url: #sec-setfunctionlength
  text: SetFunctionName; url: #sec-setfunctionname
  text: Type; url: #sec-ecmascript-data-types-and-values
 text: TypeError; url: #sec-native-error-types-used-in-this-standard-typeerror; type: exception
 text: map; url: #sec-array.prototype.map; type: method; for: Array.prototype
</pre>

<style>
  .algorithm + .algorithm { margin-top: 3em; }
</style>

<h2 id="intro">Introduction</h2>

<div class="non-normative">

<em>This section is non-normative.</em>

Large swathes of the web platform are built on streaming data: that is, data that is created,
processed, and consumed in an incremental fashion, without ever reading all of it into memory. The
Streams Standard provides a common set of APIs for creating and interfacing with such streaming
data, embodied in [=readable streams=], [=writable streams=], and [=transform streams=].

These APIs have been designed to efficiently map to low-level I/O primitives, including
specializations for byte streams where appropriate. They allow easy composition of multiple streams
into [=pipe chains=], or can be used directly via [=/readers=] and [=writers=]. Finally, they are
designed to automatically provide [=backpressure=] and queuing.

This standard provides the base stream primitives which other parts of the web platform can use to
expose their streaming data. For example, [[FETCH]] exposes {{Response}} bodies as
{{ReadableStream}} instances. More generally, the platform is full of streaming abstractions waiting
to be expressed as streams: multimedia streams, file streams, inter-global communication, and more
benefit from being able to process data incrementally instead of buffering it all into memory and
processing it in one go. By providing the foundation for these streams to be exposed to developers,
the Streams Standard enables use cases like:

* Video effects: piping a readable video stream through a transform stream that applies effects in
  real time.
* Decompression: piping a file stream through a transform stream that selectively decompresses files
  from a <kbd>.tgz</kbd> archive, turning them into <{img}> elements as the user scrolls through an
  image gallery.
* Image decoding: piping an HTTP response stream through a transform stream that decodes bytes into
  bitmap data, and then through another transform that translates bitmaps into PNGs. If installed
  inside the {{ServiceWorkerGlobalScope/fetch}} hook of a service worker, this would allow
  developers to transparently polyfill new image formats. [[SERVICE-WORKERS]]

Web developers can also use the APIs described here to create their own streams, with the same APIs
as those provided by the platform. Other developers can then transparently compose platform-provided
streams with those supplied by libraries. In this way, the APIs described here provide unifying
abstraction for all streams, encouraging an ecosystem to grow around these shared and composable
interfaces.

</div>

<h2 id="model">Model</h2>

A <dfn export>chunk</dfn> is a single piece of data that is written to or read from a stream. It can
be of any type; streams can even contain chunks of different types. A chunk will often not be the
most atomic unit of data for a given stream; for example a byte stream might contain chunks
consisting of 16 KiB {{Uint8Array}}s, instead of single bytes.

<h3 id="rs-model">Readable streams</h3>

A <dfn export>readable stream</dfn> represents a source of data, from which you can read. In other
words, data comes
<em>out</em> of a readable stream. Concretely, a readable stream is an instance of the
{{ReadableStream}} class.

Although a readable stream can be created with arbitrary behavior, most readable streams wrap a
lower-level I/O source, called the <dfn>underlying source</dfn>. There are two types of underlying
source: push sources and pull sources.

<dfn lt="push source">Push sources</dfn> push data at you, whether or not you are listening for it.
They may also provide a mechanism for pausing and resuming the flow of data. An example push source
is a TCP socket, where data is constantly being pushed from the OS level, at a rate that can be
controlled by changing the TCP window size.

<dfn lt="pull source">Pull sources</dfn> require you to request data from them. The data may be
available synchronously, e.g. if it is held by the operating system's in-memory buffers, or
asynchronously, e.g. if it has to be read from disk. An example pull source is a file handle, where
you seek to specific locations and read specific amounts.

Readable streams are designed to wrap both types of sources behind a single, unified interface. For
web developer–created streams, the implementation details of a source are provided by <a
href="#underlying-source-api">an object with certain methods and properties</a> that is passed to
the {{ReadableStream()}} constructor.

[=Chunks=] are enqueued into the stream by the stream's [=underlying source=]. They can then be read
one at a time via the stream's public interface, in particular by using a [=readable stream reader=]
acquired using the stream's {{ReadableStream/getReader()}} method.

Code that reads from a readable stream using its public interface is known as a <dfn>consumer</dfn>.

Consumers also have the ability to <dfn lt="cancel a readable stream">cancel</dfn> a readable
stream, using its {{ReadableStream/cancel()}} method. This indicates that the consumer has lost
interest in the stream, and will immediately close the stream, throw away any queued [=chunks=], and
execute any cancellation mechanism of the [=underlying source=].

Consumers can also <dfn lt="tee a readable stream">tee</dfn> a readable stream using its
{{ReadableStream/tee()}} method. This will [=locked to a reader|lock=] the stream, making it
no longer directly usable; however, it will create two new streams, called <dfn lt="branches of a
readable stream tee">branches</dfn>, which can be consumed independently.

For streams representing bytes, an extended version of the [=readable stream=] is provided to handle
bytes efficiently, in particular by minimizing copies. The [=underlying source=] for such a readable
stream is called an <dfn>underlying byte source</dfn>. A readable stream whose underlying source is
an underlying byte source is sometimes called a <dfn>readable byte stream</dfn>. Consumers of a
readable byte stream can acquire a [=BYOB reader=] using the stream's {{ReadableStream/getReader()}}
method.

<h3 id="ws-model">Writable streams</h3>

A <dfn export>writable stream</dfn> represents a destination for data, into which you can write. In
other words, data goes <em>in</em> to a writable stream. Concretely, a writable stream is an
instance of the {{WritableStream}} class.

Analogously to readable streams, most writable streams wrap a lower-level I/O sink, called the
<dfn>underlying sink</dfn>. Writable streams work to abstract away some of the complexity of the
underlying sink, by queuing subsequent writes and only delivering them to the underlying sink one by
one.

[=Chunks=] are written to the stream via its public interface, and are passed one at a time to the
stream's [=underlying sink=]. For web developer-created streams, the implementation details of the
sink are provided by <a href="#underlying-sink-api">an object with certain methods</a> that is
passed to the {{WritableStream()}} constructor.

Code that writes into a writable stream using its public interface is known as a
<dfn>producer</dfn>.

Producers also have the ability to <dfn lt="abort a writable stream">abort</dfn> a writable stream,
using its {{WritableStream/abort()}} method. This indicates that the producer believes something has
gone wrong, and that future writes should be discontinued. It puts the stream in an errored state,
even without a signal from the [=underlying sink=], and it discards all writes in the stream's
[=internal queue=].

<h3 id="ts-model">Transform streams</h3>

A <dfn export>transform stream</dfn> consists of a pair of streams: a [=writable stream=], known as
its <dfn export>writable side</dfn>, and a [=readable stream=], known as its <dfn export>readable
side</dfn>. In a manner specific to the transform stream in question, writes to the writable side
result in new data being made available for reading from the readable side.

Concretely, any object with a <code>writable</code> property and a <code>readable</code> property
can serve as a transform stream. However, the standard {{TransformStream}} class makes it much
easier to create such a pair that is properly entangled. It wraps a <dfn>transformer</dfn>, which
defines algorithms for the specific transformation to be performed. For web developer–created
streams, the implementation details of a transformer are provided by <a href="#transformer-api">an
object with certain methods and properties</a> that is passed to the {{TransformStream()}}
constructor.

An <dfn export>identity transform stream</dfn> is a type of transform stream which forwards all
[=chunks=] written to its [=writable side=] to its [=readable side=], without any changes. This can
be useful in <a href="#example-transform-identity">a variety of scenarios</a>. By default, the
{{TransformStream}} constructor will create an identity transform stream, when no
{{Transformer/transform|transform()}} method is present on the [=transformer=] object.

Some examples of potential transform streams include:

* A GZIP compressor, to which uncompressed bytes are written and from which compressed bytes are
  read;
* A video decoder, to which encoded bytes are written and from which uncompressed video frames are
  read;
* A text decoder, to which bytes are written and from which strings are read;
* A CSV-to-JSON converter, to which strings representing lines of a CSV file are written and from
  which corresponding JavaScript objects are read.

<h3 id="pipe-chains">Pipe chains and backpressure</h3>

Streams are primarily used by <dfn>piping</dfn> them to each other. A readable stream can be piped
directly to a writable stream, using its {{ReadableStream/pipeTo()}} method, or it can be piped
through one or more transform streams first, using its {{ReadableStream/pipeThrough()}} method.

A set of streams piped together in this way is referred to as a <dfn>pipe chain</dfn>. In a pipe
chain, the <dfn>original source</dfn> is the [=underlying source=] of the first readable stream in
the chain; the <dfn>ultimate sink</dfn> is the [=underlying sink=] of the final writable stream in
the chain.

Once a pipe chain is constructed, it will propagate signals regarding how fast [=chunks=] should
flow through it. If any step in the chain cannot yet accept chunks, it propagates a signal backwards
through the pipe chain, until eventually the original source is told to stop producing chunks so
fast. This process of normalizing flow from the original source according to how fast the chain can
process chunks is called <dfn>backpressure</dfn>.

Concretely, the [=original source=] is given the
{{ReadableStreamDefaultController/desiredSize|controller.desiredSize}} (or
{{ReadableByteStreamController/desiredSize|byteController.desiredSize}}) value, and can then adjust
its rate of data flow accordingly. This value is derived from the
{{WritableStreamDefaultWriter/desiredSize|writer.desiredSize}} corresponding to the [=ultimate
sink=], which gets updated as the ultimate sink finishes writing [=chunks=]. The
{{ReadableStream/pipeTo()}} method used to construct the chain automatically ensures this
information propagates back through the [=pipe chain=].

When [=tee a readable stream|teeing=] a readable stream, the [=backpressure=] signals from its two
[=branches of a readable stream tee|branches=] will aggregate, such that if neither branch is read
from, a backpressure signal will be sent to the [=underlying source=] of the original stream.

Piping [=locks=] the readable and writable streams, preventing them from being manipulated for the
duration of the pipe operation. This allows the implementation to perform important optimizations,
such as directly shuttling data from the underlying source to the underlying sink while bypassing
many of the intermediate queues.

<h3 id="queuing-strategies">Internal queues and queuing strategies</h3>

Both readable and writable streams maintain <dfn>internal queues</dfn>, which they use for similar
purposes. In the case of a readable stream, the internal queue contains [=chunks=] that have been
enqueued by the [=underlying source=], but not yet read by the consumer. In the case of a writable
stream, the internal queue contains [=chunks=] which have been written to the stream by the
producer, but not yet processed and acknowledged by the [=underlying sink=].

A <dfn>queuing strategy</dfn> is an object that determines how a stream should signal
[=backpressure=] based on the state of its [=internal queue=]. The queuing strategy assigns a size
to each [=chunk=], and compares the total size of all chunks in the queue to a specified number,
known as the <dfn>high water mark</dfn>. The resulting difference, high water mark minus total size,
is used to determine the <dfn lt="desired size to fill a stream's internal queue">desired size to
fill the stream's queue</dfn>.

For readable streams, an underlying source can use this desired size as a backpressure signal,
slowing down chunk generation so as to try to keep the desired size above or at zero. For writable
streams, a producer can behave similarly, avoiding writes that would cause the desired size to go
negative.

<a href="#qs-api">Concretely</a>, a queuing strategy for web developer–created streams is given by
any JavaScript object with a {{QueuingStrategy/highWaterMark}} property. For byte streams the
{{QueuingStrategy/highWaterMark}} always has units of bytes. For other streams the default unit is
[=chunks=], but a {{QueuingStrategy/size|size()}} function can be included in the strategy object
which returns the size for a given chunk. This permits the {{QueuingStrategy/highWaterMark}} to be
specified in arbitrary floating-point units.
<!-- TODO: https://github.com/whatwg/streams/issues/427 -->

<div class="example" id="example-simple-queuing-strategy">
 A simple example of a queuing strategy would be one that assigns a size of one to each chunk, and
 has a high water mark of three. This would mean that up to three chunks could be enqueued in a
 readable stream, or three chunks written to a writable stream, before the streams are considered to
 be applying backpressure.

 In JavaScript, such a strategy could be written manually as <code highlight="js">{ highWaterMark:
 3, size() { return 1; }}</code>, or using the built-in {{CountQueuingStrategy}} class, as <code
 highlight="js">new CountQueuingStrategy({ highWaterMark: 3 })</code>.
</div>

<h3 id="locking">Locking</h3>

A <dfn lt="reader|readable stream reader">readable stream reader</dfn>, or simply reader, is an
object that allows direct reading of [=chunks=] from a [=readable stream=]. Without a reader, a
[=consumer=] can only perform high-level operations on the readable stream: [=cancel a readable
stream|canceling=] the stream, or [=piping=] the readable stream to a writable stream. A reader is
acquired via the stream's {{ReadableStream/getReader()}} method.

A [=readable byte stream=] has the ability to vend two types of readers: <dfn>default readers</dfn>
and <dfn>BYOB readers</dfn>. BYOB ("bring your own buffer") readers allow reading into a
developer-supplied buffer, thus minimizing copies. A non-byte readable stream can only vend default
readers. Default readers are instances of the {{ReadableStreamDefaultReader}} class, while BYOB
readers are instances of {{ReadableStreamBYOBReader}}.

Similarly, a <dfn lt="writer|writable stream writer">writable stream writer</dfn>, or simply
writer, is an object that allows direct writing of [=chunks=] to a [=writable stream=]. Without a
writer, a [=producer=] can only perform the high-level operations of [=abort a writable
stream|aborting=] the stream or [=piping=] a readable stream to the writable stream. Writers are
represented by the {{WritableStreamDefaultWriter}} class.

<p class="note">Under the covers, these high-level operations actually use a reader or writer
themselves.</p>

A given readable or writable stream only has at most one reader or writer at a time. We say in this
case the stream is <dfn lt="lock|locked to a reader|locked to a writer">locked</dfn>, and that the
reader or writer is <dfn lt="active|active reader|active writer">active</dfn>. This state can be
determined using the {{ReadableStream/locked|readableStream.locked}} or
{{WritableStream/locked|writableStream.locked}} properties.

A reader or writer also has the capability to <dfn lt="release a lock|release a read lock|release a
write lock">release its lock</dfn>, which makes it no longer active, and allows further readers or
writers to be acquired. This is done via the
{{ReadableStreamDefaultReader/releaseLock()|defaultReader.releaseLock()}},
{{ReadableStreamBYOBReader/releaseLock()|byobReader.releaseLock()}}, or
{{WritableStreamDefaultWriter/releaseLock()|writer.releaseLock()}} method, as appropriate.

<h2 id="conventions">Conventions</h2>

This specification depends on the Infra Standard. [[!INFRA]]

This specification uses the [=abstract operation=] concept from the JavaScript specification for its
internal algorithms. This includes treating their return values as [=completion records=], and the
use of ! and ? prefixes for unwrapping those completion records. [[!ECMASCRIPT]]

This specification also uses the [=internal slot=] concept and notation from the JavaScript
specification. (Although, the internal slots are on Web IDL [=platform objects=] instead of on
JavaScript objects.)

<p class="note">The reasons for the usage of these foreign JavaScript specification conventions are
largely historical. We urge you to avoid following our example when writing your own web
specifications.

In this specification, all numbers are represented as double-precision 64-bit IEEE 754 floating
point values (like the JavaScript [=Number type=] or Web IDL {{unrestricted double}} type), and all
arithmetic operations performed on them must be done in the standard way for such values. This is
particularly important for the data structure described in [[#queue-with-sizes]]. [[!IEEE-754]]

<h2 id="rs">Readable streams</h2>

<h3 id="rs-intro">Using readable streams</h3>

<div class="example" id="example-basic-pipe-to">
 The simplest way to consume a readable stream is to simply [=piping|pipe=] it to a [=writable
 stream=]. This ensures that [=backpressure=] is respected, and any errors (either writing or
 reading) are propagated through the chain:

 <xmp highlight="js">
 readableStream.pipeTo(writableStream)
   .then(() => console.log("All data successfully written!"))
   .catch(e => console.error("Something went wrong!", e));
 </xmp>
</div>

<div class="example" id="example-pipe-as-chunks-receiver">
 If you simply want to be alerted of each new chunk from a readable stream, you can [=piping|pipe=]
 it to a new [=writable stream=] that you custom-create for that purpose:

 <xmp highlight="js">
 readableStream.pipeTo(new WritableStream({
   write(chunk) {
     console.log("Chunk received", chunk);
   },
   close() {
     console.log("All data successfully read!");
   },
   abort(e) {
     console.error("Something went wrong!", e);
   }
 }));
 </xmp>

 By returning promises from your {{UnderlyingSink/write|write()}} implementation, you can signal
 [=backpressure=] to the readable stream.
</div>

<div class="example" id="example-manual-read">
 Although readable streams will usually be used by piping them to a writable stream, you can also
 read them directly by acquiring a [=/reader=] and using its <code>read()</code> method to get
 successive chunks. For example, this code logs the next [=chunk=] in the stream, if available:

 <xmp highlight="js">
 const reader = readableStream.getReader();

 reader.read().then(
   ({ value, done }) => {
     if (done) {
       console.log("The stream was already closed!");
     } else {
       console.log(value);
     }
   },
   e => console.error("The stream became errored and cannot be read from!", e)
 );
 </xmp>

 This more manual method of reading a stream is mainly useful for library authors building new
 high-level operations on streams, beyond the provided ones of [=piping=] and [=tee a readable
 stream|teeing=].
</div>

<div class="example" id="example-manual-read-bytes">
 The above example showed using the readable stream's [=default reader=]. If the stream is a
 [=readable byte stream=], you can also acquire a [=BYOB reader=] for it, which allows more
 precise control over buffer allocation in order to avoid copies. For example, this code reads the
 first 1024 bytes from the stream into a single memory buffer:

 <xmp highlight="js">
 const reader = readableStream.getReader({ mode: "byob" });

 let startingAB = new ArrayBuffer(1024);
 readInto(startingAB)
   .then(buffer => console.log("The first 1024 bytes:", buffer))
   .catch(e => console.error("Something went wrong!", e));

 function readInto(buffer, offset = 0) {
   if (offset === buffer.byteLength) {
     return Promise.resolve(buffer);
   }

   const view = new Uint8Array(buffer, offset, buffer.byteLength - offset);
   return reader.read(view).then(newView => {
     return readInto(newView.buffer, offset + newView.byteLength);
   });
 }
 </xmp>

 An important thing to note here is that the final <code>buffer</code> value is different from the
 <code>startingAB</code>, but it (and all intermediate buffers) shares the same backing memory
 allocation. At each step, the buffer is <a href="#transfer-array-buffer">transferred</a> to a new
 {{ArrayBuffer}} object. The <code>newView</code> is a new {{Uint8Array}}, with that {{ArrayBuffer}}
 object as its <code>buffer</code> property, the offset that bytes were written to as its
 <code>byteOffset</code> property, and the number of bytes that were written as its
 <code>byteLength</code> property.
</div>

<h3 id="rs-class">The {{ReadableStream}} class</h3>

The {{ReadableStream}} class is a concrete instance of the general [=readable stream=] concept. It
is adaptable to any [=chunk=] type, and maintains an internal queue to keep track of data supplied
by the [=underlying source=] but not yet read by any consumer.

<h4 id="rs-class-definition">Interface definition</h4>

The Web IDL definition for the {{ReadableStream}} class is given as follows:

<xmp class="idl">
[Exposed=(Window,Worker,Worklet), Transferable]
interface ReadableStream {
  constructor(optional object underlyingSource, optional QueuingStrategy strategy = {});

  readonly attribute boolean locked;

  Promise<void> cancel(optional any reason);
  ReadableStreamReader getReader(optional ReadableStreamGetReaderOptions options = {});
  ReadableStream pipeThrough(ReadableWritablePair transform, optional StreamPipeOptions options = {});
  Promise<void> pipeTo(WritableStream destination, optional StreamPipeOptions options = {});
  sequence<ReadableStream> tee();

  async iterable<any>(optional ReadableStreamIteratorOptions options = {});
};

typedef (ReadableStreamDefaultReader or ReadableStreamBYOBReader) ReadableStreamReader;

enum ReadableStreamReaderMode { "byob" };

dictionary ReadableStreamGetReaderOptions {
  ReadableStreamReaderMode mode;
};

dictionary ReadableStreamIteratorOptions {
  boolean preventCancel = false;
};

dictionary ReadableWritablePair {
  required ReadableStream readable;
  required WritableStream writable;
};

dictionary StreamPipeOptions {
  boolean preventClose = false;
  boolean preventAbort = false;
  boolean preventCancel = false;
  AbortSignal signal;
};
</xmp>

<h4 id="rs-internal-slots">Internal slots</h4>

Instances of {{ReadableStream}} are created with the internal slots described in the following
table:

<table dfn-for="ReadableStream">
 <thead>
  <tr>
   <th>Internal Slot
   <th>Description (<em>non-normative</em>)
 <tbody>
  <tr>
   <td><dfn>\[[controller]]</dfn>
   <td class="non-normative">A {{ReadableStreamDefaultController}} or
   {{ReadableByteStreamController}} created with the ability to control the state and queue of this
   stream
  <tr>
   <td><!-- TODO(ricea): Style this as <dfn unused> when that is supported.
            See https://github.com/tabatkins/bikeshed/issues/1747 --><b>\[[detached]]</b>
   <td class="non-normative">A boolean flag set to true when the stream is transferred
  <tr>
   <td><dfn>\[[disturbed]]</dfn>
   <td class="non-normative">A boolean flag set to true when the stream has been read from or
   canceled
  <tr>
   <td><dfn>\[[reader]]</dfn>
   <td class="non-normative">A {{ReadableStreamDefaultReader}} or {{ReadableStreamBYOBReader}}
   instance, if the stream is [=locked to a reader=], or undefined if it is not
  <tr>
   <td><dfn>\[[state]]</dfn>
   <td class="non-normative">A string containing the stream's current state, used internally; one
   of "<code>readable</code>", "<code>closed</code>", or "<code>errored</code>"
  <tr>
   <td><dfn>\[[storedError]]</dfn>
   <td class="non-normative">A value indicating how the stream failed, to be given as a failure
   reason or exception when trying to operate on an errored stream
</table>

<h4 id="underlying-source-api">The underlying source API</h4>

The {{ReadableStream()}} constructor accepts as its first argument a JavaScript object representing
the [=underlying source=]. Such objects can contain any of the following properties:

<xmp class="idl">
dictionary UnderlyingSource {
  UnderlyingSourceStartCallback start;
  UnderlyingSourcePullCallback pull;
  UnderlyingSourceCancelCallback cancel;
  ReadableStreamType type;
  [EnforceRange] unsigned long long autoAllocateChunkSize;
};

typedef (ReadableStreamDefaultController or ReadableByteStreamController) ReadableStreamController;

callback UnderlyingSourceStartCallback = any (ReadableStreamController controller);
callback UnderlyingSourcePullCallback = Promise<void> (ReadableStreamController controller);
callback UnderlyingSourceCancelCallback = Promise<void> (optional any reason);

enum ReadableStreamType { "bytes" };
</xmp>

<dl>
 <dt><dfn dict-member for="UnderlyingSource" lt="start">start(<var ignore>controller</var>)</dfn></dt>
 <dd>
   <p>A function that is called immediately during creation of the {{ReadableStream}}.

   <p>Typically this is used adapt a [=push source=] by setting up relevant event listeners, as in
   the example of [[#example-rs-push-no-backpressure]], or to acquire access to a [=pull source=],
   as in [[#example-rs-pull]].

   <p>If this setup process is asynchronous, it can return a promise to signal success or failure;
   a rejected promise will error the stream. Any thrown exceptions will be re-thrown by the
   {{ReadableStream()}} constructor.

 <dt><dfn dict-member for="UnderlyingSource" lt="pull">pull(<var ignore>controller</var>)</dfn></dt>
 <dd>
  <p>A function that is called whenever the stream's [=internal queue=] of chunks becomes not full,
  i.e. whenever the queue's [=desired size to fill a stream's internal queue|desired size=] becomes
  positive. Generally, it will be called repeatedly until the queue reaches its [=high water mark=]
  (i.e. until the <a lt="desired size to fill a stream's internal queue">desired size</a> becomes
  non-positive).

  <p>For [=push sources=], this can be used to resume a paused flow, as in
  [[#example-rs-push-backpressure]]. For [=pull sources=], it is used to acquire new [=chunks=] to
  enqueue into the stream, as in [[#example-rs-pull]].

  <p>This function will not be called until {{UnderlyingSource/start|start()}} successfully
  completes. Additionally, it will only be called repeatedly if it enqueues at least one chunk or
  fulfills a BYOB request; a no-op {{UnderlyingSource/pull|pull()}} implementation will not be
  continually called.

  <p>If the function returns a promise, then it will not be called again until that promise
  fulfills. (If the promise rejects, the stream will become errored.) This is mainly used in the
  case of pull sources, where the promise returned represents the process of acquiring a new chunk.
  Throwing an exception is treated the same as returning a rejected promise.

 <dt><dfn dict-member for="UnderlyingSource" lt="cancel">cancel(<var ignore>reason</var>)</dfn></dt>
 <dd>
  <p>A function that is called whenever the [=consumer=] [=cancel a readable stream|cancels=] the
  stream, via {{ReadableStream/cancel()|stream.cancel()}} or
  {{ReadableStreamGenericReader/cancel()|reader.cancel()}}. It takes as its argument the same
  value as was passed to those methods by the consumer.

  <p>Readable streams can additionally be canceled under certain conditions during [=piping=]; see
  the definition of the {{ReadableStream/pipeTo()}} method for more details.

  <p>For all streams, this is generally used to release access to the underlying resource; see for
  example [[#example-rs-push-no-backpressure]].

  <p>If the shutdown process is asynchronous, it can return a promise to signal success or failure;
  the result will be communicated via the return value of the <code>cancel()</code>
  method that was called. Additionally, a rejected promise will error the stream, instead of
  letting it close. Throwing an exception is treated the same as returning a rejected promise.

 <dt><dfn dict-member for="UnderlyingSource" lt="type"><code>type</code></dfn> (byte streams
 only)</dt>
 <dd>
  <p>Can be set to "<dfn enum-value for="ReadableStreamType">bytes</dfn>" to signal that the
  constructed {{ReadableStream}} is a <a>readable byte stream</a>. This ensures that the resulting
  {{ReadableStream}} will successfully be able to vend [=BYOB readers=] via its
  {{ReadableStream/getReader()}} method. It also affects the |controller| argument passed to the
  {{UnderlyingSource/start|start()}} and {{UnderlyingSource/pull|pull()}} methods; see below.

  <p>For an example of how to set up a readable byte stream, including using the different
  controller interface, see [[#example-rbs-push]].

  <p>Setting any value other than "{{ReadableStreamType/bytes}}" or undefined will cause the
  {{ReadableStream()}} constructor to throw an exception.

 <dt><dfn dict-member for="UnderlyingSource"
 lt="autoAllocateChunkSize"><code>autoAllocateChunkSize</code></dfn> (byte streams only)</dt>
 <dd>
  <p>Can be set to a positive integer to cause the implementation to automatically allocate buffers
  for the underlying source code to write into. In this case, when a [=consumer=] is using a
  [=default reader=], the stream implementation will automatically allocate an {{ArrayBuffer}} of
  the given size, so that {{ReadableByteStreamController/byobRequest|controller.byobRequest}} is
  always present, as if the consumer was using a [=BYOB reader=].

  <p>This is generally used to cut down on the amount of code needed to handle consumers that use
  default readers, as can be seen by comparing [[#example-rbs-push]] without auto-allocation to
  [[#example-rbs-pull]] with auto-allocation.
</dl>

The type of the |controller| argument passed to the {{UnderlyingSource/start|start()}} and
{{UnderlyingSource/pull|pull()}} methods depends on the value of the {{UnderlyingSource/type}}
option. If {{UnderlyingSource/type}} is set to undefined (including via omission), then
|controller| will be a {{ReadableStreamDefaultController}}. If it's set to
"{{ReadableStreamType/bytes}}", then |controller| will be a {{ReadableByteStreamController}}.

<h4 id="rs-prototype">Constructor, methods, and properties</h4>

<dl class="domintro non-normative">
 <dt><code><var ignore>stream</var> = new {{ReadableStream/constructor(underlyingSource, strategy)|ReadableStream}}(<var ignore>underlyingSource</var>[, <var ignore>strategy</var>])</code>
  <dd>
   <p>Creates a new {{ReadableStream}} wrapping the provided [=underlying source=]. See
   [[#underlying-source-api]] for more details on the <var ignore>underlyingSource</var> argument.

   <p>The |strategy| argument represents the stream's [=queuing strategy=], as described in
   [[#qs-api]]. If it is not provided, the default behavior will be the same as a
   {{CountQueuingStrategy}} with a [=high water mark=] of 1.

 <dt><code><var ignore>isLocked</var> = <var ignore>stream</var>.{{ReadableStream/locked}}</code>
 <dd>
  <p>Returns whether or not the readable stream is [=locked to a reader=].

 <dt><code>await <var ignore>stream</var>.{{ReadableStream/cancel(reason)|cancel}}([ <var ignore>reason</var> ])</code>
 <dd>
  <p>[=cancel a readable stream|Cancels=] the stream, signaling a loss of interest in the stream by
  a consumer. The supplied <var ignore>reason</var> argument will be given to the underlying
  source's {{UnderlyingSource/cancel|cancel()}} method, which might or might not use it.

  <p>The returned promise will fulfill if the stream shuts down successfully, or reject if the
  underlying source signaled that there was an error doing so. Additionally, it will reject with a
  {{TypeError}} (without attempting to cancel the stream) if the stream is currently [=locked to a
  reader|locked=].

 <dt><code><var ignore>reader</var> = <var ignore>stream</var>.{{ReadableStream/getReader(options)|getReader}}()</code>
 <dd>
  <p>Creates a {{ReadableStreamDefaultReader}} and [=locked to a reader|locks=] the stream to the
  new reader. While the stream is locked, no other reader can be acquired until this one is
  [=release a read lock|released=].

  <p>This functionality is especially useful for creating abstractions that desire the ability to
  consume a stream in its entirety. By getting a reader for the stream, you can ensure nobody else
  can interleave reads with yours or cancel the stream, which would interfere with your
  abstraction.

  <dt><code><var ignore>reader</var> = <var ignore>stream</var>.{{ReadableStream/getReader(options)|getReader}}({ {{ReadableStreamGetReaderOptions/mode}}: "{{ReadableStreamReaderMode/byob}}" })</code>
  <dd>
   <p>Creates a {{ReadableStreamBYOBReader}} and [=locked to a reader|locks=] the stream to the new
   reader.

   <p>This call behaves the same way as the no-argument variant, except that it only works on
   [=readable byte streams=], i.e. streams which were constructed specifically with the ability to
   handle "bring your own buffer" reading. The returned [=BYOB reader=] provides the ability to
   directly read individual [=chunks=] from the stream via its {{ReadableStreamBYOBReader/read()}}
   method, into developer-supplied buffers, allowing more precise control over allocation.

 <dt><code><var ignore>readable</var> = <var ignore>stream</var>.{{ReadableStream/pipeThrough(transform, options)|pipeThrough}}({ {{ReadableWritablePair/writable}}, {{ReadableWritablePair/readable}} }[, { {{StreamPipeOptions/preventClose}}, {{StreamPipeOptions/preventAbort}}, {{StreamPipeOptions/preventCancel}}, {{StreamPipeOptions/signal}} }])</code></dt>
 <dd>
  <p>Provides a convenient, chainable way of [=piping=] this [=readable stream=] through a
  [=transform stream=] (or any other <code>{ writable, readable }</code> pair). It simply pipes the
  stream into the writable side of the supplied pair, and returns the readable side for further use.

  <p>Piping a stream will [=locked to a reader|lock=] it for the duration of the pipe, preventing
  any other consumer from acquiring a reader.

 <dt><code>await <var ignore>stream</var>.{{ReadableStream/pipeTo(destination, options)|pipeTo}}(<var ignore>destination</var>[, { {{StreamPipeOptions/preventClose}}, {{StreamPipeOptions/preventAbort}}, {{StreamPipeOptions/preventCancel}}, {{StreamPipeOptions/signal}} }])</code></dt>
 <dd>
  <p>[=piping|Pipes=] this [=readable stream=] to a given [=writable stream=] |destination|. The
  way in which the piping process behaves under various error conditions can be customized with a
  number of passed options. It returns a promise that fulfills when the piping process completes
  successfully, or rejects if any errors were encountered.

  Piping a stream will [=locked to a reader|lock=] it for the duration of the pipe, preventing any
  other consumer from acquiring a reader.

  Errors and closures of the source and destination streams propagate as follows:

  * An error in this source [=readable stream=] will [=abort a writable stream|abort=]
    |destination|, unless {{StreamPipeOptions/preventAbort}} is truthy. The returned promise will be
    rejected with the source's error, or with any error that occurs during aborting the destination.

  * An error in |destination| will [=cancel a readable stream|cancel=] this source [=readable
    stream=], unless {{StreamPipeOptions/preventCancel}} is truthy. The returned promise will be
    rejected with the destination's error, or with any error that occurs during canceling the
    source.

  * When this source [=readable stream=] closes, |destination| will be closed, unless
    {{StreamPipeOptions/preventClose}} is truthy. The returned promise will be fulfilled once this
    process completes, unless an error is encountered while closing the destination, in which case
    it will be rejected with that error.

  * If |destination| starts out closed or closing, this source [=readable stream=] will be [=cancel
    a readable stream|canceled=], unless {{StreamPipeOptions/preventCancel}} is true. The returned
    promise will be rejected with an error indicating piping to a closed stream failed, or with any
    error that occurs during canceling the source.

  <p>The {{StreamPipeOptions/signal}} option can be set to an {{AbortSignal}} to allow aborting an
  ongoing pipe operation via the corresponding {{AbortController}}. In this case, this source
  [=readable stream=] will be [=cancel a readable stream|canceled=], and |destination| [=abort a
  writable stream|aborted=], unless the respective options {{StreamPipeOptions/preventCancel}} or
  {{StreamPipeOptions/preventAbort}} are set.

 <dt><code>[<var ignore>branch1</var>, <var ignore>branch2</var>] = <var ignore>stream</var>.{{ReadableStream/tee()|tee}}()</code>
 <dd>
  <p>[=tee a readable stream|Tees=] this readable stream, returning a two-element array containing
  the two resulting branches as new {{ReadableStream}} instances.

  <p>Teeing a stream will [=locked to a reader|lock=] it, preventing any other consumer from
  acquiring a reader. To [=cancel a readable stream|cancel=] the stream, cancel both of the
  resulting branches; a composite cancellation reason will then be propagated to the stream's
  [=underlying source=].

  <p>Note that the [=chunks=] seen in each branch will be the same object. If the chunks are not
  immutable, this could allow interference between the two branches.
</dl>

<div algorithm>
 The <dfn id="rs-constructor" constructor for="ReadableStream" lt="ReadableStream(underlyingSource,
 strategy)">new ReadableStream(|underlyingSource|, |strategy|)</dfn> constructor steps are:

 1. If |underlyingSource| is missing, set it to null.
 1. Let |underlyingSourceDict| be |underlyingSource|, [=converted to an IDL value=] of type
    {{UnderlyingSource}}.
    <p class="note">We cannot declare the |underlyingSource| argument as having the
    {{UnderlyingSource}} type directly, because doing so would lose the reference to the original
    object. We need to retain the object so we can [=invoke=] the various methods on it.
 1. Perform ! [$InitializeReadableStream$]([=this=]).
 1. If |underlyingSourceDict|["{{UnderlyingSource/type}}"] is "{{ReadableStreamType/bytes}}":
  1. If |strategy|["{{QueuingStrategy/size}}"] [=map/exists=], throw a {{RangeError}} exception.
  1. Let |highWaterMark| be ? [$ExtractHighWaterMark$](|strategy|, 0).
  1. Perform ? [$SetUpReadableByteStreamControllerFromUnderlyingSource$]([=this=],
     |underlyingSource|, |underlyingSourceDict|, |highWaterMark|).
 1. Otherwise,
  1. Assert: |underlyingSourceDict|["{{UnderlyingSource/type}}"] does not [=map/exist=].
  1. Let |sizeAlgorithm| be ! [$ExtractSizeAlgorithm$](|strategy|).
  1. Let |highWaterMark| be ? [$ExtractHighWaterMark$](|strategy|, 1).
  1. Perform ? [$SetUpReadableStreamDefaultControllerFromUnderlyingSource$]([=this=],
     |underlyingSource|, |underlyingSourceDict|, |highWaterMark|, |sizeAlgorithm|).
</div>

<div algorithm>
 The <dfn id="rs-locked" attribute for="ReadableStream">locked</dfn> getter steps are:

 1. Return ! [$IsReadableStreamLocked$]([=this=]).
</div>

<div algorithm>
 The <dfn id="rs-cancel" method for="ReadableStream">cancel(|reason|)</dfn> method steps are:

 1. If ! [$IsReadableStreamLocked$]([=this=]) is true, return [=a promise rejected with=] a
    {{TypeError}} exception.
 1. Return ! [$ReadableStreamCancel$]([=this=], |reason|).
</div>

<div algorithm>
 The <dfn id="rs-get-reader" method for="ReadableStream">getReader(|options|)</dfn> method steps
 are:

 1. If |options|["{{ReadableStreamGetReaderOptions/mode}}"] does not [=map/exist=], return ?
    [$AcquireReadableStreamDefaultReader$]([=this=]).
 1. Assert: |options|["{{ReadableStreamGetReaderOptions/mode}}"] is
    "{{ReadableStreamReaderMode/byob}}".
 1. Return ? [$AcquireReadableStreamBYOBReader$]([=this=]).

 <div class="example" id="example-read-all-chunks">
  An example of an abstraction that might benefit from using a reader is a function like the
  following, which is designed to read an entire readable stream into memory as an array of
  [=chunks=].

  <xmp highlight="js">
  function readAllChunks(readableStream) {
    const reader = readableStream.getReader();
    const chunks = [];

    return pump();

    function pump() {
      return reader.read().then(({ value, done }) => {
        if (done) {
          return chunks;
        }

        chunks.push(value);
        return pump();
      });
    }
  }
  </xmp>

  Note how the first thing it does is obtain a reader, and from then on it uses the reader
  exclusively. This ensures that no other consumer can interfere with the stream, either by reading
  chunks or by [=cancel a readable stream|canceling=] the stream.
 </div>
</div>

<div algorithm>
 The <dfn id="rs-pipe-through" method for="ReadableStream">pipeThrough(|transform|, |options|)</dfn>
 method steps are:

 1. If ! [$IsReadableStreamLocked$]([=this=]) is true, throw a {{TypeError}} exception.
 1. If ! [$IsWritableStreamLocked$](|transform|["{{ReadableWritablePair/writable}}"]) is true, throw
    a {{TypeError}} exception.
 1. Let |signal| be |options|["{{StreamPipeOptions/signal}}"] if it [=map/exists=], or undefined
    otherwise.
 1. Let |promise| be ! [$ReadableStreamPipeTo$]([=this=],
    |transform|["{{ReadableWritablePair/writable}}"],
    |options|["{{StreamPipeOptions/preventClose}}"],
    |options|["{{StreamPipeOptions/preventAbort}}"],
    |options|["{{StreamPipeOptions/preventCancel}}"], |signal|).
 1. Set |promise|.\[[PromiseIsHandled]] to true.
 1. Return |transform|["{{ReadableWritablePair/readable}}"].

 <div class="example" id="example-pipe-chain">
  A typical example of constructing [=pipe chain=] using {{ReadableStream/pipeThrough(transform,
  options)}} would look like

  <xmp highlight="js">
  httpResponseBody
    .pipeThrough(decompressorTransform)
    .pipeThrough(ignoreNonImageFilesTransform)
    .pipeTo(mediaGallery);
  </xmp>
 </div>
</div>

<div algorithm>
 The <dfn id="rs-pipe-to" method for="ReadableStream">pipeTo(|destination|, |options|)</dfn>
 method steps are:

 1. If ! [$IsReadableStreamLocked$]([=this=]) is true, return [=a promise rejected with=] a
    {{TypeError}} exception.
 1. If ! [$IsWritableStreamLocked$](|destination|) is true, return [=a promise rejected with=] a
    {{TypeError}} exception.
 1. Let |signal| be |options|["{{StreamPipeOptions/signal}}"] if it [=map/exists=], or undefined
    otherwise.
 1. Return ! [$ReadableStreamPipeTo$]([=this=], |destination|,
    |options|["{{StreamPipeOptions/preventClose}}"],
    |options|["{{StreamPipeOptions/preventAbort}}"],
    |options|["{{StreamPipeOptions/preventCancel}}"], |signal|).

 <div class="example" id="example-pipe-abortsignal">
  An ongoing [=pipe=] operation can be stopped using an {{AbortSignal}}, as follows:

  <xmp highlight="js">
   const controller = new AbortController();
   readable.pipeTo(writable, { signal: controller.signal });

   // ... some time later ...
   controller.abort();
  </xmp>

  (The above omits error handling for the promise returned by {{ReadableStream/pipeTo()}}.
  Additionally, the impact of the {{StreamPipeOptions/preventAbort}} and
  {{StreamPipeOptions/preventCancel}} options what happens when piping is stopped are worth
  considering.)
 </div>

 <div class="example" id="example-pipe-switch-dest">
  The above technique can be used to switch the {{ReadableStream}} being piped, while writing into
  the same {{WritableStream}}:

  <xmp highlight="js">
   const controller = new AbortController();
   const pipePromise = readable1.pipeTo(writable, { preventAbort: true, signal: controller.signal });

   // ... some time later ...
   controller.abort();

   // Wait for the pipe to complete before starting a new one:
   try {
    await pipePromise;
   } catch (e) {
    // Swallow "AbortError" DOMExceptions as expected, but rethrow any unexpected failures.
    if (e.name !== "AbortError") {
     throw e;
    }
   }

   // Start the new pipe!
   readable2.pipeTo(writable);
  </xmp>
 </div>
</div>

<div algorithm>
 The <dfn id="rs-tee" method for="ReadableStream">tee()</dfn> method steps are:

 1. Return ? [$ReadableStreamTee$]([=this=], false).

 <div class="example" id="example-tee-and-pipe">
  Teeing a stream is most useful when you wish to let two independent consumers read from the stream
  in parallel, perhaps even at different speeds. For example, given a writable stream
  <code>cacheEntry</code> representing an on-disk file, and another writable stream
  <code>httpRequestBody</code> representing an upload to a remote server, you could pipe the same
  readable stream to both destinations at once:

  <xmp highlight="js">
  const [forLocal, forRemote] = readableStream.tee();

  Promise.all([
    forLocal.pipeTo(cacheEntry),
    forRemote.pipeTo(httpRequestBody)
  ])
  .then(() => console.log("Saved the stream to the cache and also uploaded it!"))
  .catch(e => console.error("Either caching or uploading failed: ", e));
  </xmp>
 </div>
</div>

<h4 id="rs-asynciterator" oldids="rs-asynciterator-prototype,
default-reader-asynciterator-prototype-internal-slots">Asynchronous iteration</h4>

<dl class="domintro">
 <dt><code>for await (const <var ignore>chunk</var> of <var ignore>stream</var>) { ... }</code>
 <dt><code>for await (const <var ignore>chunk</var> of <var ignore>stream</var>.values({ {{ReadableStreamIteratorOptions/preventCancel}}: true })) { ... }</code>
 <dd>
  <p>Asynchronously iterates over the [=chunks=] in the stream's internal queue.

  <p>Asynchronously iterating over the stream will [=locked to a reader|lock=] it, preventing any
  other consumer from acquiring a reader. The lock will be released if the async iterator's
  `return()` method is called, e.g. by `break`ing out of the loop.

  <p>By default, calling the async iterator's `return()` method will also [=cancel a readable
  stream|cancel=] the stream. To prevent this, use the stream's `values()` method, passing true for
  the {{ReadableStreamIteratorOptions/preventCancel}} option.
 </dd>
</dl>

<div algorithm="ReadableStream asynchronous iterator initialization steps" id="rs-get-iterator">
 The [=asynchronous iterator initialization steps=] for a {{ReadableStream}}, given |stream|,
 |iterator|, and |args|, are:

 1. Let |reader| be ? [$AcquireReadableStreamDefaultReader$](|stream|).
 1. Set |iterator|'s <dfn for="ReadableStream async iterator">reader</dfn> to |reader|.
 1. Let |preventCancel| be |args|[0]["{{ReadableStreamIteratorOptions/preventCancel}}"].
 1. Set |iterator|'s <dfn for="ReadableStream async iterator">prevent cancel</dfn> to
    |preventCancel|.
</div>

<div algorithm="ReadableStream get the next iteration result" id="rs-asynciterator-prototype-next">
 The [=get the next iteration result=] steps for a {{ReadableStream}}, given <var
 ignore>stream</var> and |iterator|, are:

 1. Let |reader| be |iterator|'s [=ReadableStream async iterator/reader=].
 1. If |reader|.[=ReadableStreamGenericReader/[[stream]]=] is undefined, return [=a promise rejected
    with=] a {{TypeError}}.
 1. Let |promise| be [=a new promise=].
 1. Let |readRequest| be a new [=read request=] with the following [=struct/items=]:
  : [=read request/chunk steps=], given |chunk|
  ::
   1. [=Resolve=] |promise| with |chunk|.
  : [=read request/close steps=]
  ::
   1. Perform ! [$ReadableStreamReaderGenericRelease$](|reader|).
   1. [=Resolve=] |promise| with [=end of iteration=].
  : [=read request/error steps=], given |e|
  ::
   1. Perform ! [$ReadableStreamReaderGenericRelease$](|reader|).
   1. [=Reject=] |promise| with |e|.
 1. Perform ! [$ReadableStreamDefaultReaderRead$]([=this=], |readRequest|).
 1. Return |promise|.
</div>

<div algorithm="ReadableStream asynchronous iterator return" id="rs-asynciterator-prototype-return">
 The [=asynchronous iterator return=] steps for a {{ReadableStream}}, given <var
 ignore>stream</var>, |iterator|, and |arg|, are:

 1. Let |reader| be |iterator|'s [=ReadableStream async iterator/reader=].
 1. If |reader|.[=ReadableStreamGenericReader/[[stream]]=] is undefined, return [=a promise resolved
    with=] undefined.
 1. Assert: |reader|.[=ReadableStreamDefaultReader/[[readRequests]]=] is [=list/is empty|empty=],
    as the async iterator machinery guarantees that any previous calls to `next()` have settled
    before this is called.
 1. If |iterator|'s [=ReadableStream async iterator/prevent cancel=] is false:
  1. Let |result| be ! [$ReadableStreamReaderGenericCancel$](|reader|, |arg|).
  1. Perform ! [$ReadableStreamReaderGenericRelease$](|reader|).
  1. Return |result|.
 1. Perform ! [$ReadableStreamReaderGenericRelease$](|reader|).
 1. Return [=a promise resolved with=] undefined.
</div>

<h4 id="rs-transfer">Transfer via `postMessage()`</h4>

<dl class="domintro">
 <dt><code>destination.postMessage(rs, { transfer: [rs] });</code>
 <dd>
  <p>Sends a {{ReadableStream}} to another frame, window, or worker.

  <p>The transferred stream can be used exactly like the original. The original will become
  [=locked to a reader|locked=] and no longer directly usable.
 </dd>
</dl>

<div algorithm="ReadableStream transfer steps">
 {{ReadableStream}} objects are [=transferable objects=]. Their [=transfer steps=], given |value|
 and |dataHolder|, are:

 1. If ! [$IsReadableStreamLocked$](|value|) is true, throw a "{{DataCloneError}}" {{DOMException}}.
 1. Let |port1| be a [=new=] {{MessagePort}} in [=the current Realm=].
 1. Let |port2| be a [=new=] {{MessagePort}} in [=the current Realm=].
 1. [=Entangle=] |port1| and |port2|.
 1. Let |writable| be a [=new=] {{WritableStream}} in [=the current Realm=].
 1. Perform ! [$SetUpCrossRealmTransformWritable$](|writable|, |port1|).
 1. Let |promise| be ! [$ReadableStreamPipeTo$](|value|, |writable|, false, false, false).
 1. Set |promise|.\[[PromiseIsHandled]] to true.
 1. Set |dataHolder|.\[[port]] to ! [$StructuredSerializeWithTransfer$](|port2|, « |port2| »).
</div>

<div algorithm="ReadableStream transfer-receiving steps">
 Their [=transfer-receiving steps=], given |dataHolder| and |value|, are:

 1. Let |deserializedRecord| be ! [$StructuredDeserializeWithTransfer$](|dataHolder|.\[[port]],
    [=the current Realm=]).
 1. Let |port| be |deserializedRecord|.\[[Deserialized]].
 1. Perform ! [$SetUpCrossRealmTransformReadable$](|value|, |port|).

</div>

<h3 id="generic-reader-mixin">The {{ReadableStreamGenericReader}} mixin</h3>

The {{ReadableStreamGenericReader}} mixin defines common internal slots, getters and methods that
are shared between {{ReadableStreamDefaultReader}} and {{ReadableStreamBYOBReader}} objects.

<h4 id="generic-reader-mixin-definition">Mixin definition</h4>

The Web IDL definition for the {{ReadableStreamGenericReader}} mixin is given as follows:

<xmp class="idl">
interface mixin ReadableStreamGenericReader {
  readonly attribute Promise<void> closed;

  Promise<void> cancel(optional any reason);
};
</xmp>

<h4 id="generic-reader-internal-slots">Internal slots</h4>

Instances of classes including the {{ReadableStreamGenericReader}} mixin are created with the
internal slots described in the following table:

<table dfn-for="ReadableStreamGenericReader">
 <thead>
  <tr>
   <th>Internal Slot
   <th>Description (<em>non-normative</em>)
 <tbody>
  <tr>
   <td><dfn>\[[closedPromise]]</dfn>
   <td class="non-normative">A promise returned by the reader's
   {{ReadableStreamGenericReader/closed}} getter
  <tr>
   <td><dfn>\[[stream]]</dfn>
   <td class="non-normative">A {{ReadableStream}} instance that owns this reader
</table>

<h4 id="generic-reader-prototype">Methods and properties</h4>

<div algorithm>
 The <dfn id="generic-reader-closed" oldids="default-reader-closed,byob-reader-closed" attribute
 for="ReadableStreamGenericReader">closed</dfn>
 getter steps are:

 1. Return [=this=].[=ReadableStreamGenericReader/[[closedPromise]]=].
</div>

<div algorithm>
 The <dfn id="generic-reader-cancel" oldids="default-reader-cancel,byob-reader-cancel" method
 for="ReadableStreamGenericReader">cancel(|reason|)</dfn>
 method steps are:

 1. If [=this=].[=ReadableStreamGenericReader/[[stream]]=] is undefined, return [=a promise rejected
    with=] a {{TypeError}} exception.
 1. Return ! [$ReadableStreamReaderGenericCancel$]([=this=], |reason|).
</div>

<h3 id="default-reader-class">The {{ReadableStreamDefaultReader}} class</h3>

The {{ReadableStreamDefaultReader}} class represents a [=default reader=] designed to be vended by a
{{ReadableStream}} instance.

<h4 id="default-reader-class-definition">Interface definition</h4>

The Web IDL definition for the {{ReadableStreamDefaultReader}} class is given as follows:

<xmp class="idl">
[Exposed=(Window,Worker,Worklet)]
interface ReadableStreamDefaultReader {
  constructor(ReadableStream stream);

  Promise<ReadableStreamDefaultReadResult> read();
  void releaseLock();
};
ReadableStreamDefaultReader includes ReadableStreamGenericReader;

dictionary ReadableStreamDefaultReadResult {
 any value;
 boolean done;
};
</xmp>

<h4 id="default-reader-internal-slots">Internal slots</h4>

Instances of {{ReadableStreamDefaultReader}} are created with the internal slots defined by
{{ReadableStreamGenericReader}}, and those described in the following table:

<table dfn-for="ReadableStreamDefaultReader">
 <thead>
  <tr>
   <th>Internal Slot
   <th>Description (<em>non-normative</em>)
 <tbody>
  <tr>
   <td><dfn>\[[readRequests]]</dfn>
   <td class="non-normative">A [=list=] of [=read requests=], used when a [=consumer=] requests
   [=chunks=] sooner than they are available
</table>

A <dfn export>read request</dfn> is a [=struct=] containing three algorithms to perform in reaction
to filling the [=readable stream=]'s [=internal queue=] or changing its state. It has the following
[=struct/items=]:

: <dfn export for="read request">chunk steps</dfn>
:: An algorithm taking a [=chunk=], called when a chunk is available for reading
: <dfn export for="read request">close steps</dfn>
:: An algorithm taking no arguments, called when no [=chunks=] are available because the stream is
   closed
: <dfn export for="read request">error steps</dfn>
:: An algorithm taking a JavaScript value, called when no [=chunks=] are available because the
   stream is errored

<h4 id="default-reader-prototype">Constructor, methods, and properties</h4>

<dl class="domintro non-normative">
 <dt><code><var ignore>reader</var> = new {{ReadableStreamDefaultReader(stream)|ReadableStreamDefaultReader}}(|stream|)</code>
  <dd>
   <p>This is equivalent to calling <code>|stream|.{{ReadableStream/getReader()}}</code>.

 <dt><code>await <var ignore>reader</var>.{{ReadableStreamGenericReader/closed}}</code>
 <dd>
  <p>Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the
  stream ever errors or the reader's lock is [=release a read lock|released=] before the stream
  finishes closing.

 <dt><code>await <var ignore>reader</var>.{{ReadableStreamGenericReader/cancel(reason)|cancel}}([ <var ignore>reason</var> ])</code>
 <dd>
  <p>If the reader is [=active reader|active=], behaves the same as
  <code>|stream|.{{ReadableStream/cancel(reason)|cancel}}(<var ignore>reason</var>)</code>.

 <dt><code>{ <var ignore>value</var>, <var ignore>done</var> } = await <var ignore>reader</var>.{{ReadableStreamDefaultReader/read()|read}}()</code>
 <dd>
  <p>Returns a promise that allows access to the next [=chunk=] from the stream's internal queue, if
  available.

  <ul>
   <li>If the chunk does become available, the promise will be fulfilled with an object of the form
   <code highlight="js">{ value: theChunk, done: false }</code>.

   <li>If the stream becomes closed, the promise will be fulfilled with an object of the form
   <code highlight="js">{ value: undefined, done: true }</code>.

   <li>If the stream becomes errored, the promise will be rejected with the relevant error.
  </ul>

  <p>If reading a chunk causes the queue to become empty, more data will be pulled from the
  [=underlying source=].

 <dt><code><var ignore>reader</var>.{{ReadableStreamDefaultReader/releaseLock()|releaseLock}}()</code>
 <dd>
  <p>[=release a read lock|Releases the reader's lock=] on the corresponding stream. After the lock
  is released, the reader is no longer [=active reader|active=]. If the associated stream is errored
  when the lock is released, the reader will appear errored in the same way from now on; otherwise,
  the reader will appear closed.

  <p>A reader's lock cannot be released while it still has a pending read request, i.e., if a
  promise returned by the reader's {{ReadableStreamDefaultReader/read()}} method has not yet been
  settled. Attempting to do so will throw a {{TypeError}} and leave the reader locked to the stream.
</dl>

<div algorithm>
 The <dfn id="default-reader-constructor" constructor for="ReadableStreamDefaultReader"
 lt="ReadableStreamDefaultReader(stream)">new ReadableStreamDefaultReader(|stream|)</dfn>
 constructor steps are:

 1. Perform ? [$SetUpReadableStreamDefaultReader$]([=this=], |stream|).
</div>

<div algorithm>
 The <dfn id="default-reader-read" method for="ReadableStreamDefaultReader">read()</dfn>
 method steps are:

 1. If [=this=].[=ReadableStreamGenericReader/[[stream]]=] is undefined, return [=a promise rejected with=] a {{TypeError}}
    exception.
 1. Let |promise| be [=a new promise=].
 1. Let |readRequest| be a new [=read request=] with the following [=struct/items=]:
  : [=read request/chunk steps=], given |chunk|
  ::
   1. [=Resolve=] |promise| with «[ "{{ReadableStreamDefaultReadResult/value}}" → |chunk|,
      "{{ReadableStreamDefaultReadResult/done}}" → false ]».
  : [=read request/close steps=]
  ::
   1. [=Resolve=] |promise| with «[ "{{ReadableStreamDefaultReadResult/value}}" → undefined,
      "{{ReadableStreamDefaultReadResult/done}}" → true ]».
  : [=read request/error steps=], given |e|
  ::
   1. [=Reject=] |promise| with |e|.
 1. Perform ! [$ReadableStreamDefaultReaderRead$]([=this=], |readRequest|).
 1. Return |promise|.
</div>

<div algorithm>
 The <dfn id="default-reader-release-lock" method
 for="ReadableStreamDefaultReader">releaseLock()</dfn> method steps are:

 1. If [=this=].[=ReadableStreamGenericReader/[[stream]]=] is undefined, return.
 1. If [=this=].[=ReadableStreamDefaultReader/[[readRequests]]=] is not [=list/is empty|empty=],
    throw a {{TypeError}} exception.
 1. Perform ! [$ReadableStreamReaderGenericRelease$]([=this=]).
</div>

<h3 id="byob-reader-class">The {{ReadableStreamBYOBReader}} class</h3>

The {{ReadableStreamBYOBReader}} class represents a [=BYOB reader=] designed to be vended by a
{{ReadableStream}} instance.

<h4 id="byob-reader-class-definition">Interface definition</h4>

The Web IDL definition for the {{ReadableStreamBYOBReader}} class is given as follows:

<xmp class="idl">
[Exposed=(Window,Worker,Worklet)]
interface ReadableStreamBYOBReader {
  constructor(ReadableStream stream);

  Promise<ReadableStreamBYOBReadResult> read(ArrayBufferView view);
  void releaseLock();
};
ReadableStreamBYOBReader includes ReadableStreamGenericReader;

dictionary ReadableStreamBYOBReadResult {
 ArrayBufferView value;
 boolean done;
};
</xmp>

<h4 id="byob-reader-internal-slots">Internal slots</h4>

Instances of {{ReadableStreamBYOBReader}} are created with the internal slots defined by
{{ReadableStreamGenericReader}}, and those described in the following table:

<table dfn-for="ReadableStreamBYOBReader">
 <thead>
  <tr>
   <th>Internal Slot
   <th>Description (<em>non-normative</em>)
 <tbody>
  <tr>
   <td><dfn>\[[readIntoRequests]]</dfn>
   <td class="non-normative">A [=list=] of [=read-into requests=], used when a [=consumer=] requests
   [=chunks=] sooner than they are available
</table>

A <dfn export>read-into request</dfn> is a [=struct=] containing three algorithms to perform in
reaction to filling the [=readable byte stream=]'s [=internal queue=] or changing its state. It has
the following [=struct/items=]:

: <dfn export for="read-into request">chunk steps</dfn>
:: An algorithm taking a [=chunk=], called when a chunk is available for reading
: <dfn export for="read-into request">close steps</dfn>
:: An algorithm taking a [=chunk=], called when no chunks are available because the stream is
   closed
: <dfn export for="read-into request">error steps</dfn>
:: An algorithm taking a JavaScript value, called when no [=chunks=] are available because the
   stream is errored

<p class="note">The [=read-into request/close steps=] take a [=chunk=] so that it can return the
backing memory to the caller if possible. For example,
{{ReadableStreamBYOBReader/read()|byobReader.read(chunk)}} will fulfill with <code highlight="js">{
value: newViewOnSameMemory, done: true }</code> for closed streams, instead of the more traditional
<code highlight="js">{ value: undefined, done: true }</code>.

<h4 id="byob-reader-prototype">Constructor, methods, and properties</h4>

<dl class="domintro non-normative">
 <dt><code><var ignore>reader</var> = new {{ReadableStreamBYOBReader(stream)|ReadableStreamBYOBReader}}(|stream|)</code>
  <dd>
   <p>This is equivalent to calling <code>|stream|.{{ReadableStream/getReader}}({
   {{ReadableStreamGetReaderOptions/mode}}: "{{ReadableStreamReaderMode/byob}}" })</code>.

 <dt><code>await <var ignore>reader</var>.{{ReadableStreamGenericReader/closed}}</code>
 <dd>
  <p>Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the
  stream ever errors or the reader's lock is [=release a read lock|released=] before the stream
  finishes closing.

 <dt><code>await <var ignore>reader</var>.{{ReadableStreamGenericReader/cancel(reason)|cancel}}([ <var ignore>reason</var> ])</code>
 <dd>
  <p>If the reader is [=active reader|active=], behaves the same
  <code>|stream|.{{ReadableStream/cancel(reason)|cancel}}(<var ignore>reason</var>)</code>.

 <dt><code>{ <var ignore>value</var>, <var ignore>done</var> } = await <var ignore>reader</var>.{{ReadableStreamBYOBReader/read()|read}}(<var ignore>view</var>)</code>
 <dd>
  <p>Attempts to reads bytes into |view|, and returns a promise resolved with the result:

  <ul>
   <li>If the chunk does become available, the promise will be fulfilled with an object of the form
   <code highlight="js">{ value: theChunk, done: false }</code>. In this case, |view| will be
   [=ArrayBuffer/detached=] and no longer usable, but <code>theChunk</code> will be a new view (of
   the same type) onto the same backing memory region, with the chunk's data written into it.

   <li>If the stream becomes closed, the promise will be fulfilled with an object of the form
   <code highlight="js">{ value: theChunk, done: true }</code>. In this case, |view| will be
   [=ArrayBuffer/detached=] and no longer usable, but <code>theChunk</code> will be a new view (of
   the same type) onto the same backing memory region, with no modifications, to ensure the memory
   is returned to the caller.

   <li>If the stream becomes errored, the promise will be rejected with the relevant error.
  </ul>

  <p>If reading a chunk causes the queue to become empty, more data will be pulled from the
  [=underlying source=].

 <dt><code><var ignore>reader</var>.{{ReadableStreamBYOBReader/releaseLock()|releaseLock}}()</code>
 <dd>
  <p>[=release a read lock|Releases the reader's lock=] on the corresponding stream. After the lock
  is released, the reader is no longer [=active reader|active=]. If the associated stream is errored
  when the lock is released, the reader will appear errored in the same way from now on; otherwise,
  the reader will appear closed.

  <p>A reader's lock cannot be released while it still has a pending read request, i.e., if a
  promise returned by the reader's {{ReadableStreamBYOBReader/read()}} method has not yet been
  settled. Attempting to do so will throw a {{TypeError}} and leave the reader locked to the stream.
</dl>

<div algorithm>
 The <dfn id="byob-reader-constructor" constructor for="ReadableStreamBYOBReader"
 lt="ReadableStreamBYOBReader(stream)">new ReadableStreamBYOBReader(|stream|)</dfn> constructor
 steps are:

 1. Perform ? [$SetUpReadableStreamBYOBReader$]([=this=], |stream|).
</div>

<div algorithm>
 The <dfn id="byob-reader-read" method for="ReadableStreamBYOBReader">read(|view|)</dfn>
 method steps are:

 1. If |view|.\[[ByteLength]] is 0, return [=a promise rejected with=] a {{TypeError}} exception.
 1. If |view|.\[[ViewedArrayBuffer]].\[[ArrayBufferByteLength]] is 0, return [=a promise rejected
    with=] a {{TypeError}} exception.
 1. If [=this=].[=ReadableStreamGenericReader/[[stream]]=] is undefined, return [=a promise rejected
    with=] a {{TypeError}} exception.
 1. Let |promise| be [=a new promise=].
 1. Let |readIntoRequest| be a new [=read-into request=] with the following [=struct/items=]:
  : [=read-into request/chunk steps=], given |chunk|
  ::
   1. [=Resolve=] |promise| with «[ "{{ReadableStreamBYOBReadResult/value}}" → |chunk|,
      "{{ReadableStreamBYOBReadResult/done}}" → false ]».
  : [=read-into request/close steps=], given |chunk|
  ::
   1. [=Resolve=] |promise| with «[ "{{ReadableStreamBYOBReadResult/value}}" → |chunk|,
      "{{ReadableStreamBYOBReadResult/done}}" → true ]».
  : [=read-into request/error steps=], given |e|
  ::
   1. [=Reject=] |promise| with |e|.
 1. Perform ! [$ReadableStreamBYOBReaderRead$]([=this=], |view|, |readIntoRequest|).
 1. Return |promise|.
</div>

<div algorithm>
 The <dfn id="byob-reader-release-lock" method
 for="ReadableStreamBYOBReader">releaseLock()</dfn> method steps are:

 1. If [=this=].[=ReadableStreamGenericReader/[[stream]]=] is undefined, return.
 1. If [=this=].[=ReadableStreamBYOBReader/[[readIntoRequests]]=] is not [=list/is empty|empty=],
    throw a {{TypeError}} exception.
 1. Perform ! [$ReadableStreamReaderGenericRelease$]([=this=]).
</div>

<h3 id="rs-default-controller-class">The {{ReadableStreamDefaultController}} class</h3>

The {{ReadableStreamDefaultController}} class has methods that allow control of a
{{ReadableStream}}'s state and [=internal queue=]. When constructing a {{ReadableStream}} that is
not a [=readable byte stream=], the [=underlying source=] is given a corresponding
{{ReadableStreamDefaultController}} instance to manipulate.

<h4 id="rs-default-controller-class-definition">Interface definition</h4>

The Web IDL definition for the {{ReadableStreamDefaultController}} class is given as follows:

<xmp class="idl">
[Exposed=(Window,Worker,Worklet)]
interface ReadableStreamDefaultController {
  readonly attribute unrestricted double? desiredSize;

  void close();
  void enqueue(optional any chunk);
  void error(optional any e);
};
</xmp>

<h4 id="rs-default-controller-internal-slots">Internal slots</h4>

Instances of {{ReadableStreamDefaultController}} are created with the internal slots described in
the following table:

<table dfn-for="ReadableStreamDefaultController">
 <thead>
  <tr>
   <th>Internal Slot</th>
   <th>Description (<em>non-normative</em>)</th>
 <tbody>
  <tr>
   <td><dfn>\[[cancelAlgorithm]]</dfn>
   <td class="non-normative">A promise-returning algorithm, taking one argument (the cancel reason),
   which communicates a requested cancelation to the [=underlying source=]
  <tr>
   <td><dfn>\[[closeRequested]]</dfn>
   <td class="non-normative">A boolean flag indicating whether the stream has been closed by its
   [=underlying source=], but still has [=chunks=] in its internal queue that have not yet been
   read
  <tr>
   <td><dfn>\[[pullAgain]]</dfn>
   <td class="non-normative">A boolean flag set to true if the stream's mechanisms requested a call
   to the [=underlying source=]'s pull algorithm to pull more data, but the pull could not yet be
   done since a previous call is still executing
  <tr>
   <td><dfn>\[[pullAlgorithm]]</dfn>
   <td class="non-normative">A promise-returning algorithm that pulls data from the [=underlying
   source=]
  <tr>
   <td><dfn>\[[pulling]]</dfn>
   <td class="non-normative">A boolean flag set to true while the [=underlying source=]'s pull
   algorithm is executing and the returned promise has not yet fulfilled, used to prevent reentrant
   calls
  <tr>
   <td><dfn>\[[queue]]</dfn>
   <td class="non-normative">A [=list=] representing the stream's internal queue of [=chunks=]
  <tr>
   <td><dfn>\[[queueTotalSize]]</dfn>
   <td class="non-normative">The total size of all the chunks stored in
   [=ReadableStreamDefaultController/[[queue]]=] (see [[#queue-with-sizes]])
  <tr>
   <td><dfn>\[[started]]</dfn>
   <td class="non-normative">A boolean flag indicating whether the [=underlying source=] has
   finished starting
  <tr>
   <td><dfn>\[[strategyHWM]]</dfn>
   <td class="non-normative">A number supplied to the constructor as part of the stream's [=queuing
   strategy=], indicating the point at which the stream will apply [=backpressure=] to its
   [=underlying source=]
  <tr>
   <td><dfn>\[[strategySizeAlgorithm]]</dfn>
   <td class="non-normative">An algorithm to calculate the size of enqueued [=chunks=], as part of
   the stream's [=queuing strategy=]
  <tr>
   <td><dfn>\[[stream]]</dfn>
   <td class="non-normative">The {{ReadableStream}} instance controlled
</table>

<h4 id="rs-default-controller-prototype">Methods and properties</h4>

<dl class="domintro non-normative">
 <dt><code><var ignore>desiredSize</var> = <var ignore>controller</var>.{{ReadableStreamDefaultController/desiredSize}}</code>
 <dd>
  <p>Returns the [=desired size to fill a stream's internal queue|desired size to fill the
  controlled stream's internal queue=]. It can be negative, if the queue is over-full. An
  [=underlying source=] ought to use this information to determine when and how to apply
  [=backpressure=].

 <dt><code><var ignore>controller</var>.{{ReadableStreamDefaultController/close()|close}}()</code>
 <dd>
  <p>Closes the controlled readable stream. [=Consumers=] will still be able to read any
  previously-enqueued [=chunks=] from the stream, but once those are read, the stream will become
  closed.

 <dt><code><var ignore>controller</var>.{{ReadableStreamDefaultController/enqueue()|enqueue}}(<var ignore>chunk</var>)</code>
 <dd>
  <p>Enqueues the given [=chunk=] <var ignore>chunk</var> in the controlled readable stream.

 <dt><code><var ignore>controller</var>.{{ReadableStreamDefaultController/error()|error}}(<var ignore>e</var>)</code>
 <dd>
  <p>Errors the controlled readable stream, making all future interactions with it fail with the
  given error <var ignore>e</var>.
</dl>

<div algorithm>
 The <dfn id="rs-default-controller-desired-size" attribute
 for="ReadableStreamDefaultController">desiredSize</dfn> getter steps are:

 1. Return ! [$ReadableStreamDefaultControllerGetDesiredSize$]([=this=]).
</div>

<div algorithm>
 The <dfn id="rs-default-controller-close" method
 for="ReadableStreamDefaultController">close()</dfn> method steps are:

 1. If ! [$ReadableStreamDefaultControllerCanCloseOrEnqueue$]([=this=]) is false, throw a
    {{TypeError}} exception.
 1. Perform ! [$ReadableStreamDefaultControllerClose$]([=this=]).
</div>

<div algorithm>
 The <dfn id="rs-default-controller-enqueue" method
 for="ReadableStreamDefaultController">enqueue(|chunk|)</dfn> method steps are:

 1. If ! [$ReadableStreamDefaultControllerCanCloseOrEnqueue$]([=this=]) is false, throw a
    {{TypeError}} exception.
 1. Perform ? [$ReadableStreamDefaultControllerEnqueue$]([=this=], |chunk|).
</div>

<div algorithm>
 The <dfn id="rs-default-controller-error" method
 for="ReadableStreamDefaultController">error(|e|)</dfn> method steps are:

 1. Perform ! [$ReadableStreamDefaultControllerError$]([=this=], |e|).
</div>

<h4 id="rs-default-controller-internal-methods">Internal methods</h4>

The following are internal methods implemented by each {{ReadableStreamDefaultController}} instance.
The readable stream implementation will polymorphically call to either these, or to their
counterparts for BYOB controllers, as discussed in [[#rs-abstract-ops-used-by-controllers]].

<div algorithm>
 <dfn abstract-op lt="[[CancelSteps]]" for="ReadableStreamDefaultController"
 id="rs-default-controller-private-cancel">\[[CancelSteps]](|reason|)</dfn> implements the
 [$ReadableStreamController/[[CancelSteps]]$] contract. It performs the following steps:

 1. Perform ! [$ResetQueue$]([=this=]).
 1. Let |result| be the result of performing
    [=this=].[=ReadableStreamDefaultController/[[cancelAlgorithm]]=], passing |reason|.
 1. Perform ! [$ReadableStreamDefaultControllerClearAlgorithms$]([=this=]).
 1. Return |result|.
</div>

<div algorithm>
 <dfn abstract-op lt="[[PullSteps]]" for="ReadableStreamDefaultController"
 id="rs-default-controller-private-pull">\[[PullSteps]](|readRequest|)</dfn> implements the
 [$ReadableStreamController/[[PullSteps]]$] contract. It performs the following steps:

 1. Let |stream| be [=this=].[=ReadableStreamGenericReader/[[stream]]=].
 1. If [=this=].[=ReadableStreamDefaultController/[[queue]]=] is not [=list/is empty|empty=],
  1. Let |chunk| be ! [$DequeueValue$]([=this=]).
  1. If [=this=].[=ReadableStreamDefaultController/[[closeRequested]]=] is true and
     [=this=].[=ReadableStreamDefaultController/[[queue]]=] [=list/is empty=],
   1. Perform ! [$ReadableStreamDefaultControllerClearAlgorithms$]([=this=]).
   1. Perform ! [$ReadableStreamClose$](|stream|).
  1. Otherwise, perform ! [$ReadableStreamDefaultControllerCallPullIfNeeded$]([=this=]).
  1. Perform |readRequest|'s [=read request/chunk steps=], given |chunk|.
 1. Otherwise,
  1. Perform ! [$ReadableStreamAddReadRequest$](|stream|, |readRequest|).
  1. Perform ! [$ReadableStreamDefaultControllerCallPullIfNeeded$]([=this=]).
</div>

<h3 id="rbs-controller-class">The {{ReadableByteStreamController}} class</h3>

The {{ReadableByteStreamController}} class has methods that allow control of a {{ReadableStream}}'s
state and [=internal queue=]. When constructing a {{ReadableStream}} that is a [=readable byte
stream=], the [=underlying source=] is given a corresponding {{ReadableByteStreamController}}
instance to manipulate.

<h4 id="rbs-controller-class-definition">Interface definition</h4>

The Web IDL definition for the {{ReadableByteStreamController}} class is given as follows:

<xmp class="idl">
[Exposed=(Window,Worker,Worklet)]
interface ReadableByteStreamController {
  readonly attribute ReadableStreamBYOBRequest? byobRequest;
  readonly attribute unrestricted double? desiredSize;

  void close();
  void enqueue(ArrayBufferView chunk);
  void error(optional any e);
};
</xmp>

<h4 id="rbs-controller-internal-slots">Internal slots</h4>

Instances of {{ReadableByteStreamController}} are created with the internal slots described in the
following table:

<table dfn-for="ReadableByteStreamController">
 <thead>
  <tr>
   <th>Internal Slot</th>
   <th>Description (<em>non-normative</em>)</th>
 <tbody>
  <tr>
   <td><dfn>\[[autoAllocateChunkSize]]</dfn>
   <td class="non-normative">A positive integer, when the automatic buffer allocation feature is
   enabled. In that case, this value specifies the size of buffer to allocate. It is undefined
   otherwise.
  <tr>
   <td><dfn>\[[byobRequest]]</dfn>
   <td class="non-normative">A {{ReadableStreamBYOBRequest}} instance representing the current BYOB
   pull request, or null if there are no pending requests
  <tr>
   <td><dfn>\[[cancelAlgorithm]]</dfn>
   <td class="non-normative">A promise-returning algorithm, taking one argument (the cancel reason),
   which communicates a requested cancelation to the [=underlying byte source=]
  <tr>
   <td><dfn>\[[closeRequested]]</dfn>
   <td class="non-normative">A boolean flag indicating whether the stream has been closed by its
   [=underlying byte source=], but still has [=chunks=] in its internal queue that have not yet been
   read
  <tr>
   <td><dfn>\[[pullAgain]]</dfn>
   <td class="non-normative">A boolean flag set to true if the stream's mechanisms requested a call
   to the [=underlying byte source=]'s pull algorithm to pull more data, but the pull could not yet
   be done since a previous call is still executing
  <tr>
   <td><dfn>\[[pullAlgorithm]]</dfn>
   <td class="non-normative">A promise-returning algorithm that pulls data from the [=underlying
   byte source=]
  <tr>
   <td><dfn>\[[pulling]]</dfn>
   <td class="non-normative">A boolean flag set to true while the [=underlying byte source=]'s pull
   algorithm is executing and the returned promise has not yet fulfilled, used to prevent reentrant
   calls
  <tr>
   <td><dfn>\[[pendingPullIntos]]</dfn>
   <td class="non-normative">A [=list=] of [=pull-into descriptors=]
  <tr>
   <td><dfn>\[[queue]]</dfn>
   <td class="non-normative">A [=list=] of [=readable byte stream queue entry|readable byte stream
   queue entries=] representing the stream's internal queue of [=chunks=]
  <tr>
   <td><dfn>\[[queueTotalSize]]</dfn>
   <td class="non-normative">The total size, in bytes, of all the chunks stored in
   [=ReadableByteStreamController/[[queue]]=] (see [[#queue-with-sizes]])
  <tr>
   <td><dfn>\[[started]]</dfn>
   <td class="non-normative">A boolean flag indicating whether the [=underlying byte source=] has
   finished starting
  <tr>
   <td><dfn>\[[strategyHWM]]</dfn>
   <td class="non-normative">A number supplied to the constructor as part of the stream's [=queuing
   strategy=], indicating the point at which the stream will apply [=backpressure=] to its
   [=underlying byte source=]
  <tr>
   <td><dfn>\[[stream]]</dfn>
   <td class="non-normative">The {{ReadableStream}} instance controlled
</table>

<div class="note">
 <p>Although {{ReadableByteStreamController}} instances have
 [=ReadableByteStreamController/[[queue]]=] and [=ReadableByteStreamController/[[queueTotalSize]]=]
 slots, we do not use most of the abstract operations in [[#queue-with-sizes]] on them, as the way
 in which we manipulate this queue is rather different than the others in the spec. Instead, we
 update the two slots together manually.

 <p>This might be cleaned up in a future spec refactoring.
</div>

A <dfn>readable byte stream queue entry</dfn> is a [=struct=] encapsulating the important aspects of
a [=chunk=] for the specific case of [=readable byte streams=]. It has the following
[=struct/items=]:

: <dfn for="readable byte stream queue entry">buffer</dfn>
:: An {{ArrayBuffer}}, which will be a <a href="#transfer-array-buffer">transferred</a> version of
   the one originally supplied by the [=underlying byte source=]
: <dfn for="readable byte stream queue entry">byte offset</dfn>
:: A nonnegative integer number giving the byte offset derived from the view originally supplied by
   the [=underlying byte source=]
: <dfn for="readable byte stream queue entry">byte length</dfn>
:: A nonnegative integer number giving the byte length derived from the view originally supplied by
   the [=underlying byte source=]

A <dfn>pull-into descriptor</dfn> is a [=struct=] used to represent pending BYOB pull requests. It
has the following [=struct/items=]:

: <dfn for="pull-into descriptor">buffer</dfn>
:: An {{ArrayBuffer}}
: <dfn for="pull-into descriptor">byte offset</dfn>
:: A nonnegative integer byte offset into the [=pull-into descriptor/buffer=] where the
   [=underlying byte source=] will start writing
: <dfn for="pull-into descriptor">byte length</dfn>
:: A nonnegative integer number of bytes which can be written into the [=pull-into
   descriptor/buffer=]
: <dfn for="pull-into descriptor">bytes filled</dfn>
:: A nonnegative integer number of bytes that have been written into the [=pull-into
   descriptor/buffer=] so far
: <dfn for="pull-into descriptor">element size</dfn>
:: A positive integer representing the number of bytes that can be written into the [=pull-into
   descriptor/buffer=] at a time, using views of the type described by the [=pull-into
   descriptor/view constructor=]
: <dfn for="pull-into descriptor">view constructor</dfn>
:: A [=the typed array constructors table|typed array constructor=] or {{%DataView%}}, which will be
   used for constructing a view with which to write into the [=pull-into descriptor/buffer=]
: <dfn for="pull-into descriptor">reader type</dfn>
:: Either "`default`" or "`byob`", indicating what type of [=readable stream reader=] initiated this
   request

<h4 id="rbs-controller-prototype">Methods and properties</h4>

<dl class="domintro non-normative">
 <dt><code><var ignore>byobRequest</var> = <var ignore>controller</var>.{{ReadableByteStreamController/byobRequest}}</code>
 <dd>
  <p>Returns the current BYOB pull request, or null if there isn't one.

 <dt><code><var ignore>desiredSize</var> = <var ignore>controller</var>.{{ReadableByteStreamController/desiredSize}}</code>
 <dd>
  <p>Returns the [=desired size to fill a stream's internal queue|desired size to fill the
  controlled stream's internal queue=]. It can be negative, if the queue is over-full. An
  [=underlying byte source=] ought to use this information to determine when and how to apply
  [=backpressure=].

 <dt><code><var ignore>controller</var>.{{ReadableByteStreamController/close()|close}}()</code>
 <dd>
  <p>Closes the controlled readable stream. [=Consumers=] will still be able to read any
  previously-enqueued [=chunks=] from the stream, but once those are read, the stream will become
  closed.

 <dt><code><var ignore>controller</var>.{{ReadableByteStreamController/enqueue()|enqueue}}(<var ignore>chunk</var>)</code>
 <dd>
  <p>Enqueues the given [=chunk=] <var ignore>chunk</var> in the controlled readable stream. The
  chunk has to be an {{ArrayBufferView}} instance, or else a {{TypeError}} will be thrown.

 <dt><code><var ignore>controller</var>.{{ReadableByteStreamController/error()|error}}(<var ignore>e</var>)</code>
 <dd>
  <p>Errors the controlled readable stream, making all future interactions with it fail with the
  given error <var ignore>e</var>.
</dl>

<div algorithm>
 The <dfn id="rbs-controller-byob-request" attribute
 for="ReadableByteStreamController">byobRequest</dfn> getter steps are:

 1. If [=this=].[=ReadableByteStreamController/[[byobRequest]]=] is null and [=this=].[=ReadableByteStreamController/[[pendingPullIntos]]=] is not [=list/is
    empty|empty=],
  1. Let |firstDescriptor| be [=this=].[=ReadableByteStreamController/[[pendingPullIntos]]=][0].
  1. Let |view| be ! [$Construct$]({{%Uint8Array%}}, « |firstDescriptor|'s [=pull-into
     descriptor/buffer=], |firstDescriptor|'s [=pull-into descriptor/byte offset=] +
     |firstDescriptor|'s [=pull-into descriptor/bytes filled=], |firstDescriptor|'s [=pull-into
     descriptor/byte length=] − |firstDescriptor|'s [=pull-into descriptor/bytes filled=] »).
  1. Let |byobRequest| be a [=new=] {{ReadableStreamBYOBRequest}}.
  1. Set |byobRequest|.[=ReadableStreamBYOBRequest/[[controller]]=] to [=this=].
  1. Set |byobRequest|.[=ReadableStreamBYOBRequest/[[view]]=] to |view|.
  1. Set [=this=].[=ReadableByteStreamController/[[byobRequest]]=] to |byobRequest|.
 1. Return [=this=].[=ReadableByteStreamController/[[byobRequest]]=].
</div>

<div algorithm>
 The <dfn id="rbs-controller-desired-size" attribute
 for="ReadableByteStreamController">desiredSize</dfn> getter steps are:

 1. Return ! [$ReadableByteStreamControllerGetDesiredSize$]([=this=]).
</div>

<div algorithm>
 The <dfn id="rbs-controller-close" method for="ReadableByteStreamController">close()</dfn> method
 steps are:

 1. If [=this=].[=ReadableByteStreamController/[[closeRequested]]=] is true, throw a {{TypeError}}
    exception.
 1. If [=this=].[=ReadableStreamGenericReader/[[stream]]=].[=ReadableStream/[[state]]=] is not
    "`readable`", throw a {{TypeError}} exception.
 1. Perform ? [$ReadableByteStreamControllerClose$]([=this=]).
</div>

<div algorithm>
 The <dfn id="rbs-controller-enqueue" method
for="ReadableByteStreamController">enqueue(|chunk|)</dfn> method steps are:

 1. If |chunk|.\[[ByteLength]] is 0, throw a {{TypeError}} exception.
 1. If |chunk|.\[[ViewedArrayBuffer]].\[[ArrayBufferByteLength]] is 0, throw a {{TypeError}}
    exception.
 1. If [=this=].[=ReadableByteStreamController/[[closeRequested]]=] is true, throw a {{TypeError}}
    exception.
 1. If [=this=].[=ReadableStreamGenericReader/[[stream]]=].[=ReadableStream/[[state]]=] is not
    "`readable`", throw a {{TypeError}} exception.
 1. Return ! [$ReadableByteStreamControllerEnqueue$]([=this=], |chunk|).
</div>

<div algorithm>
 The <dfn id="rbs-controller-error" method for="ReadableByteStreamController">error(|e|)</dfn>
 method steps are:

 1. Perform ! [$ReadableByteStreamControllerError$]([=this=], |e|).
</div>

<h4 id="rbs-controller-internal-methods">Internal methods</h4>

The following are internal methods implemented by each {{ReadableByteStreamController}} instance.
The readable stream implementation will polymorphically call to either these, or to their
counterparts for default controllers, as discussed in [[#rs-abstract-ops-used-by-controllers]].

<div algorithm>
 <dfn abstract-op lt="[[CancelSteps]]" for="ReadableByteStreamController"
 id="rbs-controller-private-cancel">\[[CancelSteps]](|reason|)</dfn> implements the
 [$ReadableStreamController/[[CancelSteps]]$] contract. It performs the following steps:

 1. If [=this=].[=ReadableByteStreamController/[[pendingPullIntos]]=] is not [=list/is
    empty|empty=],
  1. Let |firstDescriptor| be [=this=].[=ReadableByteStreamController/[[pendingPullIntos]]=][0].
  1. Set |firstDescriptor|'s [=pull-into descriptor/bytes filled=] to 0.
 1. Perform ! [$ResetQueue$]([=this=]).
 1. Let |result| be the result of performing
    [=this=].[=ReadableByteStreamController/[[cancelAlgorithm]]=], passing in |reason|.
 1. Perform ! [$ReadableByteStreamControllerClearAlgorithms$]([=this=]).
 1. Return |result|.
</div>

<div algorithm>
 <dfn abstract-op lt="[[PullSteps]]" for="ReadableByteStreamController"
 id="rbs-controller-private-pull">\[[PullSteps]](|readRequest|)</dfn> implements the
 [$ReadableStreamController/[[PullSteps]]$] contract. It performs the following steps:

 1. Let |stream| be [=this=].[=ReadableByteStreamController/[[stream]]=].
 1. Assert: ! [$ReadableStreamHasDefaultReader$](|stream|) is true.
 1. If [=this=].[=ReadableByteStreamController/[[queueTotalSize]]=] > 0,
  1. Assert: ! [$ReadableStreamGetNumReadRequests$](|stream|) is 0.
  1. Let |entry| be [=this=].[=ReadableByteStreamController/[[queue]]=][0].
  1. [=list/Remove=] |entry| from [=this=].[=ReadableByteStreamController/[[queue]]=].
  1. Set [=this=].[=ReadableByteStreamController/[[queueTotalSize]]=] to
     [=this=].[=ReadableByteStreamController/[[queueTotalSize]]=] − |entry|'s [=readable byte stream
     queue entry/byte length=].
  1. Perform ! [$ReadableByteStreamControllerHandleQueueDrain$]([=this=]).
  1. Let |view| be ! [$Construct$]({{%Uint8Array%}}, « |entry|'s [=readable byte stream queue
     entry/buffer=], |entry|'s [=readable byte stream queue entry/byte offset=], |entry|'s
     [=readable byte stream queue entry/byte length=] »).
  1. Perform |readRequest|'s [=read request/chunk steps=], given |view|.
  1. Return.
 1. Let |autoAllocateChunkSize| be
    [=this=].[=ReadableByteStreamController/[[autoAllocateChunkSize]]=].
 1. If |autoAllocateChunkSize| is not undefined,
  1. Let |buffer| be [$Construct$]({{%ArrayBuffer%}}, « |autoAllocateChunkSize| »).
  1. If |buffer| is an abrupt completion,
   1. Perform |readRequest|'s [=read request/error steps=], given |buffer|.\[[Value]].
   1. Return.
  1. Let |pullIntoDescriptor| be a new [=pull-into descriptor=] with [=pull-into descriptor/buffer=]
     |buffer|.\[[Value]], [=pull-into descriptor/byte offset=] 0, [=pull-into descriptor/byte
     length=] |autoAllocateChunkSize|, [=pull-into descriptor/bytes filled=] 0, [=pull-into
     descriptor/element size=] 1, [=pull-into descriptor/view constructor=] {{%Uint8Array%}}, and
     [=pull-into descriptor/reader type=] "`default`".
  1. [=list/Append=] |pullIntoDescriptor| to
     [=this=].[=ReadableByteStreamController/[[pendingPullIntos]]=].
 1. Perform ! [$ReadableStreamAddReadRequest$](|stream|, |readRequest|).
 1. Perform ! [$ReadableByteStreamControllerCallPullIfNeeded$]([=this=]).
</div>

<h3 id="rs-byob-request-class">The {{ReadableStreamBYOBRequest}} class</h3>

The {{ReadableStreamBYOBRequest}} class represents a pull-into request in a
{{ReadableByteStreamController}}.

<h4 id="rs-byob-request-class-definition">Interface definition</h4>

The Web IDL definition for the {{ReadableStreamBYOBRequest}} class is given as follows:

<xmp class="idl">
[Exposed=(Window,Worker,Worklet)]
interface ReadableStreamBYOBRequest {
  readonly attribute ArrayBufferView? view;

  void respond([EnforceRange] unsigned long long bytesWritten);
  void respondWithNewView(ArrayBufferView view);
};
</xmp>

<h4 id="rs-byob-request-internal-slots">Internal slots</h4>

Instances of {{ReadableStreamBYOBRequest}} are created with the internal slots described in the
following table:

<table dfn-for="ReadableStreamBYOBRequest">
 <thead>
  <tr>
   <th>Internal Slot</th>
   <th>Description (<em>non-normative</em>)</th>
 <tbody>
 <tr>
  <td><dfn>\[[controller]]</dfn>
  <td class="non-normative">The parent {{ReadableByteStreamController}} instance
 <tr>
  <td><dfn>\[[view]]</dfn>
  <td class="non-normative">A [=typed array=] representing the destination region to which the
  controller can write generated data, or null after the BYOB request has been invalidated.
</table>

<h4 id="rs-byob-request-prototype">Methods and properties</h4>

<dl class="domintro non-normative">
 <dt><code><var ignore>view</var> = <var ignore>byobRequest</var>.{{ReadableStreamBYOBRequest/view}}</code>
 <dd>
  <p>Returns the view for writing in to, or null if the BYOB request has already been responded to.

 <dt><code><var ignore>byobRequest</var>.{{ReadableStreamBYOBRequest/respond()|respond}}(<var ignore>bytesWritten</var>)</code>
 <dd>
  <p>Indicates to the associated [=readable byte stream=] that <var ignore>bytesWritten</var> bytes
  were written into {{ReadableStreamBYOBRequest/view}}, causing the result be surfaced to the
  [=consumer=].

  <p>After this method is called, {{ReadableStreamBYOBRequest/view}} will be <a
  href="#transfer-array-buffer">transferred</a> and no longer modifiable.

 <dt><code><var ignore>byobRequest</var>.{{ReadableStreamBYOBRequest/respondWithNewView()|respondWithNewView}}(<var ignore>view</var>)</code>
 <dd>
  <p>Indicates to the associated [=readable byte stream=] that instead of writing into
  {{ReadableStreamBYOBRequest/view}}, the [=underlying byte source=] is providing a new
  {{ArrayBufferView}}, which will be given to the [=consumer=] of the [=readable byte stream=].

  <p>After this method is called, <var ignore>view</var> will be <a
  href="#transfer-array-buffer">transferred</a> and no longer modifiable.
</dl>

<div algorithm>
 The <dfn id="rs-byob-request-view" attribute for="ReadableStreamBYOBRequest">view</dfn>
 getter steps are:

 1. Return [=this=].[=ReadableStreamBYOBRequest/[[view]]=].
</div>

<div algorithm>
 The <dfn id="rs-byob-request-respond" method
 for="ReadableStreamBYOBRequest">respond(|bytesWritten|)</dfn> method steps are:

 1. If [=this=].[=ReadableStreamBYOBRequest/[[controller]]=] is undefined, throw a {{TypeError}}
    exception.
 1. If [$IsDetachedBuffer$]([=this=].[=ReadableStreamBYOBRequest/[[view]]=].\[[ArrayBuffer]]) is
    true, throw a {{TypeError}} exception.
 1. Assert: [=this=].[=ReadableStreamBYOBRequest/[[view]]=].\[[ByteLength]] &gt; 0.
 1. Assert: [=this=].[=ReadableStreamBYOBRequest/[[view]]=].\[[ViewedArrayBuffer]].\[[ByteLength]]
    &gt; 0.
 1. Perform ?
    [$ReadableByteStreamControllerRespond$]([=this=].[=ReadableStreamBYOBRequest/[[controller]]=],
    |bytesWritten|).
</div>

<div algorithm>
 The <dfn id="rs-byob-request-respond-with-new-view" method
 for="ReadableStreamBYOBRequest">respondWithNewView(|view|)</dfn> method steps are:

 1. If |view|.\[[ByteLength]] is 0, throw a {{TypeError}} exception.
 1. If |view|.\[[ViewedArrayBuffer]].\[[ArrayBufferByteLength]] is 0, throw a {{TypeError}}
    exception.
 1. If [=this=].[=ReadableStreamBYOBRequest/[[controller]]=] is undefined, throw a {{TypeError}}
    exception.
 1. Return ?
    [$ReadableByteStreamControllerRespondWithNewView$]([=this=].[=ReadableStreamBYOBRequest/[[controller]]=],
    |view|).
</div>

<h3 id="rs-all-abstract-ops">Abstract operations</h3>

<h4 id="rs-abstract-ops">Working with readable streams</h4>

The following abstract operations operate on {{ReadableStream}} instances at a higher level. Some
are even meant to be generally useful by other specifications.

<div algorithm>
 <dfn abstract-op lt="AcquireReadableStreamBYOBReader" id="acquire-readable-stream-byob-reader"
 export>AcquireReadableStreamBYOBReader(|stream|)</dfn> is meant to be called from other
 specifications that wish to acquire a [=BYOB reader=] for a given stream. It performs the following
 steps:

 1. Let |reader| be a [=new=] {{ReadableStreamBYOBReader}}.
 1. Perform ? [$SetUpReadableStreamBYOBReader$](|reader|, |stream|).
 1. Return |reader|.
</div>

<div algorithm>
 <dfn abstract-op lt="AcquireReadableStreamDefaultReader" id="acquire-readable-stream-reader"
 export>AcquireReadableStreamDefaultReader(|stream|)</dfn> is meant to be called from other
 specifications that wish to acquire a [=default reader=] for a given stream. It performs the
 following steps:

  1. Let |reader| be a [=new=] {{ReadableStreamDefaultReader}}.
  1. Perform [$SetUpReadableStreamDefaultReader$](|reader|, |stream|).
  1. Return |reader|.
</div>

<div algorithm>
 <dfn abstract-op lt="CreateReadableStream" id="create-readable-stream"
 export>CreateReadableStream(|startAlgorithm|, |pullAlgorithm|, |cancelAlgorithm|[,
 |highWaterMark|, [, |sizeAlgorithm|]])</dfn> is meant to be called from other specifications that
 wish to create {{ReadableStream}} instances. The |pullAlgorithm| and |cancelAlgorithm| algorithms
 must return promises; if supplied, |sizeAlgorithm| must be an algorithm accepting [=chunk=]
 objects and returning a number; and if supplied, |highWaterMark| must be a non-negative, non-NaN
 number.

 It performs the following steps:

 1. If |highWaterMark| was not passed, set it to 1.
 1. If |sizeAlgorithm| was not passed, set it to an algorithm that returns 1.
 1. Assert: ! [$IsNonNegativeNumber$](|highWaterMark|) is true.
 1. Let |stream| be a [=new=] {{ReadableStream}}.
 1. Perform ! [$InitializeReadableStream$](|stream|).
 1. Let |controller| be a [=new=] {{ReadableStreamDefaultController}}.
 1. Perform ? [$SetUpReadableStreamDefaultController$](|stream|, |controller|, |startAlgorithm|,
    |pullAlgorithm|, |cancelAlgorithm|, |highWaterMark|, |sizeAlgorithm|).
 1. Return |stream|.

 <p class="note">This abstract operation will throw an exception if and only if the supplied
 |startAlgorithm| throws.
</div>

<div algorithm>
 <dfn abstract-op lt="CreateReadableByteStream" id="create-readable-byte-stream"
 export>CreateReadableByteStream(|startAlgorithm|, |pullAlgorithm|, |cancelAlgorithm|[,
 |highWaterMark|, [, |autoAllocateChunkSize|]])</dfn> is meant to be called from other
 specifications that wish to create {{ReadableStream}} instances that represent [=readable byte
 streams=]. The |pullAlgorithm| and |cancelAlgorithm| algorithms must return promises; if supplied,
 |highWaterMark| must be a non-negative, non-NaN number, and, if supplied, |autoAllocateChunkSize|
 must be a positive integer.

 It performs the following steps:

 1. If |highWaterMark| was not passed, set it to 0.
 1. If |autoAllocateChunkSize| was not passed, set it to undefined.
 1. Assert: ! [$IsNonNegativeNumber$](|highWaterMark|) is true.
 1. If |autoAllocateChunkSize| is not undefined,
  1. Assert: ! [$IsInteger$](|autoAllocateChunkSize|) is true.
  1. Assert: |autoAllocateChunkSize| is positive.
 1. Let |stream| be a [=new=] {{ReadableStream}}.
 1. Perform ! [$InitializeReadableStream$](|stream|).
 1. Let |controller| be a [=new=] {{ReadableByteStreamController}}.
 1. Perform ? [$SetUpReadableByteStreamController$](|stream|, |controller|, |startAlgorithm|,
    |pullAlgorithm|, |cancelAlgorithm|, |highWaterMark|, |autoAllocateChunkSize|).
 1. Return |stream|.

 <p class="note">This abstract operation will throw an exception if and only if the supplied
 |startAlgorithm| throws.
</div>

<div algorithm>
 <dfn abstract-op lt="InitializeReadableStream"
 id="initialize-readable-stream">InitializeReadableStream(|stream|)</dfn> performs the following
 steps:

 1. Set |stream|.[=ReadableStream/[[state]]=] to "`readable`".
 1. Set |stream|.[=ReadableStream/[[reader]]=] and |stream|.[=ReadableStream/[[storedError]]=] to
    undefined.
 1. Set |stream|.[=ReadableStream/[[disturbed]]=] to false.
</div>

<div algorithm>
 <dfn abstract-op lt="IsReadableStreamDisturbed" id="is-readable-stream-disturbed"
 export>IsReadableStreamDisturbed(|stream|)</dfn> is meant to be called from other specifications
 that wish to query whether or not a readable stream has ever been read from or canceled. It
 performs the following steps:

 1. Return |stream|.[=ReadableStream/[[disturbed]]=].
</div>

<div algorithm>
 <dfn abstract-op lt="IsReadableStreamLocked" id="is-readable-stream-locked"
 export>IsReadableStreamLocked(|stream|)</dfn> is meant to be called from other specifications
 that wish to query whether or not a readable stream is [=locked to a reader=].

 1. If |stream|.[=ReadableStream/[[reader]]=] is undefined, return false.
 1. Return true.
</div>

<div algorithm="ReadableStreamPipeTo">
 <dfn abstract-op lt="ReadableStreamPipeTo" id="readable-stream-pipe-to"
 export>ReadableStreamPipeTo(|source|, |dest|, |preventClose|, |preventAbort|, |preventCancel|[,
 |signal|])</dfn> is meant to be called from other specifications that wish to [=piping|pipe=] a
 given readable stream to a destination [=writable stream=]. It performs the following steps:

 1. Assert: |source| [=implements=] {{ReadableStream}}.
 1. Assert: |dest| [=implements=] {{WritableStream}}.
 1. Assert: |preventClose|, |preventAbort|, and |preventCancel| are all booleans.
 1. If |signal| is not given, let |signal| be undefined.
 1. Assert: either |signal| is undefined, or |signal| [=implements=] {{AbortSignal}}.
 1. Assert: ! [$IsReadableStreamLocked$](|source|) is false.
 1. Assert: ! [$IsWritableStreamLocked$](|dest|) is false.
 1. If |source|.[=ReadableStream/[[controller]]=] [=implements=] {{ReadableByteStreamController}},
    let |reader| be either ! [$AcquireReadableStreamBYOBReader$](|source|) or !
    [$AcquireReadableStreamDefaultReader$](|source|), at the user agent's discretion.
 1. Otherwise, let |reader| be ! [$AcquireReadableStreamDefaultReader$](|source|).
 1. Let |writer| be ! [$AcquireWritableStreamDefaultWriter$](|dest|).
 1. Set |source|.[=ReadableStream/[[disturbed]]=] to true.
 1. Let |shuttingDown| be false.
 1. Let |promise| be [=a new promise=].
 1. If |signal| is not undefined,
  1. Let |abortAlgorithm| be the following steps:
   1. Let |error| be a new "{{AbortError}}" {{DOMException}}.
   1. Let |actions| be an empty [=ordered set=].
   1. If |preventAbort| is false, [=set/append=] the following action to |actions|:
     1. If |dest|.[=WritableStream/[[state]]=] is "`writable`", return !
        [$WritableStreamAbort$](|dest|, |error|).
     1. Otherwise, return [=a promise resolved with=] undefined.
   1. If |preventCancel| is false, [=set/append=] the following action action to |actions|:
     1. If |source|.[=ReadableStream/[[state]]=] is "`readable`", return !
        [$ReadableStreamCancel$](|source|, |error|).
     1. Otherwise, return [=a promise resolved with=] undefined.
   1. [=Shutdown with an action=] consisting of [=getting a promise to wait for all=] of the actions
      in |actions|, and with |error|.
  1. If |signal|'s [=AbortSignal/aborted flag=] is set, perform |abortAlgorithm| and return
     |promise|.
  1. [=AbortSignal/Add=] |abortAlgorithm| to |signal|.
 1. [=In parallel=] <span class="XXX">but not really; see <a
    href="https://github.com/whatwg/streams/issues/905">#905</a></span>, using |reader| and
    |writer|, read all [=chunks=] from |source| and write them to |dest|. Due to the locking
    provided by the reader and writer, the exact manner in which this happens is not observable to
    author code, and so there is flexibility in how this is done. The following constraints apply
    regardless of the exact algorithm used:
  * <strong>Public API must not be used:</strong> while reading or writing, or performing any of
    the operations below, the JavaScript-modifiable reader, writer, and stream APIs (i.e. methods
    on the appropriate prototypes) must not be used. Instead, the streams must be manipulated
    directly.
  * <strong>Backpressure must be enforced:</strong>
   * While [$WritableStreamDefaultWriterGetDesiredSize$](|writer|) is ≤ 0 or is null, the user
     agent must not read from |reader|.
   * If |reader| is a [=BYOB reader=], [$WritableStreamDefaultWriterGetDesiredSize$](|writer|)
     should be used as a basis to determine the size of the chunks read from |reader|.
     <p class="note">It's frequently inefficient to read chunks that are too small or too large.
     Other information might be factored in to determine the optimal chunk size.
   * Reads or writes should not be delayed for reasons other than these backpressure signals.
     <p class="example" id="example-bad-backpressure">An implementation that waits for each write
     to successfully complete before proceeding to the next read/write operation violates this
     recommendation. In doing so, such an implementation makes the [=internal queue=] of |dest|
     useless, as it ensures |dest| always contains at most one queued [=chunk=].
  * <strong>Shutdown must stop activity:</strong> if |shuttingDown| becomes true, the user agent
    must not initiate further reads from |reader|, and must only perform writes of already-read
    [=chunks=], as described below. In particular, the user agent must check the below conditions
    before performing any reads or writes, since they might lead to immediate shutdown.
  * <strong>Error and close states must be propagated:</strong> the following conditions must be
    applied in order.
   1. <strong>Errors must be propagated forward:</strong> if |source|.[=ReadableStream/[[state]]=]
      is or becomes "`errored`", then
    1. If |preventAbort| is false, [=shutdown with an action=] of ! [$WritableStreamAbort$](|dest|,
       |source|.[=ReadableStream/[[storedError]]=]) and with
       |source|.[=ReadableStream/[[storedError]]=].
    1. Otherwise, [=shutdown=] with |source|.[=ReadableStream/[[storedError]]=].
   1. <strong>Errors must be propagated backward:</strong> if |dest|.[=WritableStream/[[state]]=]
      is or becomes "`errored`", then
    1. If |preventCancel| is false, [=shutdown with an action=] of !
       [$ReadableStreamCancel$](|source|, |dest|.[=WritableStream/[[storedError]]=]) and with
       |dest|.[=WritableStream/[[storedError]]=].
    1. Otherwise, [=shutdown=] with |dest|.[=WritableStream/[[storedError]]=].
   1. <strong>Closing must be propagated forward:</strong> if |source|.[=ReadableStream/[[state]]=]
      is or becomes "`closed`", then
    1. If |preventClose| is false, [=shutdown with an action=] of !
       [$WritableStreamDefaultWriterCloseWithErrorPropagation$](|writer|).
    1. Otherwise, [=shutdown=].
   1. <strong>Closing must be propagated backward:</strong> if !
      [$WritableStreamCloseQueuedOrInFlight$](|dest|) is true or |dest|.[=WritableStream/[[state]]=]
      is "`closed`", then
    1. Assert: no [=chunks=] have been read or written.
    1. Let |destClosed| be a new {{TypeError}}.
    1. If |preventCancel| is false, [=shutdown with an action=] of !
       [$ReadableStreamCancel$](|source|, |destClosed|) and with |destClosed|.
    1. Otherwise, [=shutdown=] with |destClosed|.
  * <dfn id="rs-pipeTo-shutdown-with-action"><i>Shutdown with an action</i></dfn>: if any of the
    above requirements ask to shutdown with an action |action|, optionally with an error
    |originalError|, then:
   1. If |shuttingDown| is true, abort these substeps.
   1. Set |shuttingDown| to true.
   1. If |dest|.[=WritableStream/[[state]]=] is "`writable`" and !
      [$WritableStreamCloseQueuedOrInFlight$](|dest|) is false,
     1. If any [=chunks=] have been read but not yet written, write them to |dest|.
     1. Wait until every [=chunk=] that has been read has been written (i.e. the corresponding
        promises have settled).
   1. Let |p| be the result of performing |action|.
   1. [=Upon fulfillment=] of |p|, [=finalize=], passing along |originalError| if it was given.
   1. [=Upon rejection=] of |p| with reason |newError|, [=finalize=] with |newError|.
  * <dfn id="rs-pipeTo-shutdown"><i>Shutdown</i></dfn>: if any of the above requirements or steps
    ask to shutdown, optionally with an error |error|, then:
   1. If |shuttingDown| is true, abort these substeps.
   1. Set |shuttingDown| to true.
   1. If |dest|.[=WritableStream/[[state]]=] is "`writable`" and !
      [$WritableStreamCloseQueuedOrInFlight$](|dest|) is false,
    1. If any [=chunks=] have been read but not yet written, write them to |dest|.
    1. Wait until every [=chunk=] that has been read has been written (i.e. the corresponding
       promises have settled).
   1. [=Finalize=], passing along |error| if it was given.
  * <dfn id="rs-pipeTo-finalize"><i>Finalize</i></dfn>: both forms of shutdown will eventually ask
    to finalize, optionally with an error |error|, which means to perform the following steps:
   1. Perform ! [$WritableStreamDefaultWriterRelease$](|writer|).
   1. Perform ! [$ReadableStreamReaderGenericRelease$](|reader|).
   1. If |signal| is not undefined, [=AbortSignal/remove=] |abortAlgorithm| from |signal|.
   1. If |error| was given, [=reject=] |promise| with |error|.
   1. Otherwise, [=resolve=] |promise| with undefined.
 1. Return |promise|.
</div>

<p class="note">Various abstract operations performed here include object creation (often of
promises), which usually would require specifying a realm for the created object. However, because
of the locking, none of these objects can be observed by author code. As such, the realm used to
create them does not matter.

<div algorithm>
 <dfn abstract-op lt="ReadableStreamTee" id="readable-stream-tee" export>ReadableStreamTee(|stream|,
 |cloneForBranch2|)</dfn> is meant to be called from other specifications that wish to [=tee a
 readable stream|tee=] a given readable stream.

 The second argument, |cloneForBranch2|, governs whether or not the data from the original stream
 will be cloned (using HTML's [=serializable objects=] framework) before appearing in the second of
 the returned branches. This is useful for scenarios where both branches are to be consumed in such
 a way that they might otherwise interfere with each other, such as by [=transferable
 objects|transferring=] their [=chunks=]. However, it does introduce a noticeable asymmetry between
 the two branches, and limits the possible [=chunks=] to serializable ones. [[!HTML]]

 <p class="note">In this standard ReadableStreamTee is always called with |cloneForBranch2| set to
 false; other specifications pass true.

 It performs the following steps:

 1. Assert: |stream| [=implements=] {{ReadableStream}}.
 1. Assert: |cloneForBranch2| is a boolean.
 1. Let |reader| be ? [$AcquireReadableStreamDefaultReader$](|stream|).
 1. Let |reading| be false.
 1. Let |canceled1| be false.
 1. Let |canceled2| be false.
 1. Let |reason1| be undefined.
 1. Let |reason2| be undefined.
 1. Let |branch1| be undefined.
 1. Let |branch2| be undefined.
 1. Let |cancelPromise| be [=a new promise=].
 1. Let |pullAlgorithm| be the following steps:
  1. If |reading| is true, return [=a promise resolved with=] undefined.
  1. Set |reading| to true.
  1. Let |readRequest| be a [=read request=] with the following [=struct/items=]:
   : [=read request/chunk steps=], given |value|
   ::
    1. [=Queue a microtask=] to perform the following steps:
     1. Set |reading| to false.
     1. Let |value1| and |value2| be |value|.
     1. If |canceled2| is false and |cloneForBranch2| is true, set |value2| to ?
        [$StructuredDeserialize$](? [$StructuredSerialize$](|value2|), [=the current Realm=]).
     1. If |canceled1| is false, perform ?
        [$ReadableStreamDefaultControllerEnqueue$](|branch1|.[=ReadableStream/[[controller]]=],
        |value1|).
     1. If |canceled2| is false, perform ?
        [$ReadableStreamDefaultControllerEnqueue$](|branch2|.[=ReadableStream/[[controller]]=],
        |value2|).

    <p class="note">The microtask delay here is necessary because it takes at least a microtask to
    detect errors, when we use |reader|.[=ReadableStreamGenericReader/[[closedPromise]]=] below.
    We want errors in |stream| to error both branches immediately, so we cannot let successful
    synchronously-available reads happen ahead of asynchronously-available errors.

   : [=read request/close steps=]
   ::
    1. Set |reading| to false.
    1. If |canceled1| is false, perform !
       [$ReadableStreamDefaultControllerClose$](|branch1|.[=ReadableStream/[[controller]]=]).
    1. If |canceled2| is false, perform !
       [$ReadableStreamDefaultControllerClose$](|branch2|.[=ReadableStream/[[controller]]=]).
    1. [=Resolve=] |cancelPromise| with undefined.

   : [=read request/error steps=]
   ::
    1. Set |reading| to false.
  1. Perform ! [$ReadableStreamDefaultReaderRead$](|reader|, |readRequest|).
  1. Return [=a promise resolved with=] undefined.
 1. Let |cancel1Algorithm| be the following steps, taking a |reason| argument:
  1. Set |canceled1| to true.
  1. Set |reason1| to |reason|.
  1. If |canceled2| is true,
   1. Let |compositeReason| be ! [$CreateArrayFromList$](« |reason1|, |reason2| »).
   1. Let |cancelResult| be ! [$ReadableStreamCancel$](|stream|, |compositeReason|).
   1. [=Resolve=] |cancelPromise| with |cancelResult|.
  1. Return |cancelPromise|.
 1. Let |cancel2Algorithm| be the following steps, taking a |reason| argument:
  1. Set |canceled2| to true.
  1. Set |reason2| to |reason|.
  1. If |canceled1| is true,
   1. Let |compositeReason| be ! [$CreateArrayFromList$](« |reason1|, |reason2| »).
   1. Let |cancelResult| be ! [$ReadableStreamCancel$](|stream|, |compositeReason|).
   1. [=Resolve=] |cancelPromise| with |cancelResult|.
  1. Return |cancelPromise|.
 1. Let |startAlgorithm| be an algorithm that returns undefined.
 1. Set |branch1| to ! [$CreateReadableStream$](|startAlgorithm|, |pullAlgorithm|,
    |cancel1Algorithm|).
 1. Set |branch2| to ! [$CreateReadableStream$](|startAlgorithm|, |pullAlgorithm|,
    |cancel2Algorithm|).
 1. [=Upon rejection=] of |reader|.[=ReadableStreamGenericReader/[[closedPromise]]=] with reason
    |r|,
  1. Perform ! [$ReadableStreamDefaultControllerError$](|branch1|.[=ReadableStream/[[controller]]=],
     |r|).
  1. Perform ! [$ReadableStreamDefaultControllerError$](|branch2|.[=ReadableStream/[[controller]]=],
     |r|).
  1. [=Resolve=] |cancelPromise| with undefined.
 1. Return « |branch1|, |branch2| ».
</div>

<h4 id="rs-abstract-ops-used-by-controllers">Interfacing with controllers</h4>

In terms of specification factoring, the way that the {{ReadableStream}} class encapsulates the
behavior of both simple readable streams and [=readable byte streams=] into a single class is by
centralizing most of the potentially-varying logic inside the two controller classes,
{{ReadableStreamDefaultController}} and {{ReadableByteStreamController}}. Those classes define most
of the stateful internal slots and abstract operations for how a stream's [=internal queue=] is
managed and how it interfaces with its [=underlying source=] or [=underlying byte source=].

Each controller class defines two internal methods, which are called by the {{ReadableStream}}
algorithms:

<dl>
  <dt><dfn abstract-op lt="[[CancelSteps]]"
  for="ReadableStreamController">\[[CancelSteps]](<var ignore>reason</var>)</dfn>
  <dd>The controller's steps that run in reaction to the stream being [=cancel a readable
  stream|canceled=], used to clean up the state stored in the controller and inform the
  [=underlying source=].

  <dt><dfn abstract-op lt="[[PullSteps]]" for="ReadableStreamController">\[[PullSteps]](<var
  ignore>readRequest</var>)</dfn>
  <dd>The controller's steps that run when a [=default reader=] is read from, used to pull from the
  controller any queued [=chunks=], or pull from the [=underlying source=] to get more chunks.
</dl>

(These are defined as internal methods, instead of as abstract operations, so that they can be
called polymorphically by the {{ReadableStream}} algorithms, without having to branch on which type
of controller is present.)

The rest of this section concerns abstract operations that go in the other direction: they are
used by the controller implementations to affect their associated {{ReadableStream}} object. This
translates internal state changes of the controller into developer-facing results visible through
the {{ReadableStream}}'s public API.

<div algorithm>
 <dfn abstract-op lt="ReadableStreamAddReadIntoRequest"
 id="readable-stream-add-read-into-request">ReadableStreamAddReadIntoRequest(|stream|,
 |readRequest|)</dfn> performs the following steps:

 1. Assert: |stream|.[=ReadableStream/[[reader]]=] [=implements=] {{ReadableStreamBYOBReader}}.
 1. Assert: |stream|.[=ReadableStream/[[state]]=] is "`readable`" or "`closed`".
 1. [=list/Append=] |readRequest| to
    |stream|.[=ReadableStream/[[reader]]=].[=ReadableStreamBYOBReader/[[readIntoRequests]]=].
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamAddReadRequest"
 id="readable-stream-add-read-request">ReadableStreamAddReadRequest(|stream|, |readRequest|</dfn>
 performs the following steps:

 1. Assert: |stream|.[=ReadableStream/[[reader]]=] [=implements=] {{ReadableStreamDefaultReader}}.
 1. Assert: |stream|.[=ReadableStream/[[state]]=] is "`readable`".
 1. [=list/Append=] |readRequest| to
    |stream|.[=ReadableStream/[[reader]]=].[=ReadableStreamDefaultReader/[[readRequests]]=].
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamCancel" id="readable-stream-cancel"
 export>ReadableStreamCancel(|stream|, |reason|)</dfn> performs the following steps:

 1. Set |stream|.[=ReadableStream/[[disturbed]]=] to true.
 1. If |stream|.[=ReadableStream/[[state]]=] is "`closed`", return [=a promise resolved with=]
    undefined.
 1. If |stream|.[=ReadableStream/[[state]]=] is "`errored`", return [=a promise rejected with=]
    |stream|.[=ReadableStream/[[storedError]]=].
 1. Perform ! [$ReadableStreamClose$](|stream|).
 1. Let |sourceCancelPromise| be !
    |stream|.[=ReadableStream/[[controller]]=].[$ReadableStreamController/[[CancelSteps]]$](|reason|).
 1. Return the result of [=reacting=] to |sourceCancelPromise| with a fulfillment step that returns
    undefined.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamClose"
 id="readable-stream-close">ReadableStreamClose(|stream|)</dfn> performs the following steps:

 1. Assert: |stream|.[=ReadableStream/[[state]]=] is "`readable`".
 1. Set |stream|.[=ReadableStream/[[state]]=] to "`closed`".
 1. Let |reader| be |stream|.[=ReadableStream/[[reader]]=].
 1. If |reader| is undefined, return.
 1. If |reader| [=implements=] {{ReadableStreamDefaultReader}},
  1. [=list/For each=] |readRequest| of |reader|.[=ReadableStreamDefaultReader/[[readRequests]]=],
   1. Perform |readRequest|'s [=read request/close steps=].
  1. Set |reader|.[=ReadableStreamDefaultReader/[[readRequests]]=] to an empty [=list=].
 1. [=Resolve=] |reader|.[=ReadableStreamGenericReader/[[closedPromise]]=] with undefined.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamError" id="readable-stream-error">ReadableStreamError(|stream|,
 |e|)</dfn> performs the following steps:

 1. Assert: |stream|.[=ReadableStream/[[state]]=] is "`readable`".
 1. Set |stream|.[=ReadableStream/[[state]]=] to "`errored`".
 1. Set |stream|.[=ReadableStream/[[storedError]]=] to |e|.
 1. Let |reader| be |stream|.[=ReadableStream/[[reader]]=].
 1. If |reader| is undefined, return.
 1. If |reader| [=implements=] {{ReadableStreamDefaultReader}},
  1. [=list/For each=] |readRequest| of |reader|.[=ReadableStreamDefaultReader/[[readRequests]]=],
    1. Perform |readRequest|'s [=read request/error steps=], given |e|.
  1. Set |reader|.[=ReadableStreamDefaultReader/[[readRequests]]=] to a new empty [=list=].
 1. Otherwise,
   1. Assert: |reader| [=implements=] {{ReadableStreamBYOBReader}}.
   1. [=list/For each=] |readIntoRequest| of
      |reader|.[=ReadableStreamBYOBReader/[[readIntoRequests]]=],
    1. Perform |readIntoRequest|'s [=read-into request/error steps=], given |e|.
   1. Set |reader|.[=ReadableStreamBYOBReader/[[readIntoRequests]]=] to a new empty [=list=].
 1. [=Reject=] |reader|.[=ReadableStreamGenericReader/[[closedPromise]]=] with |e|.
 1. Set |reader|.[=ReadableStreamGenericReader/[[closedPromise]]=].\[[PromiseIsHandled]] to true.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamFulfillReadIntoRequest"
 id="readable-stream-fulfill-read-into-request">ReadableStreamFulfillReadIntoRequest(|stream|,
 |chunk|, |done|)</dfn> performs the following steps:

 1. Let |reader| be |stream|.[=ReadableStream/[[reader]]=].
 1. Assert: |reader|.[=ReadableStreamBYOBReader/[[readIntoRequests]]=] is not [=list/is
    empty|empty=].
 1. Let |readIntoRequest| be |reader|.[=ReadableStreamBYOBReader/[[readIntoRequests]]=][0].
 1. [=list/Remove=] |readIntoRequest| from
    |reader|.[=ReadableStreamBYOBReader/[[readIntoRequests]]=].
 1. If |done| is true, perform |readIntoRequest|'s [=read-into request/close steps=], given |chunk|.
 1. Otherwise, perform |readIntoRequest|'s [=read-into request/chunk steps=], given |chunk|.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamFulfillReadRequest"
 id="readable-stream-fulfill-read-request">ReadableStreamFulfillReadRequest(|stream|, |chunk|,
 |done|)</dfn> performs the following steps:

 1. Let |reader| be |stream|.[=ReadableStream/[[reader]]=].
 1. Assert: |reader|.[=ReadableStreamDefaultReader/[[readRequests]]=] is not [=list/is
    empty|empty=].
 1. Let |readRequest| be |reader|.[=ReadableStreamDefaultReader/[[readRequests]]=][0].
 1. [=list/Remove=] |readRequest| from |reader|.[=ReadableStreamDefaultReader/[[readRequests]]=].
 1. If |done| is true, perform |readRequest|'s [=read request/close steps=].
 1. Otherwise, perform |readRequest|'s [=read request/chunk steps=], given |chunk|.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamGetNumReadIntoRequests"
 id="readable-stream-get-num-read-into-requests">ReadableStreamGetNumReadIntoRequests(|stream|)</dfn>
 performs the following steps:

 1. Return
    |stream|.[=ReadableStream/[[reader]]=].[=ReadableStreamBYOBReader/[[readIntoRequests]]=]'s
    [=list/size=].
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamGetNumReadRequests"
 id="readable-stream-get-num-read-requests">ReadableStreamGetNumReadRequests(|stream|)</dfn>
 performs the following steps:

 1. Return |stream|.[=ReadableStream/[[reader]]=].[=ReadableStreamDefaultReader/[[readRequests]]=]'s
    [=list/size=].
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamHasBYOBReader"
 id="readable-stream-has-byob-reader">ReadableStreamHasBYOBReader(|stream|)</dfn> performs the
 following steps:

 1. Let |reader| be |stream|.[=ReadableStream/[[reader]]=].
 1. If |reader| is undefined, return false.
 1. If |reader| [=implements=] {{ReadableStreamBYOBReader}}, return true.
 1. Return false.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamHasDefaultReader"
 id="readable-stream-has-default-reader">ReadableStreamHasDefaultReader(|stream|)</dfn> performs the
 following steps:

 1. Let |reader| be |stream|.[=ReadableStream/[[reader]]=].
 1. If |reader| is undefined, return false.
 1. If |reader| [=implements=] {{ReadableStreamDefaultReader}}, return true.
 1. Return false.
</div>

<h4 id="rs-reader-abstract-ops">Readers</h4>

The following abstract operations support the implementation and manipulation of
{{ReadableStreamDefaultReader}} and {{ReadableStreamBYOBReader}} instances.

<div algorithm>
 <dfn abstract-op lt="ReadableStreamReaderGenericCancel"
 id="readable-stream-reader-generic-cancel">ReadableStreamReaderGenericCancel(|reader|,
 |reason|)</dfn> performs the following steps:

 1. Let |stream| be |reader|.[=ReadableStreamGenericReader/[[stream]]=].
 1. Assert: |stream| is not undefined.
 1. Return ! [$ReadableStreamCancel$](|stream|, |reason|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamReaderGenericInitialize"
 id="readable-stream-reader-generic-initialize">ReadableStreamReaderGenericInitialize(|reader|,
 |stream|)</dfn> performs the following steps:

 1. Set |reader|.[=ReadableStreamGenericReader/[[stream]]=] to |stream|.
 1. Set |stream|.[=ReadableStream/[[reader]]=] to |reader|.
 1. If |stream|.[=ReadableStream/[[state]]=] is "`readable`",
  1. Set |reader|.[=ReadableStreamGenericReader/[[closedPromise]]=] to [=a new promise=].
 1. Otherwise, if |stream|.[=ReadableStream/[[state]]=] is "`closed`",
  1. Set |reader|.[=ReadableStreamGenericReader/[[closedPromise]]=] to [=a promise resolved with=]
     undefined.
 1. Otherwise,
  1. Assert: |stream|.[=ReadableStream/[[state]]=] is "`errored`".
  1. Set |reader|.[=ReadableStreamGenericReader/[[closedPromise]]=] to [=a promise rejected with=]
     |stream|.[=ReadableStream/[[storedError]]=].
  1. Set |reader|.[=ReadableStreamGenericReader/[[closedPromise]]=].\[[PromiseIsHandled]] to true.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamReaderGenericRelease"
 id="readable-stream-reader-generic-release">ReadableStreamReaderGenericRelease(|reader|)</dfn>
 performs the following steps:

 1. Assert: |reader|.[=ReadableStreamGenericReader/[[stream]]=] is not undefined.
 1. Assert: |reader|.[=ReadableStreamGenericReader/[[stream]]=].[=ReadableStream/[[reader]]=] is
    |reader|.
 1. If |reader|.[=ReadableStreamGenericReader/[[stream]]=].[=ReadableStream/[[state]]=] is
    "`readable`", [=reject=] |reader|.[=ReadableStreamGenericReader/[[closedPromise]]=] with a
    {{TypeError}} exception.
 1. Otherwise, set |reader|.[=ReadableStreamGenericReader/[[closedPromise]]=] to [=a promise
    rejected with=] a {{TypeError}} exception.
 1. Set |reader|.[=ReadableStreamGenericReader/[[closedPromise]]=].\[[PromiseIsHandled]] to true.
 1. Set |reader|.[=ReadableStreamGenericReader/[[stream]]=].[=ReadableStream/[[reader]]=] to
    undefined.
 1. Set |reader|.[=ReadableStreamGenericReader/[[stream]]=] to undefined.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamBYOBReaderRead"
 id="readable-stream-byob-reader-read">ReadableStreamBYOBReaderRead(|reader|, |view|,
 |readIntoRequest|)</dfn> performs the following steps:

 1. Let |stream| be |reader|.[=ReadableStreamGenericReader/[[stream]]=].
 1. Assert: |stream| is not undefined.
 1. Set |stream|.[=ReadableStream/[[disturbed]]=] to true.
 1. If |stream|.[=ReadableStream/[[state]]=] is "`errored`", perform |readIntoRequest|'s [=read-into
    request/error steps=] given |stream|.[=ReadableStream/[[storedError]]=].
 1. Return ! [$ReadableByteStreamControllerPullInto$](|stream|.[=ReadableStream/[[controller]]=],
    |view|, |readIntoRequest|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamDefaultReaderRead"
 id="readable-stream-default-reader-read">ReadableStreamDefaultReaderRead(|reader|,
 |readRequest|)</dfn> performs the following steps:

 1. Let |stream| be |reader|.[=ReadableStreamGenericReader/[[stream]]=].
 1. Assert: |stream| is not undefined.
 1. Set |stream|.[=ReadableStream/[[disturbed]]=] to true.
 1. If |stream|.[=ReadableStream/[[state]]=] is "`closed`", perform |readRequest|'s [=read
    request/close steps=].
 1. Otherwise, if |stream|.[=ReadableStream/[[state]]=] is "`errored`", perform |readRequest|'s
    [=read request/error steps=] given |stream|.[=ReadableStream/[[storedError]]=].
 1. Otherwise,
  1. Assert: |stream|.[=ReadableStream/[[state]]=] is "`readable`".
  1. Perform !
     |stream|.[=ReadableStream/[[controller]]=].[$ReadableStreamController/[[PullSteps]]$](|readRequest|).
</div>

<div algorithm>
 <dfn abstract-op lt="SetUpReadableStreamBYOBReader"
 id="set-up-readable-stream-byob-reader">SetUpReadableStreamBYOBReader(|reader|, |stream|)</dfn>
 performs the following steps:

 1. If ! [$IsReadableStreamLocked$](|stream|) is true, throw a {{TypeError}} exception.
 1. If |stream|.[=ReadableStream/[[controller]]=] does not [=implement=]
    {{ReadableByteStreamController}}, throw a {{TypeError}} exception.
 1. Perform ! [$ReadableStreamReaderGenericInitialize$](|reader|, |stream|).
 1. Set |reader|.[=ReadableStreamBYOBReader/[[readIntoRequests]]=] to a new empty [=list=].
</div>

<div algorithm>
 <dfn abstract-op lt="SetUpReadableStreamDefaultReader"
 id="set-up-readable-stream-default-reader">SetUpReadableStreamDefaultReader(|reader|,
 |stream|)</dfn> performs the following steps:

 1. If ! [$IsReadableStreamLocked$](|stream|) is true, throw a {{TypeError}} exception.
 1. Perform ! [$ReadableStreamReaderGenericInitialize$](|reader|, |stream|).
 1. Set |reader|.[=ReadableStreamDefaultReader/[[readRequests]]=] to a new empty [=list=].
</div>

<h4 id="rs-default-controller-abstract-ops">Default controllers</h4>

The following abstract operations support the implementation of the
{{ReadableStreamDefaultController}} class.

<div algorithm>
 <dfn abstract-op lt="ReadableStreamDefaultControllerCallPullIfNeeded"
 id="readable-stream-default-controller-call-pull-if-needed">ReadableStreamDefaultControllerCallPullIfNeeded(|controller|)</dfn>
 performs the following steps:

 1. Let |shouldPull| be ! [$ReadableStreamDefaultControllerShouldCallPull$](|controller|).
 1. If |shouldPull| is false, return.
 1. If |controller|.[=ReadableStreamDefaultController/[[pulling]]=] is true,
  1. Set |controller|.[=ReadableStreamDefaultController/[[pullAgain]]=] to true.
  1. Return.
 1. Assert: |controller|.[=ReadableStreamDefaultController/[[pullAgain]]=] is false.
 1. Set |controller|.[=ReadableStreamDefaultController/[[pulling]]=] to true.
 1. Let |pullPromise| be the result of performing
    |controller|.[=ReadableStreamDefaultController/[[pullAlgorithm]]=].
 1. [=Upon fulfillment=] of |pullPromise|,
  1. Set |controller|.[=ReadableStreamDefaultController/[[pulling]]=] to false.
  1. If |controller|.[=ReadableStreamDefaultController/[[pullAgain]]=] is true,
   1. Set |controller|.[=ReadableStreamDefaultController/[[pullAgain]]=] to false.
   1. Perform ! [$ReadableStreamDefaultControllerCallPullIfNeeded$](|controller|).
 1. [=Upon rejection=] of |pullPromise| with reason |e|,
  1. Perform ! [$ReadableStreamDefaultControllerError$](|controller|, |e|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamDefaultControllerShouldCallPull"
 id="readable-stream-default-controller-should-call-pull">ReadableStreamDefaultControllerShouldCallPull(|controller|)</dfn>
 performs the following steps:

 1. Let |stream| be |controller|.[=ReadableStreamDefaultController/[[stream]]=].
 1. If ! [$ReadableStreamDefaultControllerCanCloseOrEnqueue$](|controller|) is false, return false.
 1. If |controller|.[=ReadableStreamDefaultController/[[started]]=] is false, return false.
 1. If ! [$IsReadableStreamLocked$](|stream|) is true and !
    [$ReadableStreamGetNumReadRequests$](|stream|) > 0, return true.
 1. Let |desiredSize| be ! [$ReadableStreamDefaultControllerGetDesiredSize$](|controller|).
 1. Assert: |desiredSize| is not null.
 1. If |desiredSize| > 0, return true.
 1. Return false.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamDefaultControllerClearAlgorithms"
 id="readable-stream-default-controller-clear-algorithms">ReadableStreamDefaultControllerClearAlgorithms(|controller|)</dfn>
 is called once the stream is closed or errored and the algorithms will not be executed any more. By
 removing the algorithm references it permits the [=underlying source=] object to be garbage
 collected even if the {{ReadableStream}} itself is still referenced.

 <p class="note">This is observable using <a href="https://github.com/tc39/proposal-weakrefs/">weak
 references</a>. See <a
 href="https://github.com/tc39/proposal-weakrefs/issues/31">tc39/proposal-weakrefs#31</a> for more
 detail.

 It performs the following steps:

 1. Set |controller|.[=ReadableStreamDefaultController/[[pullAlgorithm]]=] to undefined.
 1. Set |controller|.[=ReadableStreamDefaultController/[[cancelAlgorithm]]=] to undefined.
 1. Set |controller|.[=ReadableStreamDefaultController/[[strategySizeAlgorithm]]=] to undefined.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamDefaultControllerClose"
 id="readable-stream-default-controller-close"
 export>ReadableStreamDefaultControllerClose(|controller|)</dfn> can be called by other
 specifications that wish to close a readable stream, in the same way a developer-created stream
 would be closed by its associated controller object. Specifications should <em>not</em> do this to
 streams or controllers they did not create.

 It performs the following steps:

 1. If ! [$ReadableStreamDefaultControllerCanCloseOrEnqueue$](|controller|) is false, return.
 1. Let |stream| be |controller|.[=ReadableStreamDefaultController/[[stream]]=].
 1. Set |controller|.[=ReadableStreamDefaultController/[[closeRequested]]=] to true.
 1. If |controller|.[=ReadableStreamDefaultController/[[queue]]=] [=list/is empty=],
  1. Perform ! [$ReadableStreamDefaultControllerClearAlgorithms$](|controller|).
  1. Perform ! [$ReadableStreamClose$](|stream|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamDefaultControllerEnqueue"
 id="readable-stream-default-controller-enqueue"
 export>ReadableStreamDefaultControllerEnqueue(|controller|, |chunk|)</dfn> can be called by other
 specifications that wish to enqueue [=chunks=] in a readable stream, in the same way a developer
 would enqueue chunks using the stream's associated controller object. Specifications should
 <em>not</em> do this to streams or controllers they did not create.

 It performs the following steps:

 1. If ! [$ReadableStreamDefaultControllerCanCloseOrEnqueue$](|controller|) is false, return.
 1. Let |stream| be |controller|.[=ReadableStreamDefaultController/[[stream]]=].
 1. If ! [$IsReadableStreamLocked$](|stream|) is true and !
    [$ReadableStreamGetNumReadRequests$](|stream|) > 0, perform !
    [$ReadableStreamFulfillReadRequest$](|stream|, |chunk|, false).
 1. Otherwise,
  1. Let |result| be the result of performing
     |controller|.[=ReadableStreamDefaultController/[[strategySizeAlgorithm]]=], passing in |chunk|,
     and interpreting the result as a [=completion record=].
  1. If |result| is an abrupt completion,
   1. Perform ! [$ReadableStreamDefaultControllerError$](|controller|, |result|.\[[Value]]).
   1. Return |result|.
  1. Let |chunkSize| be |result|.\[[Value]].
  1. Let |enqueueResult| be [$EnqueueValueWithSize$](|controller|, |chunk|, |chunkSize|).
  1. If |enqueueResult| is an abrupt completion,
   1. Perform ! [$ReadableStreamDefaultControllerError$](|controller|, |enqueueResult|.\[[Value]]).
   1. Return |enqueueResult|.
 1. Perform ! [$ReadableStreamDefaultControllerCallPullIfNeeded$](|controller|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamDefaultControllerError"
 id="readable-stream-default-controller-error"
 export>ReadableStreamDefaultControllerError(|controller|, |e|)</dfn> can be called by other
 specifications that wish to move a readable stream to an errored state, in the same way a
 developer would error a stream using its associated controller object. Specifications should
 <em>not</em> do this to streams or controllers they did not create.

 It performs the following steps:

 1. Let |stream| be |controller|.[=ReadableStreamDefaultController/[[stream]]=].
 1. If |stream|.[=ReadableStream/[[state]]=] is not "`readable`", return.
 1. Perform ! [$ResetQueue$](|controller|).
 1. Perform ! [$ReadableStreamDefaultControllerClearAlgorithms$](|controller|).
 1. Perform ! [$ReadableStreamError$](|stream|, |e|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamDefaultControllerGetDesiredSize"
 id="readable-stream-default-controller-get-desired-size"
 export>ReadableStreamDefaultControllerGetDesiredSize(|controller|)</dfn> can be called by other
 specifications that wish to determine the [=desired size to fill a stream's internal queue|desired
 size to fill this stream's internal queue=], similar to how a developer would consult the
 {{ReadableStreamDefaultController/desiredSize}} property of the stream's associated controller
 object. Specifications should <em>not</em> use this on streams or controllers they did not create.

 It performs the following steps:

 1. Let |state| be
    |controller|.[=ReadableStreamDefaultController/[[stream]]=].[=ReadableStream/[[state]]=].
 1. If |state| is "`errored`", return null.
 1. If |state| is "`closed`", return 0.
 1. Return |controller|.[=ReadableStreamDefaultController/[[strategyHWM]]=] −
    |controller|.[=ReadableStreamDefaultController/[[queueTotalSize]]=].
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamDefaultControllerHasBackpressure"
 id="rs-default-controller-has-backpressure">ReadableStreamDefaultControllerHasBackpressure(|controller|)</dfn>
 is used in the implementation of {{TransformStream}}. It performs the following steps:

 1. If ! [$ReadableStreamDefaultControllerShouldCallPull$](|controller|) is true, return false.
 1. Otherwise, return true.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableStreamDefaultControllerCanCloseOrEnqueue"
 id="readable-stream-default-controller-can-close-or-enqueue">ReadableStreamDefaultControllerCanCloseOrEnqueue(|controller|)</dfn>
 performs the following steps:

 1. Let |state| be
    |controller|.[=ReadableStreamDefaultController/[[stream]]=].[=ReadableStream/[[state]]=].
 1. If |controller|.[=ReadableStreamDefaultController/[[closeRequested]]=] is false and |state| is
    "`readable`", return true.
 1. Otherwise, return false.

 <p class="note">The case where |controller|.[=ReadableStreamDefaultController/[[closeRequested]]=]
 is false, but |state| is not "`readable`", happens when the stream is errored via
 {{ReadableStreamDefaultController/error(e)|controller.error()}}, or when it is closed without its
 controller's {{ReadableStreamDefaultController/close()|controller.close()}} method ever being
 called: e.g., if the stream was closed by a call to
 {{ReadableStream/cancel(reason)|stream.cancel()}}.
</div>

<div algorithm>
 <dfn abstract-op lt="SetUpReadableStreamDefaultController"
 id="set-up-readable-stream-default-controller">SetUpReadableStreamDefaultController(|stream|,
 |controller|, |startAlgorithm|, |pullAlgorithm|, |cancelAlgorithm|, |highWaterMark|,
 |sizeAlgorithm|)</dfn> performs the following steps:

 1. Assert: |stream|.[=ReadableStream/[[controller]]=] is undefined.
 1. Set |controller|.[=ReadableStreamDefaultController/[[stream]]=] to |stream|.
 1. Perform ! [$ResetQueue$](|controller|).
 1. Set |controller|.[=ReadableStreamDefaultController/[[started]]=],
    |controller|.[=ReadableStreamDefaultController/[[closeRequested]]=],
    |controller|.[=ReadableStreamDefaultController/[[pullAgain]]=], and
    |controller|.[=ReadableStreamDefaultController/[[pulling]]=] to false.
 1. Set |controller|.[=ReadableStreamDefaultController/[[strategySizeAlgorithm]]=] to
    |sizeAlgorithm| and |controller|.[=ReadableStreamDefaultController/[[strategyHWM]]=] to
    |highWaterMark|.
 1. Set |controller|.[=ReadableStreamDefaultController/[[pullAlgorithm]]=] to |pullAlgorithm|.
 1. Set |controller|.[=ReadableStreamDefaultController/[[cancelAlgorithm]]=] to |cancelAlgorithm|.
 1. Set |stream|.[=ReadableStream/[[controller]]=] to |controller|.
 1. Let |startResult| be the result of performing |startAlgorithm|. (This might throw an exception.)
 1. Let |startPromise| be [=a promise resolved with=] |startResult|.
 1. [=Upon fulfillment=]  of |startPromise|,
  1. Set |controller|.[=ReadableStreamDefaultController/[[started]]=] to true.
  1. Assert: |controller|.[=ReadableStreamDefaultController/[[pulling]]=] is false.
  1. Assert: |controller|.[=ReadableStreamDefaultController/[[pullAgain]]=] is false.
  1. Perform ! [$ReadableStreamDefaultControllerCallPullIfNeeded$](|controller|).
 1. [=Upon rejection=] of |startPromise| with reason |r|,
  1. Perform ! [$ReadableStreamDefaultControllerError$](|controller|, |r|).
</div>

<div algorithm>
 <dfn abstract-op lt="SetUpReadableStreamDefaultControllerFromUnderlyingSource"
 id="set-up-readable-stream-default-controller-from-underlying-source">SetUpReadableStreamDefaultControllerFromUnderlyingSource(|stream|,
 |controller|, |underlyingSource|, |underlyingSourceDict|, |highWaterMark|, |sizeAlgorithm|)</dfn>
 performs the following steps:

 1. Let |controller| be a [=new=] {{ReadableStreamDefaultController}}.
 1. Let |startAlgorithm| be an algorithm that returns undefined.
 1. Let |pullAlgorithm| be an algorithm that returns [=a promise resolved with=] undefined.
 1. Let |cancelAlgorithm| be an algorithm that returns [=a promise resolved with=] undefined.
 1. If |underlyingSourceDict|["{{UnderlyingSource/start}}"] [=map/exists=], then set
    |startAlgorithm| to an algorithm which returns the result of [=invoking=]
    |underlyingSourceDict|["{{UnderlyingSource/start}}"] with argument list
    «&nbsp;|controller|&nbsp;» and [=callback this value=] |underlyingSource|.
 1. If |underlyingSourceDict|["{{UnderlyingSource/pull}}"] [=map/exists=], then set
    |pullAlgorithm| to an algorithm which returns the result of [=invoking=]
    |underlyingSourceDict|["{{UnderlyingSource/pull}}"] with argument list
    «&nbsp;|controller|&nbsp;» and [=callback this value=] |underlyingSource|.
 1. If |underlyingSourceDict|["{{UnderlyingSource/cancel}}"] [=map/exists=], then set
    |cancelAlgorithm| to an algorithm which takes an argument |reason| and returns the result of
    [=invoking=] |underlyingSourceDict|["{{UnderlyingSource/cancel}}"] with argument list
    «&nbsp;|reason|&nbsp;» and [=callback this value=] |underlyingSource|.
 1. Perform ? [$SetUpReadableStreamDefaultController$](|stream|, |controller|, |startAlgorithm|,
    |pullAlgorithm|, |cancelAlgorithm|, |highWaterMark|, |sizeAlgorithm|).
</div>

<h4 id="rbs-controller-abstract-ops">Byte stream controllers</h4>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerCallPullIfNeeded"
 id="readable-byte-stream-controller-call-pull-if-needed">ReadableByteStreamControllerCallPullIfNeeded(|controller|)</dfn>
 performs the following steps:

 1. Let |shouldPull| be ! [$ReadableByteStreamControllerShouldCallPull$](|controller|).
 1. If |shouldPull| is false, return.
 1. If |controller|.[=ReadableByteStreamController/[[pulling]]=] is true,
  1. Set |controller|.[=ReadableByteStreamController/[[pullAgain]]=] to true.
  1. Return.
 1. Assert: |controller|.[=ReadableByteStreamController/[[pullAgain]]=] is false.
 1. Set |controller|.[=ReadableByteStreamController/[[pulling]]=] to true.
 1. Let |pullPromise| be the result of performing
    |controller|.[=ReadableByteStreamController/[[pullAlgorithm]]=].
 1. [=Upon fulfillment=] of |pullPromise|,
  1. Set |controller|.[=ReadableByteStreamController/[[pulling]]=] to false.
  1. If |controller|.[=ReadableByteStreamController/[[pullAgain]]=] is true,
   1. Set |controller|.[=ReadableByteStreamController/[[pullAgain]]=] to false.
   1. Perform ! [$ReadableByteStreamControllerCallPullIfNeeded$](|controller|).
 1. [=Upon rejection=] of |pullPromise| with reason |e|,
  1. Perform ! [$ReadableByteStreamControllerError$](|controller|, |e|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerClearAlgorithms"
 id="readable-byte-stream-controller-clear-algorithms">ReadableByteStreamControllerClearAlgorithms(|controller|)</dfn>
 is called once the stream is closed or errored and the algorithms will not be executed any more. By
 removing the algorithm references it permits the [=underlying byte source=] object to be garbage
 collected even if the {{ReadableStream}} itself is still referenced.

 <p class="note">This is observable using <a href="https://github.com/tc39/proposal-weakrefs/">weak
 references</a>. See <a
 href="https://github.com/tc39/proposal-weakrefs/issues/31">tc39/proposal-weakrefs#31</a> for more
 detail.

 It performs the following steps:

 1. Set |controller|.[=ReadableByteStreamController/[[pullAlgorithm]]=] to undefined.
 1. Set |controller|.[=ReadableByteStreamController/[[cancelAlgorithm]]=] to undefined.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerClearPendingPullIntos"
 id="readable-byte-stream-controller-clear-pending-pull-intos">ReadableByteStreamControllerClearPendingPullIntos(|controller|)</dfn>
 performs the following steps:

 1. Perform ! [$ReadableByteStreamControllerInvalidateBYOBRequest$](|controller|).
 1. Set |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=] to a new empty [=list=].
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerClose"
 id="readable-byte-stream-controller-close">ReadableByteStreamControllerClose(|controller|)</dfn>
 performs the following steps:

 1. Let |stream| be |controller|.[=ReadableByteStreamController/[[stream]]=].
 1. If |controller|.[=ReadableByteStreamController/[[closeRequested]]=] is true or
    |stream|.[=ReadableStream/[[state]]=] is not "`readable`", return.
 1. If |controller|.[=ReadableByteStreamController/[[queueTotalSize]]=] > 0,
  1. Set |controller|.[=ReadableByteStreamController/[[closeRequested]]=] to true.
  1. Return.
 1. If |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=] is not empty,
  1. Let |firstPendingPullInto| be
     |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=][0].
  1. If |firstPendingPullInto|'s [=pull-into descriptor/bytes filled=] > 0,
   1. Let |e| be a new {{TypeError}} exception.
   1. Perform ! [$ReadableByteStreamControllerError$](|controller|, |e|).
   1. Throw |e|.
 1. Perform ! [$ReadableByteStreamControllerClearAlgorithms$](|controller|).
 1. Perform ! [$ReadableStreamClose$](|stream|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerCommitPullIntoDescriptor"
 id="readable-byte-stream-controller-commit-pull-into-descriptor">ReadableByteStreamControllerCommitPullIntoDescriptor(|stream|,
 |pullIntoDescriptor|)</dfn> performs the following steps:

 1. Assert: |stream|.[=ReadableStream/[[state]]=] is not "`errored`".
 1. Let |done| be false.
 1. If |stream|.[=ReadableStream/[[state]]=] is "`closed`",
  1. Assert: |pullIntoDescriptor|'s [=pull-into descriptor/bytes filled=] is 0.
  1. Set |done| to true.
 1. Let |filledView| be !
    [$ReadableByteStreamControllerConvertPullIntoDescriptor$](|pullIntoDescriptor|).
 1. If |pullIntoDescriptor|'s [=pull-into descriptor/reader type=] is "`default`",
  1. Perform ! [$ReadableStreamFulfillReadRequest$](|stream|, |filledView|, |done|).
 1. Otherwise,
  1. Assert: |pullIntoDescriptor|'s [=pull-into descriptor/reader type=] is "`byob`".
  1. Perform ! [$ReadableStreamFulfillReadIntoRequest$](|stream|, |filledView|, |done|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerConvertPullIntoDescriptor"
 id="readable-byte-stream-controller-convert-pull-into-descriptor">ReadableByteStreamControllerConvertPullIntoDescriptor(|pullIntoDescriptor|)</dfn>
 performs the following steps:

 1. Let |bytesFilled| be |pullIntoDescriptor|'s [=pull-into descriptor/bytes filled=].
 1. Let |elementSize| be |pullIntoDescriptor|'s [=pull-into descriptor/element size=].
 1. Assert: |bytesFilled| ≤ |pullIntoDescriptor|'s [=pull-into descriptor/byte length=].
 1. Assert: |bytesFilled| mod |elementSize| is 0.
 1. Return ! [$Construct$](|pullIntoDescriptor|'s [=pull-into descriptor/view constructor=], «
    |pullIntoDescriptor|'s [=pull-into descriptor/buffer=], |pullIntoDescriptor|'s [=pull-into
    descriptor/byte offset=], |bytesFilled| ÷ |elementSize| »).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerEnqueue"
 id="readable-byte-stream-controller-enqueue">ReadableByteStreamControllerEnqueue(|controller|,
 |chunk|)</dfn> performs the following steps:

 1. Let |stream| be |controller|.[=ReadableByteStreamController/[[stream]]=].
 1. If |controller|.[=ReadableByteStreamController/[[closeRequested]]=] is true or
    |stream|.[=ReadableStream/[[state]]=] is not "`readable`", return.
 1. Let |buffer| be |chunk|.\[[ViewedArrayBuffer]].
 1. Let |byteOffset| be |chunk|.\[[ByteOffset]].
 1. Let |byteLength| be |chunk|.\[[ByteLength]].
 1. Let |transferredBuffer| be ! [$TransferArrayBuffer$](|buffer|).
 1. If ! [$ReadableStreamHasDefaultReader$](|stream|) is true
  1. If ! [$ReadableStreamGetNumReadRequests$](|stream|) is 0,
   1. Perform ! [$ReadableByteStreamControllerEnqueueChunkToQueue$](|controller|,
      |transferredBuffer|, |byteOffset|, |byteLength|).
  1. Otherwise,
   1. Assert: |controller|.[=ReadableByteStreamController/[[queue]]=] [=list/is empty=].
   1. Let |transferredView| be ! [$Construct$]({{%Uint8Array%}}, « |transferredBuffer|,
      |byteOffset|, |byteLength| »).
   1. Perform ! [$ReadableStreamFulfillReadRequest$](|stream|, |transferredView|, false).
 1. Otherwise, if ! [$ReadableStreamHasBYOBReader$](|stream|) is true,
  1. Perform ! [$ReadableByteStreamControllerEnqueueChunkToQueue$](|controller|,
     |transferredBuffer|, |byteOffset|, |byteLength|).
  1. Perform ! [$ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue$](|controller|).
 1. Otherwise,
  1. Assert: ! [$IsReadableStreamLocked$](|stream|) is false.
  1. Perform ! [$ReadableByteStreamControllerEnqueueChunkToQueue$](|controller|,
     |transferredBuffer|, |byteOffset|, |byteLength|).
 1. Perform ! [$ReadableByteStreamControllerCallPullIfNeeded$](|controller|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerEnqueueChunkToQueue"
 id="readable-byte-stream-controller-enqueue-chunk-to-queue">ReadableByteStreamControllerEnqueueChunkToQueue(|controller|,
 |buffer|, |byteOffset|, |byteLength|)</dfn> performs the following steps:

 1. [=list/Append=] a new [=readable byte stream queue entry=] with [=readable byte stream queue
    entry/buffer=] |buffer|, [=readable byte stream queue entry/byte offset=] |byteOffset|, and
    [=readable byte stream queue entry/byte length=] |byteLength| to
    |controller|.[=ReadableByteStreamController/[[queue]]=].
 1. Set |controller|.[=ReadableByteStreamController/[[queueTotalSize]]=] to
    |controller|.[=ReadableByteStreamController/[[queueTotalSize]]=] + |byteLength|.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerError"
 id="readable-byte-stream-controller-error">ReadableByteStreamControllerError(|controller|,
 |e|)</dfn> performs the following steps:

 1. Let |stream| be |controller|.[=ReadableByteStreamController/[[stream]]=].
 1. If |stream|.[=ReadableStream/[[state]]=] is not "`readable`", return.
 1. Perform ! [$ReadableByteStreamControllerClearPendingPullIntos$](|controller|).
 1. Perform ! [$ResetQueue$](|controller|).
 1. Perform ! [$ReadableByteStreamControllerClearAlgorithms$](|controller|).
 1. Perform ! [$ReadableStreamError$](|stream|, |e|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerFillHeadPullIntoDescriptor"
 id="readable-byte-stream-controller-fill-head-pull-into-descriptor">ReadableByteStreamControllerFillHeadPullIntoDescriptor(|controller|,
 |size|, |pullIntoDescriptor|)</dfn> performs the following steps:

 1. Assert: either |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=]
    [=list/is empty=], or |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=][0]
    is |pullIntoDescriptor|.
 1. Perform ! [$ReadableByteStreamControllerInvalidateBYOBRequest$](|controller|).
 1. Set |pullIntoDescriptor|'s [=pull-into descriptor/bytes filled=] to [=pull-into
    descriptor/bytes filled=] + |size|.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerFillPullIntoDescriptorFromQueue"
 id="readable-byte-stream-controller-fill-pull-into-descriptor-from-queue">ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(|controller|,
 |pullIntoDescriptor|)</dfn> performs the following steps:

 1. Let |elementSize| be |pullIntoDescriptor|.\[[elementSize]].
 1. Let |currentAlignedBytes| be |pullIntoDescriptor|'s [=pull-into descriptor/bytes filled=] −
    (|pullIntoDescriptor|'s [=pull-into descriptor/bytes filled=] mod |elementSize|).
 1. Let |maxBytesToCopy| be min(|controller|.[=ReadableByteStreamController/[[queueTotalSize]]=],
    |pullIntoDescriptor|'s [=pull-into descriptor/byte length=] − |pullIntoDescriptor|'s [=pull-into
    descriptor/bytes filled=]).
 1. Let |maxBytesFilled| be |pullIntoDescriptor|'s [=pull-into descriptor/bytes filled=] +
    |maxBytesToCopy|.
 1. Let |maxAlignedBytes| be |maxBytesFilled| − (|maxBytesFilled| mod |elementSize|).
 1. Let |totalBytesToCopyRemaining| be |maxBytesToCopy|.
 1. Let |ready| be false.
 1. If |maxAlignedBytes| > |currentAlignedBytes|,
  1. Set |totalBytesToCopyRemaining| to |maxAlignedBytes| − |pullIntoDescriptor|'s [=pull-into
     descriptor/bytes filled=].
  1. Set |ready| to true.
 1. Let |queue| be |controller|.[=ReadableByteStreamController/[[queue]]=].
 1. [=While=] |totalBytesToCopyRemaining| > 0,
  1. Let |headOfQueue| be |queue|[0].
  1. Let |bytesToCopy| be min(|totalBytesToCopyRemaining|, |headOfQueue|'s [=readable byte stream
     queue entry/byte length=]).
  1. Let |destStart| be |pullIntoDescriptor|'s [=pull-into descriptor/byte offset=] +
     |pullIntoDescriptor|'s [=pull-into descriptor/bytes filled=].
  1. Perform ! [$CopyDataBlockBytes$](|pullIntoDescriptor|'s [=pull-into
     descriptor/buffer=].\[[ArrayBufferData]], |destStart|,
     |headOfQueue|'s [=readable byte stream queue entry/buffer=].\[[ArrayBufferData]],
     |headOfQueue|'s [=readable byte stream queue entry/byte offset=], |bytesToCopy|).
  1. If |headOfQueue|'s [=readable byte stream queue entry/byte length=] is |bytesToCopy|,
   1. [=list/Remove=] |queue|[0].
  1. Otherwise,
   1. Set |headOfQueue|'s [=readable byte stream queue entry/byte offset=] to |headOfQueue|'s
      [=readable byte stream queue entry/byte offset=] + |bytesToCopy|.
   1. Set |headOfQueue|'s [=readable byte stream queue entry/byte length=] to |headOfQueue|'s
      [=readable byte stream queue entry/byte length=] − |bytesToCopy|.
  1. Set |controller|.[=ReadableByteStreamController/[[queueTotalSize]]=] to
     |controller|.[=ReadableByteStreamController/[[queueTotalSize]]=] − |bytesToCopy|.
  1. Perform ! [$ReadableByteStreamControllerFillHeadPullIntoDescriptor$](|controller|,
     |bytesToCopy|, |pullIntoDescriptor|).
  1. Set |totalBytesToCopyRemaining| to |totalBytesToCopyRemaining| − |bytesToCopy|.
 1. If |ready| is false,
  1. Assert: |controller|.[=ReadableByteStreamController/[[queueTotalSize]]=] is 0.
  1. Assert: |pullIntoDescriptor|'s [=pull-into descriptor/bytes filled=] > 0.
  1. Assert: |pullIntoDescriptor|'s [=pull-into descriptor/bytes filled=] &lt;
     |pullIntoDescriptor|'s [=pull-into descriptor/element size=].
 1. Return |ready|.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerGetDesiredSize"
 id="readable-byte-stream-controller-get-desired-size">ReadableByteStreamControllerGetDesiredSize(|controller|)</dfn>
 performs the following steps:

 1. Let |state| be |controller|.[=ReadableByteStreamController/[[stream]]=].[=ReadableStream/[[state]]=].
 1. If |state| is "`errored`", return null.
 1. If |state| is "`closed`", return 0.
 1. Return |controller|.[=ReadableByteStreamController/[[strategyHWM]]=] −
    |controller|.[=ReadableByteStreamController/[[queueTotalSize]]=].
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerHandleQueueDrain"
 id="readable-byte-stream-controller-handle-queue-drain">ReadableByteStreamControllerHandleQueueDrain(|controller|)</dfn>
 performs the following steps:

 1. Assert: |controller|.[=ReadableByteStreamController/[[stream]]=].[=ReadableStream/[[state]]=] is
    "`readable`".
 1. If |controller|.[=ReadableByteStreamController/[[queueTotalSize]]=] is 0 and
    |controller|.[=ReadableByteStreamController/[[closeRequested]]=] is true,
  1. Perform ! [$ReadableByteStreamControllerClearAlgorithms$](|controller|).
  1. Perform ! [$ReadableStreamClose$](|controller|.[=ReadableByteStreamController/[[stream]]=]).
 1. Otherwise,
  1. Perform ! [$ReadableByteStreamControllerCallPullIfNeeded$](|controller|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerInvalidateBYOBRequest"
 id="readable-byte-stream-controller-invalidate-byob-request">ReadableByteStreamControllerInvalidateBYOBRequest(|controller|)</dfn>
 performs the following steps:

 1. If |controller|.[=ReadableByteStreamController/[[byobRequest]]=] is null, return.
 1. Set
    |controller|.[=ReadableByteStreamController/[[byobRequest]]=].[=ReadableStreamBYOBRequest/[[controller]]=]
    to undefined.
 1. Set
    |controller|.[=ReadableByteStreamController/[[byobRequest]]=].[=ReadableStreamBYOBRequest/[[view]]=]
    to null.
 1. Set |controller|.[=ReadableByteStreamController/[[byobRequest]]=] to null.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue"
 id="readable-byte-stream-controller-process-pull-into-descriptors-using-queue">ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(|controller|)</dfn>
 performs the following steps:

 1. Assert: |controller|.[=ReadableByteStreamController/[[closeRequested]]=] is false.
 1. [=While=] |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=] is not
    [=list/is empty|empty=],
  1. If |controller|.[=ReadableByteStreamController/[[queueTotalSize]]=] is 0, return.
  1. Let |pullIntoDescriptor| be
     |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=][0].
  1. If ! [$ReadableByteStreamControllerFillPullIntoDescriptorFromQueue$](|controller|,
     |pullIntoDescriptor|) is true,
   1. Perform ! [$ReadableByteStreamControllerShiftPendingPullInto$](|controller|).
   1. Perform !
      [$ReadableByteStreamControllerCommitPullIntoDescriptor$](|controller|.[=ReadableByteStreamController/[[stream]]=],
      |pullIntoDescriptor|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerPullInto"
 id="readable-byte-stream-controller-pull-into">ReadableByteStreamControllerPullInto(|controller|,
 |view|, |readIntoRequest|)</dfn> performs the following steps:

 1. Let |stream| be |controller|.[=ReadableByteStreamController/[[stream]]=].
 1. Let |elementSize| be 1.
 1. Let |ctor| be {{%DataView%}}.
 1. If |view| has a \[[TypedArrayName]] internal slot (i.e., it is not a {{DataView}}),
  1. Set |elementSize| to the element size specified in [=the typed array constructors table=] for
     |view|.\[[TypedArrayName]].
  1. Set |ctor| to the constructor specified in [=the typed array constructors table=] for
     |view|.\[[TypedArrayName]].
 1. Let |byteOffset| be |view|.\[[ByteOffset]].
 1. Let |byteLength| be |view|.\[[ByteLength]].
 1. Let |buffer| be ! [$TransferArrayBuffer$](|view|.\[[ViewedArrayBuffer]]).
 1. Let |pullIntoDescriptor| be a new [=pull-into descriptor=] with [=pull-into descriptor/buffer=]
    |buffer|, [=pull-into descriptor/byte offset=] |byteOffset|, [=pull-into descriptor/byte
    length=] |byteLength|, [=pull-into descriptor/bytes filled=] 0, [=pull-into descriptor/element
    size=] |elementSize|, [=pull-into descriptor/view constructor=] |ctor|, and [=pull-into
    descriptor/reader type=] "`byob`".
 1. If |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=] is not empty,
  1. [=list/Append=] |pullIntoDescriptor| to
     |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=].
  1. Perform ! [$ReadableStreamAddReadIntoRequest$](|stream|, |readIntoRequest|).
  1. Return.
 1. If |stream|.[=ReadableStream/[[state]]=] is "`closed`",
  1. Let |emptyView| be ! [$Construct$](|ctor|, « |pullIntoDescriptor|'s [=pull-into
     descriptor/buffer=], |pullIntoDescriptor|'s [=pull-into descriptor/byte offset=], 0 »).
  1. Perform |readIntoRequest|'s [=read-into request/close steps=], given |emptyView|.
  1. Return.
 1. If |controller|.[=ReadableByteStreamController/[[queueTotalSize]]=] > 0,
  1. If ! [$ReadableByteStreamControllerFillPullIntoDescriptorFromQueue$](|controller|,
     |pullIntoDescriptor|) is true,
   1. Let |filledView| be !
      [$ReadableByteStreamControllerConvertPullIntoDescriptor$](|pullIntoDescriptor|).
   1. Perform ! [$ReadableByteStreamControllerHandleQueueDrain$](|controller|).
   1. Perform |readIntoRequest|'s [=read-into request/chunk steps=], given |filledView|.
   1. Return.
  1. If |controller|.[=ReadableByteStreamController/[[closeRequested]]=] is true,
   1. Let |e| be a {{TypeError}} exception.
   1. Perform ! [$ReadableByteStreamControllerError$](|controller|, |e|).
   1. Perform |readIntoRequest|'s [=read-into request/error steps=], given |e|.
   1. Return.
 1. [=list/Append=] |pullIntoDescriptor| to
    |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=].
 1. Perform ! [$ReadableStreamAddReadIntoRequest$](|stream|, |readIntoRequest|).
 1. Perform ! [$ReadableByteStreamControllerCallPullIfNeeded$](|controller|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerRespond"
 id="readable-byte-stream-controller-respond">ReadableByteStreamControllerRespond(|controller|,
 |bytesWritten|)</dfn> performs the following steps:

 1. Assert: |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=] is not empty.
 1. Perform ? [$ReadableByteStreamControllerRespondInternal$](|controller|, |bytesWritten|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerRespondInClosedState"
 id="readable-byte-stream-controller-respond-in-closed-state">ReadableByteStreamControllerRespondInClosedState(|controller|,
 |firstDescriptor|)</dfn> performs the following steps:

 1. Set |firstDescriptor|'s [=pull-into descriptor/buffer=] to !
    [$TransferArrayBuffer$](|firstDescriptor|'s [=pull-into descriptor/buffer=]).
 1. Assert: |firstDescriptor|'s [=pull-into descriptor/bytes filled=] is 0.
 1. Let |stream| be |controller|.[=ReadableByteStreamController/[[stream]]=].
 1. If ! [$ReadableStreamHasBYOBReader$](|stream|) is true,
  1. [=While=] ! [$ReadableStreamGetNumReadIntoRequests$](|stream|) > 0,
   1. Let |pullIntoDescriptor| be !
      [$ReadableByteStreamControllerShiftPendingPullInto$](|controller|).
   1. Perform ! [$ReadableByteStreamControllerCommitPullIntoDescriptor$](|stream|,
      |pullIntoDescriptor|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerRespondInReadableState"
 id="readable-byte-stream-controller-respond-in-readable-state">ReadableByteStreamControllerRespondInReadableState(|controller|,
 |bytesWritten|, |pullIntoDescriptor|)</dfn> performs the following steps:

 1. If |pullIntoDescriptor|'s [=pull-into descriptor/bytes filled=] + |bytesWritten| >
    |pullIntoDescriptor|'s [=pull-into descriptor/byte length=], throw a {{RangeError}} exception.
 1. Perform ! [$ReadableByteStreamControllerFillHeadPullIntoDescriptor$](|controller|,
    |bytesWritten|, |pullIntoDescriptor|).
 1. If |pullIntoDescriptor|'s [=pull-into descriptor/bytes filled=] &lt; |pullIntoDescriptor|'s
    [=pull-into descriptor/element size=], return.
 1. Perform ! [$ReadableByteStreamControllerShiftPendingPullInto$](|controller|).
 1. Let |remainderSize| be |pullIntoDescriptor|'s [=pull-into descriptor/bytes filled=] mod
    |pullIntoDescriptor|'s [=pull-into descriptor/element size=].
 1. If |remainderSize| > 0,
   1. Let |end| be |pullIntoDescriptor|'s [=pull-into descriptor/byte offset=] +
      |pullIntoDescriptor|'s [=pull-into descriptor/bytes filled=].
   1. Let |remainder| be ? [$CloneArrayBuffer$](|pullIntoDescriptor|'s [=pull-into
      descriptor/buffer=], |end| − |remainderSize|, |remainderSize|, {{%ArrayBuffer%}}).
   1. Perform ! [$ReadableByteStreamControllerEnqueueChunkToQueue$](|controller|, |remainder|, 0,
      |remainder|.\[[ByteLength]]).
 1. Set |pullIntoDescriptor|'s [=pull-into descriptor/buffer=] to !
    [$TransferArrayBuffer$](|pullIntoDescriptor|'s [=pull-into descriptor/buffer=]).
 1. Set |pullIntoDescriptor|'s [=pull-into descriptor/bytes filled=] to |pullIntoDescriptor|'s
    [=pull-into descriptor/bytes filled=] − |remainderSize|.
 1. Perform !
    [$ReadableByteStreamControllerCommitPullIntoDescriptor$](|controller|.[=ReadableByteStreamController/[[stream]]=],
    |pullIntoDescriptor|).
 1. Perform ! [$ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue$](|controller|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerRespondInternal"
 id="readable-byte-stream-controller-respond-internal">ReadableByteStreamControllerRespondInternal(|controller|,
 |bytesWritten|)</dfn> performs the following steps:

 1. Let |firstDescriptor| be |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=][0].
 1. Let |state| be
    |controller|.[=ReadableByteStreamController/[[stream]]=].[=ReadableStream/[[state]]=].
 1. If |state| is "`closed`",
  1. If |bytesWritten| is not 0, throw a {{TypeError}} exception.
  1. Perform ! [$ReadableByteStreamControllerRespondInClosedState$](|controller|,
     |firstDescriptor|).
 1. Otherwise,
  1. Assert: |state| is "`readable`".
  1. Perform ? [$ReadableByteStreamControllerRespondInReadableState$](|controller|, |bytesWritten|,
     |firstDescriptor|).
 1. Perform ! [$ReadableByteStreamControllerCallPullIfNeeded$](|controller|).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerRespondWithNewView"
 id="readable-byte-stream-controller-respond-with-new-view">ReadableByteStreamControllerRespondWithNewView(|controller|,
 |view|)</dfn> performs the following steps:

 1. Assert: |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=] is not [=list/is
    empty|empty=].
 1. Let |firstDescriptor| be |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=][0].
 1. If |firstDescriptor|'s [=pull-into descriptor/byte offset=] + |firstDescriptor|' [=pull-into
    descriptor/bytes filled=] is not |view|.\[[ByteOffset]], throw a {{RangeError}} exception.
 1. If |firstDescriptor|'s [=pull-into descriptor/byte length=] is not |view|.\[[ByteLength]], throw
    a {{RangeError}} exception.
 1. Set |firstDescriptor|'s [=pull-into descriptor/buffer=] to |view|.\[[ViewedArrayBuffer]].
 1. Perform ? [$ReadableByteStreamControllerRespondInternal$](|controller|, |view|.\[[ByteLength]]).
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerShiftPendingPullInto"
 id="readable-byte-stream-controller-shift-pending-pull-into">ReadableByteStreamControllerShiftPendingPullInto(|controller|)</dfn>
 performs the following steps:

 1. Let |descriptor| be |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=][0].
 1. [=list/Remove=] |descriptor| from
    |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=].
 1. Perform ! [$ReadableByteStreamControllerInvalidateBYOBRequest$](|controller|).
 1. Return |descriptor|.
</div>

<div algorithm>
 <dfn abstract-op lt="ReadableByteStreamControllerShouldCallPull"
 id="readable-byte-stream-controller-should-call-pull">ReadableByteStreamControllerShouldCallPull(|controller|)</dfn>
 performs the following steps:

 1. Let |stream| be |controller|.[=ReadableByteStreamController/[[stream]]=].
 1. If |stream|.[=ReadableStream/[[state]]=] is not "`readable`", return false.
 1. If |controller|.[=ReadableByteStreamController/[[closeRequested]]=] is true, return false.
 1. If |controller|.[=ReadableByteStreamController/[[started]]=] is false, return false.
 1. If ! [$ReadableStreamHasDefaultReader$](|stream|) is true and !
    [$ReadableStreamGetNumReadRequests$](|stream|) > 0, return true.
 1. If ! [$ReadableStreamHasBYOBReader$](|stream|) is true and !
    [$ReadableStreamGetNumReadIntoRequests$](|stream|) > 0, return true.
 1. Let |desiredSize| be  ! [$ReadableByteStreamControllerGetDesiredSize$](|controller|).
 1. Assert: |desiredSize| is not null.
 1. If |desiredSize| > 0, return true.
 1. Return false.
</div>

<div algorithm>
 <dfn abstract-op lt="SetUpReadableByteStreamController"
 id="set-up-readable-byte-stream-controller">SetUpReadableByteStreamController(|stream|,
 |controller|, |startAlgorithm|, |pullAlgorithm|, |cancelAlgorithm|, |highWaterMark|,
 |autoAllocateChunkSize|)</dfn> performs the following steps:

 1. Assert: |stream|.[=ReadableStream/[[controller]]=] is undefined.
 1. If |autoAllocateChunkSize| is not undefined,
  1. Assert: ! IsInteger(|autoAllocateChunkSize|) is true.
  1. Assert: |autoAllocateChunkSize| is positive.
 1. Set |controller|.[=ReadableByteStreamController/[[stream]]=] to |stream|.
 1. Set |controller|.[=ReadableByteStreamController/[[pullAgain]]=] and
    |controller|.[=ReadableByteStreamController/[[pulling]]=] to false.
 1. Set |controller|.[=ReadableByteStreamController/[[byobRequest]]=] to null.
 1. Perform ! [$ResetQueue$](|controller|).
 1. Set |controller|.[=ReadableByteStreamController/[[closeRequested]]=] and
    |controller|.[=ReadableByteStreamController/[[started]]=] to false.
 1. Set |controller|.[=ReadableByteStreamController/[[strategyHWM]]=] to |highWaterMark|.
 1. Set |controller|.[=ReadableByteStreamController/[[pullAlgorithm]]=] to |pullAlgorithm|.
 1. Set |controller|.[=ReadableByteStreamController/[[cancelAlgorithm]]=] to |cancelAlgorithm|.
 1. Set |controller|.[=ReadableByteStreamController/[[autoAllocateChunkSize]]=] to
    |autoAllocateChunkSize|.
 1. Set |controller|.[=ReadableByteStreamController/[[pendingPullIntos]]=] to a new empty [=list=].
 1. Set |stream|.[=ReadableStream/[[controller]]=] to |controller|.
 1. Let |startResult| be the result of performing |startAlgorithm|.
 1. Let |startPromise| be [=a promise resolved with=] |startResult|.
 1. [=Upon fulfillment=]  of |startPromise|,
   1. Set |controller|.[=ReadableByteStreamController/[[started]]=] to true.
   1. Assert: |controller|.[=ReadableByteStreamController/[[pulling]]=] is false.
   1. Assert: |controller|.[=ReadableByteStreamController/[[pullAgain]]=] is false.
   1. Perform ! [$ReadableByteStreamControllerCallPullIfNeeded$](|controller|).
 1. [=Upon rejection=] of |startPromise| with reason |r|,
   1. Perform ! [$ReadableByteStreamControllerError$](|controller|, |r|).
</div>

<div algorithm>
 <dfn abstract-op lt="SetUpReadableByteStreamControllerFromUnderlyingSource"
 id="set-up-readable-byte-stream-controller-from-underlying-source">SetUpReadableByteStreamControllerFromUnderlyingSource(|stream|,
 |underlyingSource|, |underlyingSourceDict|, |highWaterMark|)</dfn> performs the following steps:

 1. Let |controller| be a [=new=] {{ReadableByteStreamController}}.
 1. Let |startAlgorithm| be an algorithm that returns undefined.
 1. Let |pullAlgorithm| be an algorithm that returns [=a promise resolved with=] undefined.
 1. Let |cancelAlgorithm| be an algorithm that returns [=a promise resolved with=] undefined.
 1. If |underlyingSourceDict|["{{UnderlyingSource/start}}"] [=map/exists=], then set
    |startAlgorithm| to an algorithm which returns the result of [=invoking=]
    |underlyingSourceDict|["{{UnderlyingSource/start}}"] with argument list
    «&nbsp;|controller|&nbsp;» and [=callback this value=] |underlyingSource|.
 1. If |underlyingSourceDict|["{{UnderlyingSource/pull}}"] [=map/exists=], then set
    |pullAlgorithm| to an algorithm which returns the result of [=invoking=]
    |underlyingSourceDict|["{{UnderlyingSource/pull}}"] with argument list
    «&nbsp;|controller|&nbsp;» and [=callback this value=] |underlyingSource|.
 1. If |underlyingSourceDict|["{{UnderlyingSource/cancel}}"] [=map/exists=], then set
    |cancelAlgorithm| to an algorithm which takes an argument |reason| and returns the result of
    [=invoking=] |underlyingSourceDict|["{{UnderlyingSource/cancel}}"] with argument list
    «&nbsp;|reason|&nbsp;» and [=callback this value=] |underlyingSource|.
 1. Let |autoAllocateChunkSize| be
    |underlyingSourceDict|["{{UnderlyingSource/autoAllocateChunkSize}}"], if it [=map/exists=], or
    undefined otherwise.
 1. Perform ? [$SetUpReadableByteStreamController$](|stream|, |controller|, |startAlgorithm|,
    |pullAlgorithm|, |cancelAlgorithm|, |highWaterMark|, |autoAllocateChunkSize|).
</div>
<h2 id="ws">Writable streams</h2>

<h3 id="ws-intro">Using writable streams</h3>

<div class="example" id="example-basic-pipe-to-2">
 The usual way to write to a writable stream is to simply [=piping|pipe=] a [=readable stream=] to
 it. This ensures that [=backpressure=] is respected, so that if the writable stream's [=underlying
 sink=] is not able to accept data as fast as the readable stream can produce it, the readable
 stream is informed of this and has a chance to slow down its data production.

 <xmp highlight="js">
 readableStream.pipeTo(writableStream)
   .then(() => console.log("All data successfully written!"))
   .catch(e => console.error("Something went wrong!", e));
 </xmp>
</div>

<div class="example" id="example-manual-write-batch">
 You can also write directly to writable streams by acquiring a [=writer=] and using its
 {{WritableStreamDefaultWriter/write()}} and {{WritableStreamDefaultWriter/close()}} methods. Since
 writable streams queue any incoming writes, and take care internally to forward them to the
 [=underlying sink=] in sequence, you can indiscriminately write to a writable stream without much
 ceremony:

 <xmp highlight="js">
 function writeArrayToStream(array, writableStream) {
   const writer = writableStream.getWriter();
   array.forEach(chunk => writer.write(chunk).catch(() => {}));

   return writer.close();
 }

 writeArrayToStream([1, 2, 3, 4, 5], writableStream)
   .then(() => console.log("All done!"))
   .catch(e => console.error("Error with the stream: " + e));
 </xmp>

 Note how we use <code>.catch(() => {})</code> to suppress any rejections from the
 {{WritableStreamDefaultWriter/write()}} method; we'll be notified of any fatal errors via a
 rejection of the {{WritableStreamDefaultWriter/close()}} method, and leaving them un-caught would
 cause potential {{unhandledrejection}} events and console warnings.
</div>

<div class="example" id="example-manual-write-with-error-handling">
 In the previous example we only paid attention to the success or failure of the entire stream, by
 looking at the promise returned by the writer's {{WritableStreamDefaultWriter/close()}} method.
 That promise will reject if anything goes wrong with the stream—initializing it, writing to it, or
 closing it. And it will fulfill once the stream is successfully closed. Often this is all you care
 about.

 However, if you care about the success of writing a specific [=chunk=], you can use the promise
 returned by the writer's {{WritableStreamDefaultWriter/write()}} method:

 <xmp highlight="js">
 writer.write("i am a chunk of data")
   .then(() => console.log("chunk successfully written!"))
   .catch(e => console.error(e));
 </xmp>

 What "success" means is up to a given stream instance (or more precisely, its [=underlying sink=])
 to decide. For example, for a file stream it could simply mean that the OS has accepted the write,
 and not necessarily that the chunk has been flushed to disk. Some streams might not be able to
 give such a signal at all, in which case the returned promise will fulfill immediately.
</div>

<div class="example" id="example-manual-write-with-backpressure">
 The {{WritableStreamDefaultWriter/desiredSize}} and {{WritableStreamDefaultWriter/ready}}
 properties of <a>writable stream writers</a> allow [=producers=] to more precisely respond to flow
 control signals from the stream, to keep memory usage below the stream's specified [=high water
 mark=]. The following example writes an infinite sequence of random bytes to a stream, using
 {{WritableStreamDefaultWriter/desiredSize}} to determine how many bytes to generate at a given
 time, and using {{WritableStreamDefaultWriter/ready}} to wait for the [=backpressure=] to subside.

 <xmp highlight="js">
 async function writeRandomBytesForever(writableStream) {
   const writer = writableStream.getWriter();

   while (true) {
     await writer.ready;

     const bytes = new Uint8Array(writer.desiredSize);
     crypto.getRandomValues(bytes);

     // Purposefully don't await; awaiting writer.ready is enough.
     writer.write(bytes).catch(() => {});
   }
 }

 writeRandomBytesForever(myWritableStream).catch(e => console.error("Something broke", e));
 </xmp>

 Note how we don't <code>await</code> the promise returned by
 {{WritableStreamDefaultWriter/write()}}; this would be redundant with <code>await</code>ing the
 {{WritableStreamDefaultWriter/ready}} promise. Additionally, similar to <a
 href="#example-manual-write-batch">a previous example</a>, we use the <code>.catch(() =>
 {})</code> pattern on the promises returned by {{WritableStreamDefaultWriter/write()}}; in this
 case we'll be notified about any failures
 <code>await</code>ing the {{WritableStreamDefaultWriter/ready}} promise.
</div>

<div class="example" id="example-manual-write-dont-await">
 To further emphasize how it's a bad idea to <code>await</code> the promise returned by
 {{WritableStreamDefaultWriter/write()}}, consider a modification of the above example, where we
 continue to use the {{WritableStreamDefaultWriter}} interface directly, but we don't control how
 many bytes we have to write at a given time. In that case, the [=backpressure=]-respecting code
 looks the same:

 <xmp highlight="js">
 async function writeSuppliedBytesForever(writableStream, getBytes) {
   const writer = writableStream.getWriter();

   while (true) {
     await writer.ready;

     const bytes = getBytes();
     writer.write(bytes).catch(() => {});
   }
 }
 </xmp>

 Unlike the previous example, where—because we were always writing exactly
 {{WritableStreamDefaultWriter/desiredSize|writer.desiredSize}} bytes each time—the
 {{WritableStreamDefaultWriter/write()}} and {{WritableStreamDefaultWriter/ready}} promises were
 synchronized, in this case it's quite possible that the {{WritableStreamDefaultWriter/ready}}
 promise fulfills before the one returned by {{WritableStreamDefaultWriter/write()}} does.
 Remember, the {{WritableStreamDefaultWriter/ready}} promise fulfills when the [=desired size to
 fill a stream's internal queue|desired size=] becomes positive, which might be before the write
 succeeds (especially in cases with a larger [=high water mark=]).

 In other words, <code>await</code>ing the return value of {{WritableStreamDefaultWriter/write()}}
 means you never queue up writes in the stream's [=internal queue=], instead only executing a write
 after the previous one succeeds, which can result in low throughput.
</div>

<h3 id="ws-class">The {{WritableStream}} class</h3>

The {{WritableStream}} represents a [=writable stream=].

<h4 id="ws-class-definition">Interface definition</h4>

The Web IDL definition for the {{WritableStream}} class is given as follows:

<xmp class="idl">
[Exposed=(Window,Worker,Worklet), Transferable]
interface WritableStream {
  constructor(optional object underlyingSink, optional QueuingStrategy strategy = {});

  readonly attribute boolean locked;

  Promise<void> abort(optional any reason);
  Promise<void> close();
  WritableStreamDefaultWriter getWriter();
};
</xmp>

<h4 id="ws-internal-slots">Internal slots</h4>

Instances of {{WritableStream}} are created with the internal slots described in the following
table:

<table dfn-for="WritableStream">
 <thead>
  <tr>
   <th>Internal Slot
   <th>Description (<em>non-normative</em>)
 <tbody>
  <tr>
  <td><dfn>\[[backpressure]]</dfn>
  <td class="non-normative">A boolean indicating the backpressure signal set by the controller
 <tr>
  <td><dfn>\[[closeRequest]]</dfn>
  <td class="non-normative">The promise returned from the writer's
  {{WritableStreamDefaultWriter/close()}} method
 <tr>
  <td><dfn>\[[controller]]</dfn>
  <td class="non-normative">A {{WritableStreamDefaultController}} created with the ability to
  control the state and queue of this stream
 <tr>
  <td><!-- TODO(ricea): Style this as <dfn unused> when that is supported --><b>\[[detached]]</b>
  <td class="non-normative">A boolean flag set to true when the stream is transferred
 <tr>
  <td><dfn>\[[inFlightWriteRequest]]</dfn>
  <td class="non-normative">A slot set to the promise for the current in-flight write operation
  while the [=underlying sink=]'s write algorithm is executing and has not yet fulfilled, used to
  prevent reentrant calls
 <tr>
  <td><dfn>\[[inFlightCloseRequest]]</dfn>
  <td class="non-normative">A slot set to the promise for the current in-flight close operation
  while the [=underlying sink=]'s close algorithm is executing and has not yet fulfilled, used to
  prevent the {{WritableStreamDefaultWriter/abort()}} method from interrupting close
 <tr>
  <td><dfn>\[[pendingAbortRequest]]</dfn>
  <td class="non-normative">A [=pending abort request=]
 <tr>
  <td><dfn>\[[state]]</dfn>
  <td class="non-normative">A string containing the stream's current state, used internally; one of
  "`writable`", "`closed`", "`erroring`", or "`errored`"
 <tr>
  <td><dfn>\[[storedError]]</dfn>
  <td class="non-normative">A value indicating how the stream failed, to be given as a failure
  reason or exception when trying to operate on the stream while in the "`errored`" state
 <tr>
  <td><dfn>\[[writer]]</dfn>
  <td class="non-normative">A {{WritableStreamDefaultWriter}} instance, if the stream is [=locked to
  a writer=], or undefined if it is not
 <tr>
  <td><dfn>\[[writeRequests]]</dfn>
  <td class="non-normative">A [=list=] of promises representing the stream's internal queue of write
  requests not yet processed by the [=underlying sink=]
</table>

<p class="note">The [=WritableStream/[[inFlightCloseRequest]]=] slot and
[=WritableStream/[[closeRequest]]=] slot are mutually exclusive. Similarly, no element will be
removed from [=WritableStream/[[writeRequests]]=] while [=WritableStream/[[inFlightWriteRequest]]=]
is not undefined. Implementations can optimize storage for these slots based on these invariants.

A <dfn>pending abort request</dfn> is a [=struct=] used to track a request to abort the stream
before that request is finally processed. It has the following [=struct/items=]:

: <dfn for="pending abort request">promise</dfn>
:: A promise returned from [$WritableStreamAbort$]
: <dfn for="pending abort request">reason</dfn>
:: A JavaScript value that was passed as the abort reason to [$WritableStreamAbort$]
: <dfn for="pending abort request">was already erroring</dfn>
:: A boolean indicating whether or not the stream was in the "`erroring`" state when
   [$WritableStreamAbort$] was called, which impacts the outcome of the abort request

<h4 id="underlying-sink-api">The underlying sink API</h4>

The {{WritableStream()}} constructor accepts as its first argument a JavaScript object representing
the [=underlying sink=]. Such objects can contain any of the following properties:

<xmp class="idl">
dictionary UnderlyingSink {
  UnderlyingSinkStartCallback start;
  UnderlyingSinkWriteCallback write;
  UnderlyingSinkCloseCallback close;
  UnderlyingSinkAbortCallback abort;
  any type;
};

callback UnderlyingSinkStartCallback = any (WritableStreamDefaultController controller);
callback UnderlyingSinkWriteCallback = Promise<void> (any chunk, WritableStreamDefaultController controller);
callback UnderlyingSinkCloseCallback = Promise<void> ();
callback UnderlyingSinkAbortCallback = Promise<void> (optional any reason);
</xmp>

<dl>
 <dt><dfn dict-member for="UnderlyingSink" lt="start">start(<var ignore>controller</var>)</dfn></dt>
 <dd>
  <p>A function that is called immediately during creation of the {{WritableStream}}.

  <p>Typically this is used to acquire access to the [=underlying sink=] resource being
  represented.

  <p>If this setup process is asynchronous, it can return a promise to signal success or failure; a
  rejected promise will error the stream. Any thrown exceptions will be re-thrown by the
  {{WritableStream()}} constructor.

  <dt><dfn dict-member for="UnderlyingSink" lt="write">write(<var ignore>chunk</var>,
  <var ignore>controller</var>)</dfn></dt>
  <dd>
   <p>A function that is called when a new [=chunk=] of data is ready to be written to the
   [=underlying sink=]. The stream implementation guarantees that this function will be called only
   after previous writes have succeeded, and never before {{UnderlyingSink/start|start()}} has
   succeeded or after {{UnderlyingSink/close|close()}} or {{UnderlyingSink/abort|abort()}} have
   been called.

   <p>This function is used to actually send the data to the resource presented by the [=underlying
   sink=], for example by calling a lower-level API.

   <p>If the process of writing data is asynchronous, and communicates success or failure signals
   back to its user, then this function can return a promise to signal success or failure. This
   promise return value will be communicated back to the caller of
   {{WritableStreamDefaultWriter/write()|writer.write()}}, so they can monitor that individual
   write. Throwing an exception is treated the same as returning a rejected promise.

   <p>Note that such signals are not always available; compare e.g. [[#example-ws-no-backpressure]]
   with [[#example-ws-backpressure]]. In such cases, it's best to not return anything.

   <p>The promise potentially returned by this function also governs whether the given chunk counts
   as written for the purposes of computed the [=desired size to fill a stream's internal
   queue|desired size to fill the stream's internal queue=]. That is, during the time it takes the
   promise to settle, {{WritableStreamDefaultWriter/desiredSize|writer.desiredSize}} will stay at
   its previous value, only increasing to signal the desire for more chunks once the write
   succeeds.

  <dt><dfn dict-member for="UnderlyingSink" lt="close">close()</dfn></dt>
  <dd>
   <p>A function that is called after the [=producer=] signals, via
   {{WritableStreamDefaultWriter/close()|writer.close()}}, that they are done writing [=chunks=] to
   the stream, and subsequently all queued-up writes have successfully completed.

   <p>This function can perform any actions necessary to finalize or flush writes to the
   [=underlying sink=], and release access to any held resources.

   <p>If the shutdown process is asynchronous, the function can return a promise to signal success
   or failure; the result will be communicated via the return value of the called
   {{WritableStreamDefaultWriter/close()|writer.close()}} method. Additionally, a rejected promise
   will error the stream, instead of letting it close successfully. Throwing an exception is
   treated the same as returning a rejected promise.

  <dt><dfn dict-member for="UnderlyingSink" lt="abort">abort(<var ignore>reason</var>)</dfn></dt>
  <dd>
   <p>A function that is called after the [=producer=] signals, via
   {{WritableStream/abort()|stream.abort()}} or
   {{WritableStreamDefaultWriter/abort()|writer.abort()}}, that they wish to [=abort a writable
   stream|abort=] the stream. It takes as its argument the same value as was passed to those
   methods by the producer.

   <p>Writable streams can additionally be aborted under certain conditions during [=piping=]; see
   the definition of the {{ReadableStream/pipeTo()}} method for more details.

   <p>This function can clean up any held resources, much like {{UnderlyingSink/close|close()}},
   but perhaps with some custom handling.

   <p>If the shutdown process is asynchronous, the function can return a promise to signal success
   or failure; the result will be communicated via the return value of the called
   {{WritableStreamDefaultWriter/abort()|writer.abort()}} method. Throwing an exception is treated
   the same as returning a rejected promise. Regardless, the stream will be errored with a new
   {{TypeError}} indicating that it was aborted.

  <dt><dfn dict-member for="UnderlyingSink">type</dfn></dt>
  <dd>
   <p>This property is reserved for future use, so any attempts to supply a value will throw an
   exception.
</dl>

The <code>controller</code> argument passed to {{UnderlyingSink/start|start()}} and
{{UnderlyingSink/write|write()}} is an instance of {{WritableStreamDefaultController}}, and has the
ability to error the stream. This is mainly used for bridging the gap with non-promise-based APIs,
as seen for example in [[#example-ws-no-backpressure]].

<h4 id="ws-prototype">Constructor, methods, and properties</h4>

<dl class="domintro non-normative">
 <dt><code><var ignore>stream</var> = new {{WritableStream/constructor(underlyingSink, strategy)|WritableStream}}(<var ignore>underlyingSink</var>[, <var ignore>strategy</var>)</code>
  <dd>
   <p>Creates a new {{WritableStream}} wrapping the provided [=underlying sink=]. See
   [[#underlying-sink-api]] for more details on the <var ignore>underlyingSink</var> argument.

   <p>The |strategy| argument represents the stream's [=queuing strategy=], as described in
   [[#qs-api]]. If it is not provided, the default behavior will be the same as a
   {{CountQueuingStrategy}} with a [=high water mark=] of 1.

 <dt><code><var ignore>isLocked</var> = <var ignore>stream</var>.{{WritableStream/locked}}</code>
 <dd>
  <p>Returns whether or not the writable stream is [=locked to a writer=].

 <dt><code>await <var ignore>stream</var>.{{WritableStream/abort(reason)|abort}}([ <var ignore>reason</var> ])</code>
 <dd>
  <p>[=abort a writable stream|Aborts=] the stream, signaling that the producer can no longer
  successfully write to the stream and it is to be immediately moved to an errored state, with any
  queued-up writes discarded. This will also execute any abort mechanism of the [=underlying
  sink=].

  <p>The returned promise will fulfill if the stream shuts down successfully, or reject if the
  underlying sink signaled that there was an error doing so. Additionally, it will reject with a
  {{TypeError}} (without attempting to cancel the stream) if the stream is currently [=locked to a
  writer|locked=].

 <dt><code>await <var ignore>stream</var>.{{WritableStream/close()|close}}()</code>
 <dd>
  <p>Closes the stream. The [=underlying sink=] will finish processing any previously-written
  [=chunks=], before invoking its close behavior. During this time any further attempts to write
  will fail (without erroring the stream).

  <p>The method returns a promise that will fulfill if all remaining [=chunks=] are successfully
  written and the stream successfully closes, or rejects if an error is encountered during this
  process. Additionally, it will reject with a {{TypeError}} (without attempting to cancel the
  stream) if the stream is currently [=locked to a writer|locked=].

 <dt><code><var ignore>writer</var> = <var ignore>stream</var>.{{WritableStream/getWriter()|getWriter}}()</code>
 <dd>
  <p>Creates a [=writer=] (an instance of {{WritableStreamDefaultWriter}}) and [=locked to a
  writer|locks=] the stream to the new writer. While the stream is locked, no other writer can be
  acquired until this one is [=release a write lock|released=].

  <p>This functionality is especially useful for creating abstractions that desire the ability to
  write to a stream without interruption or interleaving. By getting a writer for the stream, you
  can ensure nobody else can write at the same time, which would cause the resulting written data
  to be unpredictable and probably useless.
</dl>

<div algorithm>
 The <dfn id="ws-constructor" constructor for="WritableStream" lt="WritableStream(underlyingSink,
 strategy)">new WritableStream(|underlyingSink|, |strategy|)</dfn> constructor steps are:

 1. If |underlyingSink| is missing, set it to null.
 1. Let |underlyingSinkDict| be |underlyingSink|, [=converted to an IDL value=] of type
    {{UnderlyingSink}}.
    <p class="note">We cannot declare the |underlyingSink| argument as having the {{UnderlyingSink}}
    type directly, because doing so would lose the reference to the original object. We need to
    retain the object so we can [=invoke=] the various methods on it.
 1. If |underlyingSinkDict|["{{UnderlyingSink/type}}"] [=map/exists=], throw a {{RangeError}}
    exception.
    <p class="note">This is to allow us to add new potential types in the future, without
    backward-compatibility concerns.
 1. Perform ! [$InitializeWritableStream$]([=this=]).
 1. Let |sizeAlgorithm| be ! [$ExtractSizeAlgorithm$](|strategy|).
 1. Let |highWaterMark| be ? [$ExtractHighWaterMark$](|strategy|, 1).
 1. Perform ? [$SetUpWritableStreamDefaultControllerFromUnderlyingSink$]([=this=], |underlyingSink|,
    |underlyingSinkDict|, |highWaterMark|, |sizeAlgorithm|).
</div>

<div algorithm>
 The <dfn id="ws-locked" attribute for="WritableStream">locked</dfn> getter steps are:

 1. Return ! [$IsWritableStreamLocked$]([=this=]).
</div>

<div algorithm>
 The <dfn id="ws-abort" method for="WritableStream">abort(|reason|)</dfn> method steps are:

 1. If ! [$IsWritableStreamLocked$]([=this=]) is true, return [=a promise rejected with=] a
    {{TypeError}} exception.
 1. Return ! [$WritableStreamAbort$]([=this=], |reason|).
</div>

<div algorithm>
 The <dfn id="ws-close" method for="WritableStream">close()</dfn> method steps are:

 1. If ! [$IsWritableStreamLocked$]([=this=]) is true, return [=a promise rejected with=] a
    {{TypeError}} exception.
 1. If ! [$WritableStreamCloseQueuedOrInFlight$]([=this=]) is true, return [=a promise rejected
    with=] a {{TypeError}} exception.
 1. Return ! [$WritableStreamClose$]([=this=]).
</div>

<div algorithm>
 The <dfn id="ws-get-writer" method for="WritableStream">getWriter()</dfn> method steps are:

 1. Return ? [$AcquireWritableStreamDefaultWriter$]([=this=]).
</div>

<h4 id="ws-transfer">Transfer via `postMessage()`</h4>

<dl class="domintro">
 <dt><code>destination.postMessage(ws, { transfer: [ws] });</code>
 <dd>
  <p>Sends a {{WritableStream}} to another frame, window, or worker.

  <p>The transferred stream can be used exactly like the original. The original will become
  [=locked to a writer|locked=] and no longer directly usable.
 </dd>
</dl>

<div algorithm="WritableStream transfer steps">
 {{WritableStream}} objects are [=transferable objects=]. Their [=transfer steps=], given |value|
 and |dataHolder|, are:

 1. If ! [$IsWritableStreamLocked$](|value|) is true, throw a "{{DataCloneError}}" {{DOMException}}.
 1. Let |port1| be a [=new=] {{MessagePort}} in [=the current Realm=].
 1. Let |port2| be a [=new=] {{MessagePort}} in [=the current Realm=].
 1. [=Entangle=] |port1| and |port2|.
 1. Let |readable| be a [=new=] {{ReadableStream}} in [=the current Realm=].
 1. Perform ! [$SetUpCrossRealmTransformReadable$](|readable|, |port1|).
 1. Let |promise| be ! [$ReadableStreamPipeTo$](|readable|, |value|, false, false, false).
 1. Set |promise|.\[[PromiseIsHandled]] to true.
 1. Set |dataHolder|.\[[port]] to ! [$StructuredSerializeWithTransfer$](|port2|, « |port2| »).
</div>

<div algorithm="WritableStream transfer-receiving steps">
 Their [=transfer-receiving steps=], given |dataHolder| and |value|, are:

 1. Let |deserializedRecord| be ! [$StructuredDeserializeWithTransfer$](|dataHolder|.\[[port]],
    [=the current Realm=]).
 1. Let |port| be a |deserializedRecord|.\[[Deserialized]].
 1. Perform ! [$SetUpCrossRealmTransformWritable$](|value|, |port|).
</div>

<h3 id="default-writer-class">The {{WritableStreamDefaultWriter}} class</h3>

The {{WritableStreamDefaultWriter}} class represents a [=writable stream writer=] designed to be
vended by a {{WritableStream}} instance.

<h4 id="default-writer-class-definition">Interface definition</h4>

The Web IDL definition for the {{WritableStreamDefaultWriter}} class is given as follows:

<xmp class="idl">
[Exposed=(Window,Worker,Worklet)]
interface WritableStreamDefaultWriter {
  constructor(WritableStream stream);

  readonly attribute Promise<void> closed;
  readonly attribute unrestricted double? desiredSize;
  readonly attribute Promise<void> ready;

  Promise<void> abort(optional any reason);
  Promise<void> close();
  void releaseLock();
  Promise<void> write(optional any chunk);
};
</xmp>

<h4 id="default-writer-internal-slots">Internal slots</h4>

Instances of {{WritableStreamDefaultWriter}} are created with the internal slots described in the
following table:

<table dfn-for="WritableStreamDefaultWriter">
 <thead>
  <tr>
   <th>Internal Slot
   <th>Description (<em>non-normative</em>)
 <tbody>
  <tr>
   <td><dfn>\[[closedPromise]]</dfn>
   <td class="non-normative">A promise returned by the writer's
   {{WritableStreamDefaultWriter/closed}} getter
  <tr>
   <td><dfn>\[[readyPromise]]</dfn>
   <td class="non-normative">A promise returned by the writer's
   {{WritableStreamDefaultWriter/ready}} getter
  <tr>
   <td><dfn>\[[stream]]</dfn>
   <td class="non-normative">A {{WritableStream}} instance that owns this reader
</table>

<h4 id="default-writer-prototype">Constructor, methods, and properties</h4>

<dl class="domintro non-normative">
 <dt><code><var ignore>writer</var> = new {{WritableStreamDefaultWriter(stream)|WritableStreamDefaultWriter}}(|stream|)</code>
  <dd>
   <p>This is equivalent to calling <code>|stream|.{{WritableStream/getWriter()}}</code>.

 <dt><code>await <var ignore>writer</var>.{{WritableStreamDefaultWriter/closed}}</code>
 <dd>
  <p>Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the
  stream ever errors or the writer's lock is [=release a write lock|released=] before the stream
  finishes closing.

 <dt><code><var ignore>desiredSize</var> = <var ignore>writer</var>.{{WritableStreamDefaultWriter/desiredSize}}</code>
 <dd>
  <p>Returns the [=desired size to fill a stream's internal queue|desired size to fill the stream's
  internal queue=]. It can be negative, if the queue is over-full. A [=producer=] can use this
  information to determine the right amount of data to write.

  <p>It will be null if the stream cannot be successfully written to (due to either being errored,
  or having an abort queued up). It will return zero if the stream is closed. And the getter will
  throw an exception if invoked when the writer's lock is [=release a write lock|released=].

 <dt><code>await <var ignore>writer</var>.{{WritableStreamDefaultWriter/ready}}</code>
 <dd>
  <p>Returns a promise that will be fulfilled when the [=desired size to fill a stream's internal
  queue|desired size to fill the stream's internal queue=] transitions from non-positive to
  positive, signaling that it is no longer applying [=backpressure=]. Once the [=desired size to
  fill a stream's internal queue|desired size=] dips back to zero or below, the getter will return
  a new promise that stays pending until the next transition.

  <p>If the stream becomes errored or aborted, or the writer's lock is [=release a write
  lock|released=], the returned promise will become rejected.

 <dt><code>await <var ignore>writer</var>.{{WritableStreamDefaultWriter/abort(reason)|abort}}([ <var ignore>reason</var> ])</code>
 <dd>
  <p>If the reader is [=active writer|active=], behaves the same as
  <code>|stream|.{{WritableStream/abort(reason)|abort}}(<var ignore>reason</var>)</code>.

 <dt><code>await <var ignore>writer</var>.{{WritableStreamDefaultWriter/close()|close}}()</code>
 <dd>
  <p>If the reader is [=active writer|active=], behaves the same as
  <code>|stream|.{{WritableStream/close()|close}}()</code>.

 <dt><code><var ignore>writer</var>.{{WritableStreamDefaultWriter/releaseLock()|releaseLock}}()</code>
 <dd>
  <p>[=release a write lock|Releases the writer's lock=] on the corresponding stream. After the lock
  is released, the writer is no longer [=active writer|active=]. If the associated stream is errored
  when the lock is released, the writer will appear errored in the same way from now on; otherwise,
  the writer will appear closed.

  <p>Note that the lock can still be released even if some ongoing writes have not yet finished
  (i.e. even if the promises returned from previous calls to
  {{WritableStreamDefaultWriter/write()}} have not yet settled). It's not necessary to hold the
  lock on the writer for the duration of the write; the lock instead simply prevents other
  [=producers=] from writing in an interleaved manner.

 <dt><code>await <var ignore>writer</var>.{{WritableStreamDefaultWriter/write(chunk)|write}}(<var ignore>chunk</var>)</code>
 <dd>
  <p>Writes the given [=chunk=] to the writable stream, by waiting until any previous writes have
  finished successfully, and then sending the [=chunk=] to the [=underlying sink=]'s
  {{UnderlyingSink/write|write()}} method. It will return a promise that fulfills with undefined
  upon a successful write, or rejects if the write fails or stream becomes errored before the
  writing process is initiated.

  <p>Note that what "success" means is up to the [=underlying sink=]; it might indicate simply that
  the [=chunk=] has been accepted, and not necessarily that it is safely saved to its ultimate
  destination.
</dl>

<div algorithm>
 The <dfn id="default-writer-constructor" constructor for="WritableStreamDefaultWriter"
 lt="WritableStreamDefaultWriter(stream)">new WritableStreamDefaultWriter(|stream|)</dfn>
 constructor steps are:

 1. Perform ? [$SetUpWritableStreamDefaultWriter$]([=this=], |stream|).
</div>

<div algorithm>
 The <dfn id="default-writer-closed" attribute for="WritableStreamDefaultWriter">closed</dfn>
 getter steps are:

 1. Return [=this=].[=WritableStreamDefaultWriter/[[closedPromise]]=].
</div>

<div algorithm>
 The <dfn id="default-writer-desired-size" attribute
 for="WritableStreamDefaultWriter">desiredSize</dfn> getter steps are:

 1. If [=this=].[=WritableStreamDefaultWriter/[[stream]]=] is undefined, throw a {{TypeError}}
    exception.
 1. Return ! [$WritableStreamDefaultWriterGetDesiredSize$]([=this=]).
</div>

<div algorithm>
 The <dfn id="default-writer-ready" attribute for="WritableStreamDefaultWriter">ready</dfn> getter
 steps are:

 1. Return [=this=].[=WritableStreamDefaultWriter/[[readyPromise]]=].
</div>

<div algorithm>
 The <dfn id="default-writer-abort" method for="WritableStreamDefaultWriter">abort(|reason|)</dfn>
 method steps are:

 1. If [=this=].[=WritableStreamDefaultWriter/[[stream]]=] is undefined, return [=a promise rejected
    with=] a {{TypeError}} exception.
 1. Return ! [$WritableStreamDefaultWriterAbort$]([=this=], |reason|).
</div>

<div algorithm>
 The <dfn id="default-writer-close" method for="WritableStreamDefaultWriter">close()</dfn> method
 steps are:

 1. Let |stream| be [=this=].[=WritableStreamDefaultWriter/[[stream]]=].
 1. If |stream| is undefined, return [=a promise rejected with=] a {{TypeError}} exception.
 1. If ! [$WritableStreamCloseQueuedOrInFlight$](|stream|) is true, return [=a promise rejected
    with=] a {{TypeError}} exception.
 1. Return ! [$WritableStreamDefaultWriterClose$]([=this=]).
</div>

<div algorithm>
 The <dfn id="default-writer-release-lock" method
 for="WritableStreamDefaultWriter">releaseLock()</dfn> method steps are:

 1. Let |stream| be [=this=].[=WritableStreamDefaultWriter/[[stream]]=].
 1. If |stream| is undefined, return.
 1. Assert: |stream|.[=WritableStream/[[writer]]=] is not undefined.
 1. Perform ! [$WritableStreamDefaultWriterRelease$]([=this=]).
</div>

<div algorithm>
 The <dfn id="default-writer-write" method for="WritableStreamDefaultWriter">write(|chunk|)</dfn>
 method steps are:

 1. If [=this=].[=WritableStreamDefaultWriter/[[stream]]=] is undefined, return [=a promise rejected
    with=] a {{TypeError}} exception.
 1. Return ! [$WritableStreamDefaultWriterWrite$]([=this=], |chunk|).
</div>

<h3 id="ws-default-controller-class">The {{WritableStreamDefaultController}} class</h3>

The {{WritableStreamDefaultController}} class has methods that allow control of a
{{WritableStream}}'s state. When constructing a {{WritableStream}}, the [=underlying sink=] is
given a corresponding {{WritableStreamDefaultController}} instance to manipulate.

<h4 id="ws-default-controller-class-definition">Interface definition</h4>

The Web IDL definition for the {{WritableStreamDefaultController}} class is given as follows:

<xmp class="idl">
[Exposed=(Window,Worker,Worklet)]
interface WritableStreamDefaultController {
  void error(optional any e);
};
</xmp>

<h4 id="ws-default-controller-internal-slots">Internal slots</h4>

Instances of {{WritableStreamDefaultController}} are created with the internal slots described in
the following table:

<table dfn-for="WritableStreamDefaultController">
 <thead>
  <tr>
   <th>Internal Slot</th>
   <th>Description (<em>non-normative</em>)</th>
 <tbody>
  <tr>
   <td><dfn>\[[abortAlgorithm]]</dfn>
   <td class="non-normative">A promise-returning algorithm, taking one argument (the abort reason),
   which communicates a requested abort to the [=underlying sink=]
  <tr>
   <td><dfn>\[[closeAlgorithm]]</dfn>
   <td class="non-normative">A promise-returning algorithm which communicates a requested close to
   the [=underlying sink=]
  <tr>
   <td><dfn>\[[queue]]</dfn>
   <td class="non-normative">A [=list=] representing the stream's internal queue of [=chunks=]
  <tr>
   <td><dfn>\[[queueTotalSize]]</dfn>
   <td class="non-normative">The total size of all the chunks stored in
   [=WritableStreamDefaultController/[[queue]]=] (see [[#queue-with-sizes]])
  <tr>
   <td><dfn>\[[started]]</dfn>
   <td class="non-normative">A boolean flag indicating whether the [=underlying sink=] has finished
   starting
  <tr>
   <td><dfn>\[[strategyHWM]]</dfn>
   <td class="non-normative">A number supplied by the creator of the stream as part of the stream's
   [=queuing strategy=], indicating the point at which the stream will apply [=backpressure=] to its
   [=underlying sink=]
  <tr>
   <td><dfn>\[[strategySizeAlgorithm]]</dfn>
   <td class="non-normative">An algorithm to calculate the size of enqueued [=chunks=], as part of
    the stream's [=queuing strategy=]
  <tr>
   <td><dfn>\[[stream]]</dfn>
   <td class="non-normative">The {{WritableStream}} instance controlled
  <tr>
   <td><dfn>\[[writeAlgorithm]]</dfn>
   <td class="non-normative">A promise-returning algorithm, taking one argument (the [=chunk=] to
   write), which writes data to the [=underlying sink=]
</table>

The <dfn>close sentinel</dfn> is a unique value enqueued into
[=WritableStreamDefaultController/[[queue]]=], in lieu of a [=chunk=], to signal that the stream is
closed. It is only used internally, and is never exposed to web developers.

<h4 id="ws-default-controller-prototype">Methods</h4>

<dl class="domintro non-normative">
 <dt><code><var ignore>controller</var>.{{WritableStreamDefaultController/error()|error}}(<var ignore>e</var>)</code>
 <dd>
  <p>Closes the controlled writable stream, making all future interactions with it fail with the
  given error <var ignore>e</var>.

  <p>This method is rarely used, since usually it suffices to return a rejected promise from one of
  the [=underlying sink=]'s methods. However, it can be useful for suddenly shutting down a stream
  in response to an event outside the normal lifecycle of interactions with the [=underlying
  sink=].
</dl>

<div algorithm>
 The <dfn id="ws-default-controller-error" method
 for="WritableStreamDefaultController">error(|e|)</dfn> method steps are:

 1. Let |state| be [=this=].[=WritableStreamDefaultController/[[stream]]=].[=WritableStream/[[state]]=].
 1. If |state| is not "`writable`", return.
 1. Perform ! [$WritableStreamDefaultControllerError$]([=this=], |e|).
</div>

<h4 id="ws-default-controller-internal-methods">Internal methods</h4>

The following are internal methods implemented by each {{WritableStreamDefaultController}} instance.
The writable stream implementation will call into these.

<p class="note">The reason these are in method form, instead of as abstract operations, is to make
it clear that the writable stream implementation is decoupled from the controller implementation,
and could in the future be expanded with other controllers, as long as those controllers
implemented such internal methods. A similar scenario is seen for readable streams (see
[[#rs-abstract-ops-used-by-controllers]]), where there actually are multiple controller types and
as such the counterpart internal methods are used polymorphically.

<div algorithm>
 <dfn abstract-op lt="[[AbortSteps]]" for="WritableStreamDefaultController"
 id="ws-default-controller-private-abort"
 oldids="writable-stream-default-controller-abort">\[[AbortSteps]](|reason|)</dfn> implements the
 [$WritableStreamController/[[AbortSteps]]$] contract. It performs the following steps:

 1. Let |result| be the result of performing
    [=this=].[=WritableStreamDefaultController/[[abortAlgorithm]]=], passing |reason|.
 1. Perform ! [$WritableStreamDefaultControllerClearAlgorithms$]([=this=]).
 1. Return |result|.
</div>

<div algorithm>
 <dfn abstract-op lt="[[ErrorSteps]]" for="WritableStreamDefaultController"
 id="ws-default-controller-private-error">\[[ErrorSteps]]()</dfn> implements the
 [$WritableStreamController/[[ErrorSteps]]$] contract. It performs the following steps:

 1. Perform ! [$ResetQueue$]([=this=]).
</div>

<h3 id="ws-all-abstract-ops">Abstract operations</h3>

<h4 id="ws-abstract-ops">Working with writable streams</h4>

The following abstract operations operate on {{WritableStream}} instances at a higher level. Some
are even meant to be generally useful by other specifications.

<div algorithm>
 <dfn abstract-op lt="AcquireWritableStreamDefaultWriter"
 id="acquire-writable-stream-default-writer"
 export>AcquireWritableStreamDefaultWriter(|stream|)</dfn> is meant to be called from other
 specifications that wish to acquire a [=writer=] for a given writable stream. It performs the
 following steps:

 1. Let |writer| be a [=new=] {{WritableStreamDefaultWriter}}.
 1. Perform ? [$SetUpWritableStreamDefaultWriter$](|writer|, |stream|).
 1. Return |writer|.
</div>

<div algorithm>
 <dfn abstract-op lt="CreateWritableStream" id="create-writable-stream"
 export>CreateWritableStream(|startAlgorithm|, |writeAlgorithm|, |closeAlgorithm|,
 |abortAlgorithm|[, |highWaterMark|[, |sizeAlgorithm|]])</dfn> is meant to be called from other
 specifications that wish to create {{WritableStream}} instances. The |writeAlgorithm|,
 |closeAlgorithm|, and |abortAlgorithm| algorithms must return promises; if supplied,
 |sizeAlgorithm| must be an algorithm accepting [=chunk=] objects and returning a number; and if
 supplied, |highWaterMark| must be a non-negative, non-NaN number.

 It performs the following steps:

 1. If |highWaterMark| was not passed, set it to 1.
 1. If |sizeAlgorithm| was not passed, set it to an algorithm that returns 1.
 1. Assert: ! [$IsNonNegativeNumber$](|highWaterMark|) is true.
 1. Let |stream| be a [=new=] {{WritableStream}}.
 1. Perform ! [$InitializeWritableStream$](|stream|).
 1. Let |controller| be a [=new=] {{WritableStreamDefaultController}}.
 1. Perform ? [$SetUpWritableStreamDefaultController$](|stream|, |controller|, |startAlgorithm|,
    |writeAlgorithm|, |closeAlgorithm|, |abortAlgorithm|, |highWaterMark|, |sizeAlgorithm|).
 1. Return |stream|.

 <p class="note">This abstract operation will throw an exception if and only if the supplied
 |startAlgorithm| throws.
</div>

<div algorithm>
 <dfn abstract-op lt="InitializeWritableStream"
 id="initialize-writable-stream">InitializeWritableStream(|stream|)</dfn> performs the following
 steps:

 1. Set |stream|.[=WritableStream/[[state]]=] to "`writable`".
 1. Set |stream|.[=WritableStream/[[storedError]]=], |stream|.[=WritableStream/[[writer]]=],
    |stream|.[=WritableStream/[[controller]]=],
    |stream|.[=WritableStream/[[inFlightWriteRequest]]=],
    |stream|.[=WritableStream/[[closeRequest]]=],
    |stream|.[=WritableStream/[[inFlightCloseRequest]]=], and
    |stream|.[=WritableStream/[[pendingAbortRequest]]=] to undefined.
 1. Set |stream|.[=WritableStream/[[writeRequests]]=] to a new empty [=list=].
 1. Set |stream|.[=WritableStream/[[backpressure]]=] to false.
</div>

<div algorithm>
 <dfn abstract-op lt="IsWritableStreamLocked"
 id="is-writable-stream-locked">IsWritableStreamLocked(|stream|)</dfn> is meant to be called from
 other specifications that wish to query whether or not a writable stream is [=locked to a writer=].
 It performs the following steps:

 1. If |stream|.[=WritableStream/[[writer]]=] is undefined, return false.
 1. Return true.
</div>

<div algorithm>
 <dfn abstract-op lt="SetUpWritableStreamDefaultWriter"
 id="set-up-writable-stream-default-writer">SetUpWritableStreamDefaultWriter(|writer|,
 |stream|)</dfn> performs the following steps:

 1. If ! [$IsWritableStreamLocked$](|stream|) is true, throw a {{TypeError}} exception.
 1. Set |writer|.[=WritableStreamDefaultWriter/[[stream]]=] to |stream|.
 1. Set |stream|.[=WritableStream/[[writer]]=] to |writer|.
 1. Let |state| be |stream|.[=WritableStream/[[state]]=].
 1. If |state| is "`writable`",
  1. If ! [$WritableStreamCloseQueuedOrInFlight$](|stream|) is false and
     |stream|.[=WritableStream/[[backpressure]]=] is true, set
     |writer|.[=WritableStreamDefaultWriter/[[readyPromise]]=] to [=a new promise=].
  1. Otherwise, set |writer|.[=WritableStreamDefaultWriter/[[readyPromise]]=] to [=a promise
     resolved with=] undefined.
  1. Set |writer|.[=WritableStreamDefaultWriter/[[closedPromise]]=] to [=a new promise=].
 1. Otherwise, if |state| is "`erroring`",
  1. Set |writer|.[=WritableStreamDefaultWriter/[[readyPromise]]=] to [=a promise rejected with=]
     |stream|.[=WritableStream/[[storedError]]=].
  1. Set |writer|.[=WritableStreamDefaultWriter/[[readyPromise]]=].\[[PromiseIsHandled]] to true.
  1. Set |writer|.[=WritableStreamDefaultWriter/[[closedPromise]]=] to [=a new promise=].
 1. Otherwise, if |state| is "`closed`",
  1. Set |writer|.[=WritableStreamDefaultWriter/[[readyPromise]]=] to [=a promise resolved with=]
     undefined.
  1. Set |writer|.[=WritableStreamDefaultWriter/[[closedPromise]]=] to [=a promise resolved with=]
     undefined.
 1. Otherwise,
  1. Assert: |state| is "`errored`".
  1. Let |storedError| be |stream|.[=WritableStream/[[storedError]]=].
  1. Set |writer|.[=WritableStreamDefaultWriter/[[readyPromise]]=] to [=a promise rejected with=]
     |storedError|.
  1. Set |writer|.[=WritableStreamDefaultWriter/[[readyPromise]]=].\[[PromiseIsHandled]] to true.
  1. Set |writer|.[=WritableStreamDefaultWriter/[[closedPromise]]=] to [=a promise rejected with=]
     |storedError|.
  1. Set |writer|.[=WritableStreamDefaultWriter/[[closedPromise]]=].\[[PromiseIsHandled]] to true.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamAbort"
 id="writable-stream-abort">WritableStreamAbort(|stream|, |reason|)</dfn> performs the following
 steps:

 1. Let |state| be |stream|.[=WritableStream/[[state]]=].
 1. If |state| is "`closed`" or "`errored`", return [=a promise resolved with=] undefined.
 1. If |stream|.[=WritableStream/[[pendingAbortRequest]]=] is not undefined, return
    |stream|.[=WritableStream/[[pendingAbortRequest]]=]'s [=pending abort request/promise=].
 1. Assert: |state| is "`writable`" or "`erroring`".
 1. Let |wasAlreadyErroring| be false.
 1. If |state| is "`erroring`",
   1. Set |wasAlreadyErroring| to true.
   1. Set |reason| to undefined.
 1. Let |promise| be [=a new promise=].
 1. Set |stream|.[=WritableStream/[[pendingAbortRequest]]=] to a new [=pending abort request=] whose
    [=pending abort request/promise=] is |promise|, [=pending abort request/reason=] is |reason|,
    and [=pending abort request/was already erroring=] is |wasAlreadyErroring|.
 1. If |wasAlreadyErroring| is false, perform ! [$WritableStreamStartErroring$](|stream|, |reason|).
 1. Return |promise|.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamClose"
 id="writable-stream-close">WritableStreamClose(|stream|)</dfn> performs the following steps:

 1. Let |state| be |stream|.[=WritableStream/[[state]]=].
 1. If |state| is "`closed`" or "`errored`", return [=a promise rejected with=] a {{TypeError}}
    exception.
 1. Assert: |state| is "`writable`" or "`erroring`".
 1. Assert: ! [$WritableStreamCloseQueuedOrInFlight$](|stream|) is false.
 1. Let |promise| be [=a new promise=].
 1. Set |stream|.[=WritableStream/[[closeRequest]]=] to |promise|.
 1. Let |writer| be |stream|.[=WritableStream/[[writer]]=].
 1. If |writer| is not undefined, and |stream|.[=WritableStream/[[backpressure]]=] is true, and
    |state| is "`writable`", [=resolve=] |writer|.[=WritableStreamDefaultWriter/[[readyPromise]]=]
    with undefined.
 1. Perform ! [$WritableStreamDefaultControllerClose$](|stream|.[=WritableStream/[[controller]]=]).
 1. Return |promise|.
</div>

<h4 id="ws-abstract-ops-used-by-controllers">Interfacing with controllers</h4>

To allow future flexibility to add different writable stream behaviors (similar to the distinction
between default readable streams and [=readable byte streams=]), much of the internal state of a
[=writable stream=] is encapsulated by the {{WritableStreamDefaultController}} class.

Each controller class defines two internal methods, which are called by the {{WritableStream}}
algorithms:

<dl>
  <dt><dfn abstract-op lt="[[AbortSteps]]"
  for="WritableStreamController">\[[AbortSteps]](<var ignore>reason</var>)</dfn>
  <dd>The controller's steps that run in reaction to the stream being [=abort a writable
  stream|aborted=], used to clean up the state stored in the controller and inform the
  [=underlying sink=].

  <dt><dfn abstract-op lt="[[ErrorSteps]]" for="WritableStreamController">\[[ErrorSteps]]()</dfn>
  <dd>The controller's steps that run in reaction to the stream being errored, used to clean up the
   state stored in the controller.
</dl>

(These are defined as internal methods, instead of as abstract operations, so that they can be
called polymorphically by the {{WritableStream}} algorithms, without having to branch on which type
of controller is present. This is a bit theoretical for now, given that only
{{WritableStreamDefaultController}} exists so far.)

The rest of this section concerns abstract operations that go in the other direction: they are used
by the controller implementation to affect its associated {{WritableStream}} object. This
translates internal state changes of the controllerinto developer-facing results visible through
the {{WritableStream}}'s public API.

<div algorithm>
 <dfn abstract-op lt="WritableStreamAddWriteRequest"
 id="writable-stream-add-write-request">WritableStreamAddWriteRequest(|stream|)</dfn> performs the
 following steps:

 1. Assert: ! [$IsWritableStreamLocked$](|stream|) is true.
 1. Assert: |stream|.[=WritableStream/[[state]]=] is "`writable`".
 1. Let |promise| be [=a new promise=].
 1. [=list/Append=] |promise| to |stream|.[=WritableStream/[[writeRequests]]=].
 1. Return |promise|.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamCloseQueuedOrInFlight"
 id="writable-stream-close-queued-or-in-flight">WritableStreamCloseQueuedOrInFlight(|stream|)</dfn>
 performs the following steps:

 1. If |stream|.[=WritableStream/[[closeRequest]]=] is undefined and
    |stream|.[=WritableStream/[[inFlightCloseRequest]]=] is undefined, return false.
 1. Return true.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDealWithRejection"
 id="writable-stream-deal-with-rejection">WritableStreamDealWithRejection(|stream|, |error|)</dfn>
 performs the following steps:

 1. Let |state| be |stream|.[=WritableStream/[[state]]=].
 1. If |state| is "`writable`",
  1. Perform ! [$WritableStreamStartErroring$](|stream|, |error|).
  1. Return.
 1. Assert: |state| is "`erroring`".
 1. Perform ! [$WritableStreamFinishErroring$](|stream|).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamFinishErroring"
 id="writable-stream-finish-erroring">WritableStreamFinishErroring(|stream|, |reason|)</dfn>
 performs the following steps:

 1. Assert: |stream|.[=WritableStream/[[state]]=] is "`erroring`".
 1. Assert: ! [$WritableStreamHasOperationMarkedInFlight$](|stream|) is false.
 1. Set |stream|.[=WritableStream/[[state]]=] to "`errored`".
 1. Perform ! |stream|.[=WritableStream/[[controller]]=].\[[ErrorSteps]]().
 1. Let |storedError| be |stream|.[=WritableStream/[[storedError]]=].
 1. [=list/For each=] |writeRequest| of |stream|.[=WritableStream/[[writeRequests]]=]:
  1. [=Reject=] |writeRequest| with |storedError|.
 1. Set |stream|.[=WritableStream/[[writeRequests]]=] to an empty [=list=].
 1. If |stream|.[=WritableStream/[[pendingAbortRequest]]=] is undefined,
  1. Perform ! [$WritableStreamRejectCloseAndClosedPromiseIfNeeded$](|stream|).
  1. Return.
 1. Let |abortRequest| be |stream|.[=WritableStream/[[pendingAbortRequest]]=].
 1. Set |stream|.[=WritableStream/[[pendingAbortRequest]]=] to undefined.
 1. If |abortRequest|'s [=pending abort request/was already erroring=] is true,
  1. [=Reject=] |abortRequest|'s [=pending abort request/promise=] with |storedError|.
  1. Perform ! [$WritableStreamRejectCloseAndClosedPromiseIfNeeded$](|stream|).
  1. Return.
 1. Let |promise| be ! stream.[=WritableStream/[[controller]]=].\[[AbortSteps]](|abortRequest|'s
    [=pending abort request/reason=]).
 1. [=Upon fulfillment=] of |promise|,
  1. [=Resolve=] |abortRequest|'s [=pending abort request/promise=] with undefined.
  1. Perform ! [$WritableStreamRejectCloseAndClosedPromiseIfNeeded$](|stream|).
 1. [=Upon rejection=] of |promise| with reason |reason|,
  1. [=Reject=] |abortRequest|'s [=pending abort request/promise=] with |reason|.
  1. Perform ! [$WritableStreamRejectCloseAndClosedPromiseIfNeeded$](|stream|).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamFinishInFlightClose"
 id="writable-stream-finish-in-flight-close">WritableStreamFinishInFlightClose(|stream|)</dfn>
 performs the following steps:

 1. Assert: |stream|.[=WritableStream/[[inFlightCloseRequest]]=] is not undefined.
 1. [=Resolve=] |stream|.[=WritableStream/[[inFlightCloseRequest]]=] with undefined.
 1. Set |stream|.[=WritableStream/[[inFlightCloseRequest]]=] to undefined.
 1. Let |state| be |stream|.[=WritableStream/[[state]]=].
 1. Assert: |stream|.[=WritableStream/[[state]]=] is "`writable`" or "`erroring`".
 1. If |state| is "`erroring`",
  1. Set |stream|.[=WritableStream/[[storedError]]=] to undefined.
  1. If |stream|.[=WritableStream/[[pendingAbortRequest]]=] is not undefined,
   1. [=Resolve=] |stream|.[=WritableStream/[[pendingAbortRequest]]=]'s [=pending abort
      request/promise=] with undefined.
   1. Set |stream|.[=WritableStream/[[pendingAbortRequest]]=] to undefined.
 1. Set |stream|.[=WritableStream/[[state]]=] to "`closed`".
 1. Let |writer| be |stream|.[=WritableStream/[[writer]]=].
 1. If |writer| is not undefined, [=resolve=]
    |writer|.[=WritableStreamDefaultWriter/[[closedPromise]]=] with undefined.
 1. Assert: |stream|.[=WritableStream/[[pendingAbortRequest]]=] is undefined.
 1. Assert: |stream|.[=WritableStream/[[storedError]]=] is undefined.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamFinishInFlightCloseWithError"
 id="writable-stream-finish-in-flight-close-with-error">WritableStreamFinishInFlightCloseWithError(|stream|,
 |error|)</dfn> performs the following steps:

 1. Assert: |stream|.[=WritableStream/[[inFlightCloseRequest]]=] is not undefined.
 1. [=Reject=] |stream|.[=WritableStream/[[inFlightCloseRequest]]=] with |error|.
 1. Set |stream|.[=WritableStream/[[inFlightCloseRequest]]=] to undefined.
 1. Assert: |stream|.[=WritableStream/[[state]]=] is "`writable`" or "`erroring`".
 1. If |stream|.[=WritableStream/[[pendingAbortRequest]]=] is not undefined,
  1. [=Reject=] |stream|.[=WritableStream/[[pendingAbortRequest]]=]'s [=pending abort
     request/promise=] with |error|.
  1. Set |stream|.[=WritableStream/[[pendingAbortRequest]]=] to undefined.
 1. Perform ! WritableStreamDealWithRejection(|stream|, |error|).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamFinishInFlightWrite"
 id="writable-stream-finish-in-flight-write">WritableStreamFinishInFlightWrite(|stream|)</dfn>
 performs the following steps:

 1. Assert: |stream|.[=WritableStream/[[inFlightWriteRequest]]=] is not undefined.
 1. [=Resolve=] |stream|.[=WritableStream/[[inFlightWriteRequest]]=] with undefined.
 1. Set |stream|.[=WritableStream/[[inFlightWriteRequest]]=] to undefined.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamFinishInFlightWriteWithError"
 id="writable-stream-finish-in-flight-write-with-error">WritableStreamFinishInFlightWriteWithError(|stream|,
 |error|)</dfn> performs the following steps:

 1. Assert: |stream|.[=WritableStream/[[inFlightWriteRequest]]=] is not undefined.
 1. [=Reject=] |stream|.[=WritableStream/[[inFlightWriteRequest]]=] with |error|.
 1. Set |stream|.[=WritableStream/[[inFlightWriteRequest]]=] to undefined.
 1. Assert: |stream|.[=WritableStream/[[state]]=] is "`writable`" or "`erroring`".
 1. Perform ! [$WritableStreamDealWithRejection$](|stream|, |error|).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamHasOperationMarkedInFlight"
 id="writable-stream-has-operation-marked-in-flight">WritableStreamHasOperationMarkedInFlight(|stream|)</dfn>
 performs the following steps:

 1. If |stream|.[=WritableStream/[[inFlightWriteRequest]]=] is undefined and
    |stream|.[=WritableStream/[[controller]]=].[=WritableStream/[[inFlightCloseRequest]]=] is
    undefined, return false.
 1. Return true.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamMarkCloseRequestInFlight"
 id="writable-stream-mark-close-request-in-flight">WritableStreamMarkCloseRequestInFlight(|stream|)</dfn>
 performs the following steps:

 1. Assert: |stream|.[=WritableStream/[[inFlightCloseRequest]]=] is undefined.
 1. Assert: |stream|.[=WritableStream/[[closeRequest]]=] is not undefined.
 1. Set |stream|.[=WritableStream/[[inFlightCloseRequest]]=] to
    |stream|.[=WritableStream/[[closeRequest]]=].
 1. Set |stream|.[=WritableStream/[[closeRequest]]=] to undefined.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamMarkFirstWriteRequestInFlight"
 id="writable-stream-mark-first-write-request-in-flight">WritableStreamMarkFirstWriteRequestInFlight(|stream|)</dfn>
 performs the following steps:

 1. Assert: |stream|.[=WritableStream/[[inFlightWriteRequest]]=] is undefined.
 1. Assert: |stream|.[=WritableStream/[[writeRequests]]=] is not empty.
 1. Let |writeRequest| be |stream|.[=WritableStream/[[writeRequests]]=][0].
 1. [=list/Remove=] |writeRequest| from |stream|.[=WritableStream/[[writeRequests]]=].
 1. Set |stream|.[=WritableStream/[[inFlightWriteRequest]]=] to |writeRequest|.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamRejectCloseAndClosedPromiseIfNeeded"
 id="writable-stream-reject-close-and-closed-promise-if-needed">WritableStreamRejectCloseAndClosedPromiseIfNeeded(|stream|)</dfn>
 performs the following steps:

 1. Assert: |stream|.[=WritableStream/[[state]]=] is "`errored`".
 1. If |stream|.[=WritableStream/[[closeRequest]]=] is not undefined,
  1. Assert: |stream|.[=WritableStream/[[inFlightCloseRequest]]=] is undefined.
  1. [=Reject=] |stream|.[=WritableStream/[[closeRequest]]=] with
     |stream|.[=WritableStream/[[storedError]]=].
  1. Set |stream|.[=WritableStream/[[closeRequest]]=] to undefined.
 1. Let |writer| be |stream|.[=WritableStream/[[writer]]=].
 1. If |writer| is not undefined,
  1. [=Reject=] |writer|.[=WritableStreamDefaultWriter/[[closedPromise]]=] with
     |stream|.[=WritableStream/[[storedError]]=].
  1. Set |writer|.[=WritableStreamDefaultWriter/[[closedPromise]]=].\[[PromiseIsHandled]] to true.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamStartErroring"
 id="writable-stream-start-erroring">WritableStreamStartErroring(|stream|, |reason|)</dfn>
 performs the following steps:

 1. Assert: |stream|.[=WritableStream/[[storedError]]=] is undefined.
 1. Assert: |stream|.[=WritableStream/[[state]]=] is "`writable`".
 1. Let |controller| be |stream|.[=WritableStream/[[controller]]=].
 1. Assert: |controller| is not undefined.
 1. Set |stream|.[=WritableStream/[[state]]=] to "`erroring`".
 1. Set |stream|.[=WritableStream/[[storedError]]=] to |reason|.
 1. Let |writer| be |stream|.[=WritableStream/[[writer]]=].
 1. If |writer| is not undefined, perform !
    [$WritableStreamDefaultWriterEnsureReadyPromiseRejected$](|writer|, |reason|).
 1. If ! [$WritableStreamHasOperationMarkedInFlight$](|stream|) is false and
    |controller|.[=WritableStreamDefaultController/[[started]]=] is true, perform !
    [$WritableStreamFinishErroring$](|stream|).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamUpdateBackpressure"
 id="writable-stream-update-backpressure">WritableStreamUpdateBackpressure(|stream|,
 |backpressure|)</dfn> performs the following steps:

 1. Assert: |stream|.[=WritableStream/[[state]]=] is "`writable`".
 1. Assert: ! [$WritableStreamCloseQueuedOrInFlight$](|stream|) is false.
 1. Let |writer| be |stream|.[=WritableStream/[[writer]]=].
 1. If |writer| is not undefined and |backpressure| is not
    |stream|.[=WritableStream/[[backpressure]]=],
  1. If |backpressure| is true, set |writer|.[=WritableStreamDefaultWriter/[[readyPromise]]=] to
     [=a new promise=].
  1. Otherwise,
   1. Assert: |backpressure| is false.
   1. [=Resolve=] |writer|.[=WritableStreamDefaultWriter/[[readyPromise]]=] with undefined.
 1. Set |stream|.[=WritableStream/[[backpressure]]=] to |backpressure|.
</div>

<h4 id="ws-writer-abstract-ops">Writers</h4>

The following abstract operations support the implementation and manipulation of
{{WritableStreamDefaultWriter}} instances.

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultWriterAbort"
 id="writable-stream-default-writer-abort">WritableStreamDefaultWriterAbort(|writer|,
 |reason|)</dfn> performs the following steps:

 1. Let |stream| be |writer|.[=WritableStreamDefaultWriter/[[stream]]=].
 1. Assert: |stream| is not undefined.
 1. Return ! [$WritableStreamAbort$](|stream|, |reason|).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultWriterClose"
 id="writable-stream-default-writer-close">WritableStreamDefaultWriterClose(|writer|)</dfn> performs
 the following steps:

 1. Let |stream| be |writer|.[=WritableStreamDefaultWriter/[[stream]]=].
 1. Assert: |stream| is not undefined.
 1. Return ! [$WritableStreamClose$](|stream|).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultWriterCloseWithErrorPropagation"
 id="writable-stream-default-writer-close-with-error-propagation">WritableStreamDefaultWriterCloseWithErrorPropagation(|writer|)</dfn>
 performs the following steps:

 1. Let |stream| be |writer|.[=WritableStreamDefaultWriter/[[stream]]=].
 1. Assert: |stream| is not undefined.
 1. Let |state| be |stream|.[=WritableStream/[[state]]=].
 1. If ! [$WritableStreamCloseQueuedOrInFlight$](|stream|) is true or |state| is "`closed`", return
    [=a promise resolved with=] undefined.
 1. If |state| is "`errored`", return [=a promise rejected with=]
    |stream|.[=WritableStream/[[storedError]]=].
 1. Assert: |state| is "`writable`" or "`erroring`".
 1. Return ! [$WritableStreamDefaultWriterClose$](|writer|).

 <p class="note">This abstract operation helps implement the error propagation semantics of
 {{ReadableStream}}'s {{ReadableStream/pipeTo()}}.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultWriterEnsureClosedPromiseRejected"
 id="writable-stream-default-writer-ensure-closed-promise-rejected">WritableStreamDefaultWriterEnsureClosedPromiseRejected(|writer|,
 |error|)</dfn> performs the following steps:

 1. If |writer|.[=WritableStreamDefaultWriter/[[closedPromise]]=].\[[PromiseState]] is "`pending`",
    [=reject=] |writer|.[=WritableStreamDefaultWriter/[[closedPromise]]=] with |error|.
 1. Otherwise, set |writer|.[=WritableStreamDefaultWriter/[[closedPromise]]=] to [=a promise
    rejected with=] |error|.
 1. Set |writer|.[=WritableStreamDefaultWriter/[[closedPromise]]=].\[[PromiseIsHandled]] to true.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultWriterEnsureReadyPromiseRejected"
 id="writable-stream-default-writer-ensure-ready-promise-rejected">WritableStreamDefaultWriterEnsureReadyPromiseRejected(|writer|,
 |error|)</dfn> performs the following steps:

 1. If |writer|.[=WritableStreamDefaultWriter/[[readyPromise]]=].\[[PromiseState]] is "`pending`",
    [=reject=] |writer|.[=WritableStreamDefaultWriter/[[readyPromise]]=] with |error|.
 1. Otherwise, set |writer|.[=WritableStreamDefaultWriter/[[readyPromise]]=] to [=a promise rejected
    with=] |error|.
 1. Set |writer|.[=WritableStreamDefaultWriter/[[readyPromise]]=].\[[PromiseIsHandled]] to true.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultWriterGetDesiredSize"
 id="writable-stream-default-writer-get-desired-size">WritableStreamDefaultWriterGetDesiredSize(|writer|)</dfn>
 performs the following steps:

 1. Let |stream| be |writer|.[=WritableStreamDefaultWriter/[[stream]]=].
 1. Let |state| be |stream|.[=WritableStream/[[state]]=].
 1. If |state| is "`errored`" or "`erroring`", return null.
 1. If |state| is "`closed`", return 0.
 1. Return !
    [$WritableStreamDefaultControllerGetDesiredSize$](|stream|.[=WritableStream/[[controller]]=]).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultWriterRelease"
 id="writable-stream-default-writer-release">WritableStreamDefaultWriterRelease(|writer|)</dfn>
 performs the following steps:

 1. Let |stream| be |writer|.[=WritableStreamDefaultWriter/[[stream]]=].
 1. Assert: |stream| is not undefined.
 1. Assert: |stream|.[=WritableStream/[[writer]]=] is |writer|.
 1. Let |releasedError| be a new {{TypeError}}.
 1. Perform ! [$WritableStreamDefaultWriterEnsureReadyPromiseRejected$](|writer|, |releasedError|).
 1. Perform ! [$WritableStreamDefaultWriterEnsureClosedPromiseRejected$](|writer|, |releasedError|).
 1. Set |stream|.[=WritableStream/[[writer]]=] to undefined.
 1. Set |writer|.[=WritableStreamDefaultWriter/[[stream]]=] to undefined.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultWriterWrite"
 id="writable-stream-default-writer-write">WritableStreamDefaultWriterWrite(|writer|, |chunk|)</dfn>
 performs the following steps:

 1. Let |stream| be |writer|.[=WritableStreamDefaultWriter/[[stream]]=].
 1. Assert: |stream| is not undefined.
 1. Let |controller| be |stream|.[=WritableStream/[[controller]]=].
 1. Let |chunkSize| be ! [$WritableStreamDefaultControllerGetChunkSize$](|controller|, |chunk|).
 1. If |stream| is not equal to |writer|.[=WritableStreamDefaultWriter/[[stream]]=], return [=a
    promise rejected with=] a {{TypeError}} exception.
 1. Let |state| be |stream|.[=WritableStream/[[state]]=].
 1. If |state| is "`errored`", return [=a promise rejected with=]
    |stream|.[=WritableStream/[[storedError]]=].
 1. If ! [$WritableStreamCloseQueuedOrInFlight$](|stream|) is true or |state| is "`closed`", return
    [=a promise rejected with=] a {{TypeError}} exception indicating that the stream is closing or
    closed.
 1. If |state| is "`erroring`", return [=a promise rejected with=]
    |stream|.[=WritableStream/[[storedError]]=].
 1. Assert: |state| is "`writable`".
 1. Let |promise| be ! [$WritableStreamAddWriteRequest$](|stream|).
 1. Perform ! [$WritableStreamDefaultControllerWrite$](|controller|, |chunk|, |chunkSize|).
 1. Return |promise|.
</div>

<h4 id="ws-default-controller-abstract-ops">Default controllers</h3>

The following abstract operations support the implementation of the
{{WritableStreamDefaultController}} class.


<div algorithm>
 <dfn abstract-op lt="SetUpWritableStreamDefaultController"
 id="set-up-writable-stream-default-controller">SetUpWritableStreamDefaultController(|stream|,
 |controller|, |startAlgorithm|, |writeAlgorithm|, |closeAlgorithm|, |abortAlgorithm|,
 |highWaterMark|, |sizeAlgorithm|)</dfn> performs the following steps:

 1. Assert: |stream| [=implements=] {{WritableStream}}.
 1. Assert: |stream|.[=WritableStream/[[controller]]=] is undefined.
 1. Set |controller|.[=WritableStreamDefaultController/[[stream]]=] to |stream|.
 1. Set |stream|.[=WritableStream/[[controller]]=] to |controller|.
 1. Perform ! [$ResetQueue$](|controller|).
 1. Set |controller|.[=WritableStreamDefaultController/[[started]]=] to false.
 1. Set |controller|.[=WritableStreamDefaultController/[[strategySizeAlgorithm]]=] to
    |sizeAlgorithm|.
 1. Set |controller|.[=WritableStreamDefaultController/[[strategyHWM]]=] to |highWaterMark|.
 1. Set |controller|.[=WritableStreamDefaultController/[[writeAlgorithm]]=] to |writeAlgorithm|.
 1. Set |controller|.[=WritableStreamDefaultController/[[closeAlgorithm]]=] to |closeAlgorithm|.
 1. Set |controller|.[=WritableStreamDefaultController/[[abortAlgorithm]]=] to |abortAlgorithm|.
 1. Let |backpressure| be ! [$WritableStreamDefaultControllerGetBackpressure$](|controller|).
 1. Perform ! [$WritableStreamUpdateBackpressure$](|stream|, |backpressure|).
 1. Let |startResult| be the result of performing |startAlgorithm|. (This may throw an exception.)
 1. Let |startPromise| be [=a promise resolved with=] |startResult|.
 1. [=Upon fulfillment=] of |startPromise|,
  1. Assert: |stream|.[=WritableStream/[[state]]=] is "`writable`" or "`erroring`".
  1. Set |controller|.[=WritableStreamDefaultController/[[started]]=] to true.
  1. Perform ! [$WritableStreamDefaultControllerAdvanceQueueIfNeeded$](|controller|).
 1. [=Upon rejection=] of |startPromise| with reason |r|,
  1. Assert: |stream|.[=WritableStream/[[state]]=] is "`writable`" or "`erroring`".
  1. Set |controller|.[=WritableStreamDefaultController/[[started]]=] to true.
  1. Perform ! [$WritableStreamDealWithRejection$](|stream|, |r|).
</div>

<div algorithm>
 <dfn abstract-op lt="SetUpWritableStreamDefaultControllerFromUnderlyingSink"
 id="set-up-writable-stream-default-controller-from-underlying-sink">SetUpWritableStreamDefaultControllerFromUnderlyingSink(|stream|,
 |underlyingSink|, |underlyingSinkDict|, |highWaterMark|, |sizeAlgorithm|)</dfn> performs the
 following steps:

 1. Let |controller| be a [=new=] {{WritableStreamDefaultController}}.
 1. Let |startAlgorithm| be an algorithm that returns undefined.
 1. Let |writeAlgorithm| be an algorithm that returns [=a promise resolved with=] undefined.
 1. Let |closeAlgorithm| be an algorithm that returns [=a promise resolved with=] undefined.
 1. Let |abortAlgorithm| be an algorithm that returns [=a promise resolved with=] undefined.
 1. If |underlyingSinkDict|["{{UnderlyingSink/start}}"] [=map/exists=], then set |startAlgorithm| to
    an algorithm which returns the result of [=invoking=]
    |underlyingSinkDict|["{{UnderlyingSink/start}}"] with argument list «&nbsp;|controller|&nbsp;»
    and [=callback this value=] |underlyingSink|.
 1. If |underlyingSinkDict|["{{UnderlyingSink/write}}"] [=map/exists=], then set |writeAlgorithm| to
    an algorithm which takes an argument |chunk| and returns the result of [=invoking=]
    |underlyingSinkDict|["{{UnderlyingSink/write}}"] with argument list «&nbsp;|chunk|,
    |controller|&nbsp;» and [=callback this value=] |underlyingSink|.
 1. If |underlyingSinkDict|["{{UnderlyingSink/close}}"] [=map/exists=], then set |closeAlgorithm| to
    an algorithm which returns the result of [=invoking=]
    |underlyingSinkDict|["{{UnderlyingSink/close}}"] with argument list «» and [=callback this
    value=] |underlyingSink|.
 1. If |underlyingSinkDict|["{{UnderlyingSink/abort}}"] [=map/exists=], then set |abortAlgorithm| to
    an algorithm which takes an argument |reason| and returns the result of [=invoking=]
    |underlyingSinkDict|["{{UnderlyingSink/abort}}"] with argument list «&nbsp;|reason|&nbsp;» and
    [=callback this value=] |underlyingSink|.
 1. Perform ? [$SetUpWritableStreamDefaultController$](|stream|, |controller|, |startAlgorithm|,
    |writeAlgorithm|, |closeAlgorithm|, |abortAlgorithm|, |highWaterMark|, |sizeAlgorithm|).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultControllerAdvanceQueueIfNeeded"
 id="writable-stream-default-controller-advance-queue-if-needed">WritableStreamDefaultControllerAdvanceQueueIfNeeded(|controller|)</dfn>
 performs the following steps:

 1. Let |stream| be |controller|.[=WritableStreamDefaultController/[[stream]]=].
 1. If |controller|.[=WritableStreamDefaultController/[[started]]=] is false, return.
 1. If |stream|.[=WritableStream/[[inFlightWriteRequest]]=] is not undefined, return.
 1. Let |state| be |stream|.[=WritableStream/[[state]]=].
 1. Assert: |state| is not "`closed`" or "`errored`".
 1. If |state| is "`erroring`",
  1. Perform ! [$WritableStreamFinishErroring$](|stream|).
  1. Return.
 1. If |controller|.[=WritableStreamDefaultController/[[queue]]=] is empty, return.
 1. Let |value| be ! [$PeekQueueValue$](|controller|).
 1. If |value| is the [=close sentinel=], perform !
    [$WritableStreamDefaultControllerProcessClose$](|controller|).
 1. Otherwise, perform ! [$WritableStreamDefaultControllerProcessWrite$](|controller|,
    |value|).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultControllerClearAlgorithms"
 id="writable-stream-default-controller-clear-algorithms">WritableStreamDefaultControllerClearAlgorithms(|controller|)</dfn>
 is called once the stream is closed or errored and the algorithms will not be executed any more. By
 removing the algorithm references it permits the [=underlying sink=] object to be garbage
 collected even if the {{WritableStream}} itself is still referenced.

 <p class="note">This is observable using <a href="https://github.com/tc39/proposal-weakrefs/">weak
 references</a>. See <a
 href="https://github.com/tc39/proposal-weakrefs/issues/31">tc39/proposal-weakrefs#31</a> for more
 detail.

 It performs the following steps:

 1. Set |controller|.[=WritableStreamDefaultController/[[writeAlgorithm]]=] to undefined.
 1. Set |controller|.[=WritableStreamDefaultController/[[closeAlgorithm]]=] to undefined.
 1. Set |controller|.[=WritableStreamDefaultController/[[abortAlgorithm]]=] to undefined.
 1. Set |controller|.[=WritableStreamDefaultController/[[strategySizeAlgorithm]]=] to undefined.

 <p class="note">This algorithm will be performed multiple times in some edge cases. After the first
 time it will do nothing.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultControllerClose"
 id="writable-stream-default-controller-close">WritableStreamDefaultControllerClose(|controller|)</dfn>
 performs the following steps:

 1. Perform ! [$EnqueueValueWithSize$](|controller|, [=close sentinel=], 0).
 1. Perform ! [$WritableStreamDefaultControllerAdvanceQueueIfNeeded$](|controller|).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultControllerError"
 id="writable-stream-default-controller-error">WritableStreamDefaultControllerError(|controller|,
 |error|)</dfn> performs the following steps:

 1. Let |stream| be |controller|.[=WritableStreamDefaultController/[[stream]]=].
 1. Assert: |stream|.[=WritableStream/[[state]]=] is "`writable`".
 1. Perform ! [$WritableStreamDefaultControllerClearAlgorithms$](|controller|).
 1. Perform ! [$WritableStreamStartErroring$](|stream|, |error|).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultControllerErrorIfNeeded"
 id="writable-stream-default-controller-error-if-needed">WritableStreamDefaultControllerErrorIfNeeded(|controller|,
 |error|)</dfn> performs the following steps:

 1. If |controller|.[=WritableStreamDefaultController/[[stream]]=].[=WritableStream/[[state]]=] is
    "`writable`", perform ! [$WritableStreamDefaultControllerError$](|controller|, |error|).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultControllerGetBackpressure"
 id="writable-stream-default-controller-get-backpressure">WritableStreamDefaultControllerGetBackpressure(|controller|)</dfn>
 performs the following steps:

 1. Let |desiredSize| be ! [$WritableStreamDefaultControllerGetDesiredSize$](|controller|).
 1. Return true if |desiredSize| ≤ 0, or false otherwise.
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultControllerGetChunkSize"
 id="writable-stream-default-controller-get-chunk-size">WritableStreamDefaultControllerGetChunkSize(|controller|,
 |chunk|)</dfn> performs the following steps:

 1. Let |returnValue| be the result of performing
    |controller|.[=WritableStreamDefaultController/[[strategySizeAlgorithm]]=], passing in |chunk|,
    and interpreting the result as a [=completion record=].
 1. If |returnValue| is an abrupt completion,
  1. Perform ! [$WritableStreamDefaultControllerErrorIfNeeded$](|controller|,
     |returnValue|.\[[Value]]).
  1. Return 1.
 1. Return |returnValue|.\[[Value]].
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultControllerGetDesiredSize"
 id="writable-stream-default-controller-get-desired-size">WritableStreamDefaultControllerGetDesiredSize(|controller|)</dfn>
 performs the following steps:

 1. Return |controller|.[=WritableStreamDefaultController/[[strategyHWM]]=] −
    |controller|.[=WritableStreamDefaultController/[[queueTotalSize]]=].
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultControllerProcessClose"
 id="writable-stream-default-controller-process-close">WritableStreamDefaultControllerProcessClose(|controller|)</dfn>
 performs the following steps:

 1. Let |stream| be |controller|.[=WritableStreamDefaultController/[[stream]]=].
 1. Perform ! [$WritableStreamMarkCloseRequestInFlight$](|stream|).
 1. Perform ! [$DequeueValue$](|controller|).
 1. Assert: |controller|.[=WritableStreamDefaultController/[[queue]]=] is empty.
 1. Let |sinkClosePromise| be the result of performing
    |controller|.[=WritableStreamDefaultController/[[closeAlgorithm]]=].
 1. Perform ! [$WritableStreamDefaultControllerClearAlgorithms$](|controller|).
 1. [=Upon fulfillment=] of |sinkClosePromise|,
  1. Perform ! [$WritableStreamFinishInFlightClose$](|stream|).
 1. [=Upon rejection=] of |sinkClosePromise| with reason |reason|,
  1. Perform ! [$WritableStreamFinishInFlightCloseWithError$](|stream|, |reason|).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultControllerProcessWrite"
 id="writable-stream-default-controller-process-write">WritableStreamDefaultControllerProcessWrite(|controller|,
 |chunk|)</dfn> performs the following steps:

 1. Let |stream| be |controller|.[=WritableStreamDefaultController/[[stream]]=].
 1. Perform ! [$WritableStreamMarkFirstWriteRequestInFlight$](|stream|).
 1. Let |sinkWritePromise| be the result of performing
    |controller|.[=WritableStreamDefaultController/[[writeAlgorithm]]=], passing in |chunk|.
 1. [=Upon fulfillment=] of |sinkWritePromise|,
  1. Perform ! [$WritableStreamFinishInFlightWrite$](|stream|).
  1. Let |state| be |stream|.[=WritableStream/[[state]]=].
  1. Assert: |state| is "`writable`" or "`erroring`".
  1. Perform ! [$DequeueValue$](|controller|).
  1. If ! [$WritableStreamCloseQueuedOrInFlight$](|stream|) is false and |state| is "`writable`",
   1. Let |backpressure| be ! [$WritableStreamDefaultControllerGetBackpressure$](|controller|).
   1. Perform ! [$WritableStreamUpdateBackpressure$](|stream|, |backpressure|).
  1. Perform ! [$WritableStreamDefaultControllerAdvanceQueueIfNeeded$](|controller|).
 1. [=Upon rejection=] of |sinkWritePromise| with |reason|,
  1. If |stream|.[=WritableStream/[[state]]=] is "`writable`", perform !
     [$WritableStreamDefaultControllerClearAlgorithms$](|controller|).
  1. Perform ! [$WritableStreamFinishInFlightWriteWithError$](|stream|, |reason|).
</div>

<div algorithm>
 <dfn abstract-op lt="WritableStreamDefaultControllerWrite"
 id="writable-stream-default-controller-write">WritableStreamDefaultControllerWrite(|controller|,
 |chunk|, |chunkSize|)</dfn> performs the following steps:

 1. Let |enqueueResult| be [$EnqueueValueWithSize$](|controller|, |chunk|, |chunkSize|).
 1. If |enqueueResult| is an abrupt completion,
  1. Perform ! [$WritableStreamDefaultControllerErrorIfNeeded$](|controller|,
     |enqueueResult|.\[[Value]]).
  1. Return.
 1. Let |stream| be |controller|.[=WritableStreamDefaultController/[[stream]]=].
 1. If ! [$WritableStreamCloseQueuedOrInFlight$](|stream|) is false and
    |stream|.[=WritableStream/[[state]]=] is "`writable`",
  1. Let |backpressure| be ! [$WritableStreamDefaultControllerGetBackpressure$](|controller|).
  1. Perform ! [$WritableStreamUpdateBackpressure$](|stream|, |backpressure|).
 1. Perform ! [$WritableStreamDefaultControllerAdvanceQueueIfNeeded$](|controller|).
</div>

<h2 id="ts">Transform streams</h2>

<h3 id="ts-intro">Using transform streams</h3>

<div class="example" id="example-basic-pipe-through">
 The natural way to use a transform stream is to place it in a [=piping|pipe=] between a [=readable
 stream=] and a [=writable stream=]. [=Chunks=] that travel from the [=readable stream=] to the
 [=writable stream=] will be transformed as they pass through the transform stream.
 [=Backpressure=] is respected, so data will not be read faster than it can be transformed and
 consumed.

 <xmp highlight="js">
 readableStream
   .pipeThrough(transformStream)
   .pipeTo(writableStream)
   .then(() => console.log("All data successfully transformed!"))
   .catch(e => console.error("Something went wrong!", e));
 </xmp>
</div>

<div class="example" id="example-transform-stream-properties">
 You can also use the {{TransformStream/readable}} and {{TransformStream/writable}} properties of a
 transform stream directly to access the usual interfaces of a [=readable stream=] and [=writable
 stream=]. In this example we supply data to the [=writable side=] of the stream using its
 [=writer=] interface. The [=readable side=] is then piped to
 <code>anotherWritableStream</code>.

 <xmp highlight="js">
 const writer = transformStream.writable.getWriter();
 writer.write("input chunk");
 transformStream.readable.pipeTo(anotherWritableStream);
 </xmp>
</div>

<div class="example" id="example-transform-identity">
 One use of [=identity transform streams=] is to easily convert between readable and writable
 streams. For example, the {{fetch()}} API accepts a readable stream [=request/body|request body=],
 but it can be more convenient to write data for uploading via a writable stream interface. Using
 an identity transform stream addresses this:

 <xmp highlight="js">
 const { writable, readable } = new TransformStream();
 fetch("...", { body: readable }).then(response => /* ... */);

 const writer = writable.getWriter();
 writer.write(new Uint8Array([0x73, 0x74, 0x72, 0x65, 0x61, 0x6D, 0x73, 0x21]));
 writer.close();
 </xmp>

 Another use of identity transform streams is to add additional buffering to a [=pipe=]. In this
 example we add extra buffering between <code>readableStream</code> and
 <code>writableStream</code>.

 <xmp highlight="js">
 const writableStrategy = new ByteLengthQueuingStrategy({ highWaterMark: 1024 * 1024 });

 readableStream
   .pipeThrough(new TransformStream(undefined, writableStrategy))
   .pipeTo(writableStream);
 </xmp>
</div>

<h3 id="ts-class">The {{TransformStream}} class</h3>

The {{TransformStream}} class is a concrete instance of the general [=transform stream=] concept.

<h4 id="ts-class-definition">Interface definition</h4>

The Web IDL definition for the {{TransformStream}} class is given as follows:

<xmp class="idl">
[Exposed=(Window,Worker,Worklet), Transferable]
interface TransformStream {
  constructor(optional object transformer,
              optional QueuingStrategy writableStrategy = {},
              optional QueuingStrategy readableStrategy = {});

  readonly attribute ReadableStream readable;
  readonly attribute WritableStream writable;
};
</xmp>

<h4 id="ts-internal-slots">Internal slots</h4>

Instances of {{TransformStream}} are created with the internal slots described in the following
table:

<table dfn-for="TransformStream">
 <thead>
  <tr>
   <th>Internal Slot</th>
   <th>Description (<em>non-normative</em>)</th>
 <tbody>
  <tr>
   <td><dfn>\[[backpressure]]</dfn>
   <td class="non-normative">Whether there was backpressure on [=TransformStream/[[readable]]=] the
   last time it was observed
  <tr>
   <td><dfn>\[[backpressureChangePromise]]</dfn>
   <td class="non-normative">A promise which is fulfilled and replaced every time the value of
   [=TransformStream/[[backpressure]]=] changes
  <tr>
   <td><dfn>\[[controller]]</dfn>
   <td class="non-normative">A {{TransformStreamDefaultController}} created with the ability to
   control [=TransformStream/[[readable]]=] and [=TransformStream/[[writable]]=]
  <tr>
   <td><!-- TODO(ricea): Style this as <dfn unused> when that is supported --><b>\[[detached]]</b>
   <td class="non-normative">A boolean flag set to true when the stream is transferred
  <tr>
   <td><dfn>\[[readable]]</dfn>
   <td class="non-normative">The {{ReadableStream}} instance controlled by this object
  <tr>
   <td><dfn>\[[writable]]</dfn>
   <td class="non-normative">The {{WritableStream}} instance controlled by this object
</table>

<h4 id="transformer-api">The transformer API</h4>

The {{TransformStream()}} constructor accepts as its first argument a JavaScript object representing
the [=transformer=]. Such objects can contain any of the following methods:

<xmp class="idl">
dictionary Transformer {
  TransformerStartCallback start;
  TransformerTransformCallback transform;
  TransformerFlushCallback flush;
  any readableType;
  any writableType;
};

callback TransformerStartCallback = any (TransformStreamDefaultController controller);
callback TransformerFlushCallback = Promise<void> (TransformStreamDefaultController controller);
callback TransformerTransformCallback = Promise<void> (any chunk, TransformStreamDefaultController controller);
</xmp>

<dl>
 <dt><dfn dict-member for="Transformer" lt="start">start(<var ignore>controller</var>)</dfn></dt>
  <dd>
   <p>A function that is called immediately during creation of the {{TransformStream}}.

   <p>Typically this is used to enqueue prefix [=chunks=], using
   {{TransformStreamDefaultController/enqueue()|controller.enqueue()}}. Those chunks will be read
   from the [=readable side=] but don't depend on any writes to the [=writable side=].

   <p>If this initial process is asynchronous, for example because it takes some effort to acquire
   the prefix chunks, the function can return a promise to signal success or failure; a rejected
   promise will error the stream. Any thrown exceptions will be re-thrown by the
   {{TransformStream()}} constructor.

 <dt><dfn dict-member for="Transformer" lt="transform">transform(<var ignore>chunk</var>, <var ignore>controller</var>)</dfn></dt>
 <dd>
  <p>A function called when a new [=chunk=] originally written to the [=writable side=] is ready to
  be transformed. The stream implementation guarantees that this function will be called only after
  previous transforms have succeeded, and never before {{Transformer/start|start()}} has completed
  or after {{Transformer/flush|flush()}} has been called.

  <p>This function performs the actual transformation work of the transform stream. It can enqueue
  the results using {{TransformStreamDefaultController/enqueue()|controller.enqueue()}}. This
  permits a single chunk written to the writable side to result in zero or multiple chunks on the
  [=readable side=], depending on how many times
  {{TransformStreamDefaultController/enqueue()|controller.enqueue()}} is called.
  [[#example-ts-lipfuzz]] demonstrates this by sometimes enqueuing zero chunks.

  <p>If the process of transforming is asynchronous, this function can return a promise to signal
  success or failure of the transformation. A rejected promise will error both the readable and
  writable sides of the transform stream.

  <p>If no {{Transformer/transform|transform()}} method is supplied, the identity transform is
  used, which enqueues chunks unchanged from the writable side to the readable side.

  <dt><dfn dict-member for="Transformer" lt="flush">flush(<var ignore>controller</var>)</dfn></dt>
  <dd>
   <p>A function called after all [=chunks=] written to the [=writable side=] have been transformed
   by successfully passing through {{Transformer/transform|transform()}}, and the writable side is
   about to be closed.

   <p>Typically this is used to enqueue suffix chunks to the [=readable side=], before that too
   becomes closed. An example can be seen in [[#example-ts-lipfuzz]].

   <p>If the flushing process is asynchronous, the function can return a promise to signal success
   or failure; the result will be communicated to the caller of
   {{WritableStreamDefaultWriter/write()|stream.writable.write()}}. Additionally, a rejected
   promise will error both the readable and writable sides of the stream. Throwing an exception is
   treated the same as returning a rejected promise.

   <p>(Note that there is no need to call
   {{TransformStreamDefaultController/terminate()|controller.terminate()}} inside
   {{Transformer/flush|flush()}}; the stream is already in the process of successfully closing down,
   and terminating it would be counterproductive.)

 <dt><dfn dict-member for="Transformer">readableType</dfn></dt>
 <dd>
  <p>This property is reserved for future use, so any attempts to supply a value will throw an
  exception.

 <dt><dfn dict-member for="Transformer">writableType</dfn></dt>
 <dd>
  <p>This property is reserved for future use, so any attempts to supply a value will throw an
  exception.
</dl>

The <code>controller</code> object passed to {{Transformer/start|start()}},
{{Transformer/transform|transform()}}, and {{Transformer/flush|flush()}} is an instance of
{{TransformStreamDefaultController}}, and has the ability to enqueue [=chunks=] to the [=readable
side=], or to terminate or error the stream.

<h4 id="ts-prototype">Constructor and properties</h4>

<dl class="domintro non-normative">
 <dt><code><var ignore>stream</var> = new {{TransformStream/constructor(transformer, writableStrategy, readableStrategy)|TransformStream}}([<var ignore>transformer</var>[, <var ignore>writableStrategy</var>[, <var ignore>readableStrategy</var>]]])</code>
 <dd>
  <p>Creates a new {{TransformStream}} wrapping the provided [=transformer=]. See
  [[#transformer-api]] for more details on the <var ignore>transformer</var> argument.

  <p>If no <var ignore>transformer</var> argument is supplied, then the result will be an [=identity
  transform stream=]. See <a href="#example-transform-identity">this example</a> for some cases
  where that can be useful.

  <p>The <var ignore>writableStrategy</var> and <var ignore>readableStrategy</var> arguments are
  the [=queuing strategy=] objects for the [=writable side|writable=] and [=readable
  side|readable=] sides respectively. These are used in the construction of the {{WritableStream}}
  and {{ReadableStream}} objects and can be used to add buffering to a {{TransformStream}}, in
  order to smooth out variations in the speed of the transformation, or to increase the amount of
  buffering in a [=pipe=]. If they are not provided, the default behavior will be the same as a
  {{CountQueuingStrategy}}, with respective [=high water marks=] of 1 and 0.

 <dt><code><var ignore>readable</var> = <var ignore>stream</var>.{{TransformStream/readable}}</code>
 <dd>
  <p>Returns a {{ReadableStream}} representing the [=readable side=] of this transform stream.

 <dt><code><var ignore>writable</var> = <var ignore>stream</var>.{{TransformStream/writable}}</code>
 <dd>
  <p>Returns a {{WritableStream}} representing the [=writable side=] of this transform stream.
</dl>

<div algorithm>
 The <dfn id="ts-constructor" constructor for="TransformStream" lt="TransformStream(transformer,
 writableStrategy, readableStrategy)">new TransformStream(|transformer|, |writableStrategy|,
 |readableStrategy|)</dfn> constructor steps are:

 1. If |transformer| is missing, set it to null.
 1. Let |transformerDict| be |transformer|, [=converted to an IDL value=] of type {{Transformer}}.
    <p class="note">We cannot declare the |transformer| argument as having the {{Transformer}} type
    directly, because doing so would lose the reference to the original object. We need to retain
    the object so we can [=invoke=] the various methods on it.
 1. If |transformerDict|["{{Transformer/readableType}}"] [=map/exists=], throw a {{RangeError}}
    exception.
 1. If |transformerDict|["{{Transformer/writableType}}"] [=map/exists=], throw a {{RangeError}}
    exception.
 1. Let |readableHighWaterMark| be ? [$ExtractHighWaterMark$](|readableStrategy|, 0).
 1. Let |readableSizeAlgorithm| be ! [$ExtractSizeAlgorithm$](|readableStrategy|).
 1. Let |writableHighWaterMark| be ? [$ExtractHighWaterMark$](|writableStrategy|, 1).
 1. Let |writableSizeAlgorithm| be ! [$ExtractSizeAlgorithm$](|writableStrategy|).
 1. Let |startPromise| be [=a new promise=].
 1. Perform ! [$InitializeTransformStream$]([=this=], |startPromise|, |writableHighWaterMark|,
    |writableSizeAlgorithm|, |readableHighWaterMark|, |readableSizeAlgorithm|).
 1. Perform ? [$SetUpTransformStreamDefaultControllerFromTransformer$]([=this=], |transformer|,
    |transformerDict|).
 1. Let |startPromise| be [=a new promise=].
 1. If |transformerDict|["{{Transformer/start}}"] [=map/exists=], then [=resolve=] |startPromise|
    with the result of [=invoking=] |transformerDict|["{{Transformer/start}}"] with argument list
    «&nbsp;[=this=].[=TransformStream/[[controller]]=]&nbsp;» and [=callback this value=]
    |transformer|.
 1. Otherwise, [=resolve=] |startPromise| with undefined.
</div>

<div algorithm>
 The <dfn id="ts-readable" attribute for="TransformStream">readable</dfn> getter steps
 are:

 1. Return [=this=].[=TransformStream/[[readable]]=].
</div>

<div algorithm>
 The <dfn id="ts-writable" attribute for="TransformStream">writable</dfn> getter steps
 are:

 1. Return [=this=].[=TransformStream/[[writable]]=].
</div>

<h4 id="ts-transfer">Transfer via `postMessage()`</h4>

<dl class="domintro">
 <dt><code>destination.postMessage(ts, { transfer: [ts] });</code>
 <dd>
  <p>Sends a {{TransformStream}} to another frame, window, or worker.

  <p>The transferred stream can be used exactly like the original. Its [=readable side|readable=]
  and [=writable sides=] will become locked and no longer directly usable.
 </dd>
</dl>

<div algorithm="TransformStream transfer steps">
 {{TransformStream}} objects are [=transferable objects=]. Their [=transfer steps=], given |value|
 and |dataHolder|, are:

 1. Let |readable| be |value|.[=TransformStream/[[readable]]=].
 1. Let |writable| be |value|.[=TransformStream/[[writable]]=].
 1. If ! [$IsReadableStreamLocked$](|readable|) is true, throw a "{{DataCloneError}}"
    {{DOMException}}.
 1. If ! [$IsWritableStreamLocked$](|writable|) is true, throw a "{{DataCloneError}}"
    {{DOMException}}.
 1. Set |dataHolder|.\[[readable]] to ! [$StructuredSerializeWithTransfer$](|readable|,
    « |readable| »).
 1. Set |dataHolder|.\[[writable]] to ! [$StructuredSerializeWithTransfer$](|writable|,
    « |writable| »).
</div>

<div algorithm="TransformStream transfer-receiving steps">
 Their [=transfer-receiving steps=], given |dataHolder| and |value|, are:

 1. Let |readableRecord| be ! [$StructuredDeserializeWithTransfer$](|dataHolder|.\[[readable]],
    [=the current Realm=]).
 1. Let |writableRecord| be ! [$StructuredDeserializeWithTransfer$](|dataHolder|.\[[writable]],
    [=the current Realm=]).
 1. Set |value|.[=TransformStream/[[readable]]=] to |readableRecord|.\[[Deserialized]].
 1. Set |value|.[=TransformStream/[[writable]]=] to |writableRecord|.\[[Deserialized]].
 1. Set |value|.[=TransformStream/[[backpressure]]=],
    |value|.[=TransformStream/[[backpressureChangePromise]]=], and
    |value|.[=TransformStream/[[controller]]=] to undefined.

 <p class="note">The [=TransformStream/[[backpressure]]=],
 [=TransformStream/[[backpressureChangePromise]]=], and [=TransformStream/[[controller]]=] slots are
 not used in a transferred {{TransformStream}}.</p>
</div>

<h3 id="ts-default-controller-class">The {{TransformStreamDefaultController}} class</h3>

The {{TransformStreamDefaultController}} class has methods that allow manipulation of the
associated {{ReadableStream}} and {{WritableStream}}. When constructing a {{TransformStream}}, the
[=transformer=] object is given a corresponding {{TransformStreamDefaultController}} instance to
manipulate.

<h4 id="ts-default-controller-class-definition">Interface definition</h4>

The Web IDL definition for the {{TransformStreamDefaultController}} class is given as follows:

<xmp class="idl">
[Exposed=(Window,Worker,Worklet)]
interface TransformStreamDefaultController {
  readonly attribute unrestricted double? desiredSize;

  void enqueue(optional any chunk);
  void error(optional any reason);
  void terminate();
};
</xmp>

<h4 id="ts-default-controller-internal-slots">Internal slots</h4>

Instances of {{TransformStreamDefaultController}} are created with the internal slots described in
the following table:

<table dfn-for="TransformStreamDefaultController">
 <thead>
  <tr>
   <th>Internal Slot</th>
   <th>Description (<em>non-normative</em>)</th>
 <tbody>
  <tr>
   <td><dfn>\[[flushAlgorithm]]</dfn>
   <td class="non-normative">A promise-returning algorithm which communicates a requested close to
   the [=transformer=]
  <tr>
   <td><dfn>\[[stream]]</dfn>
   <td class="non-normative">The {{TransformStream}} instance controlled
  <tr>
   <td><dfn>\[[transformAlgorithm]]</dfn>
   <td class="non-normative">A promise-returning algorithm, taking one argument (the [=chunk=] to
   transform), which requests the [=transformer=] perform its transformation
</table>

<h4 id="ts-default-controller-prototype">Methods and properties</h4>

<dl class="domintro non-normative">
 <dt><code><var ignore>desiredSize</var> = <var ignore>controller</var>.{{TransformStreamDefaultController/desiredSize}}</code>
 <dd>
  <p>Returns the [=desired size to fill a stream's internal queue|desired size to fill the
  readable side's internal queue=]. It can be negative, if the queue is over-full.

 <dt><code><var ignore>controller</var>.{{TransformStreamDefaultController/enqueue()|enqueue}}(<var ignore>chunk</var>)</code>
 <dd>
  <p>Enqueues the given [=chunk=] <var ignore>chunk</var> in the [=readable side=] of the controlled
  transform stream.

 <dt><code><var ignore>controller</var>.{{TransformStreamDefaultController/error()|error}}(<var ignore>e</var>)</code>
 <dd>
  <p>Errors the both the [=readable side=] and the [=writable side=] of the controlled transform
  stream, making all future interactions with it fail with the given error <var ignore>e</var>. Any
  [=chunks=] queued for transformation will be discarded.

 <dt><code><var ignore>controller</var>.{{TransformStreamDefaultController/terminate()|terminate}}()</code>
 <dd>
  <p>Closes the [=readable side=] and errors the [=writable side=] of the controlled transform
  stream. This is useful when the [=transformer=] only needs to consume a portion of the [=chunks=]
  written to the [=writable side=].
</dl>

<div algorithm>
 The <dfn id="ts-default-controller-desired-size" attribute
 for="TransformStreamDefaultController">desiredSize</dfn> getter steps are:

 1. Let |readableController| be [=this=].[=TransformStreamDefaultController/[[stream]]=].[=TransformStream/[[readable]]=].[=ReadableStream/[[controller]]=].
 1. Return ! [$ReadableStreamDefaultControllerGetDesiredSize$](|readableController|).
</div>

<div algorithm>
 The <dfn id="ts-default-controller-enqueue" method
 for="TransformStreamDefaultController">enqueue(|chunk|)</dfn> method steps are:

 1. Perform ? [$TransformStreamDefaultControllerEnqueue$]([=this=], |chunk|).
</div>

<div algorithm>
 The <dfn id="ts-default-controller-error" method
 for="TransformStreamDefaultController">error(|e|)</dfn> method steps are:

 1. Perform ? [$TransformStreamDefaultControllerError$]([=this=], |e|).
</div>

<div algorithm>
 The <dfn id="ts-default-controller-terminate" method
 for="TransformStreamDefaultController">terminate()</dfn> method steps are:

 1. Perform ? [$TransformStreamDefaultControllerTerminate$]([=this=]).
</div>

<h3 id="ts-all-abstract-ops">Abstract operations</h3>

<h4 id="ts-abstract-ops">Working with transform streams</h4>

The following abstract operations operate on {{TransformStream}} instances at a higher level. Some
are even meant to be generally useful by other specifications.

<div algorithm>
 <dfn abstract-op lt="CreateTransformStream" id="create-transform-stream"
 export>CreateTransformStream(|startAlgorithm|, |transformAlgorithm|, |flushAlgorithm|[,
 |writableHighWaterMark|[, |writableSizeAlgorithm|[, |readableHighWaterMark|[,
 |readableSizeAlgorithm|]]]])</dfn> is meant to be called from other specifications that wish to
 create {{TransformStream}} instances. The |transformAlgorithm| and |flushAlgorithm| algorithms
 must return promises; if supplied, |writableHighWaterMark| and |readableHighWaterMark| must be
 non-negative, non-NaN numbers; and if supplied, |writableSizeAlgorithm| and
 |readableSizeAlgorithm| must be algorithms accepting [=chunk=] objects and returning numbers.

 It performs the following steps:

 1. If |writableHighWaterMark| was not passed, set it to 1.
 1. If |writableSizeAlgorithm| was not passed, set it to an algorithm that returns 1.
 1. If |readableHighWaterMark| was not passed, set it to 0.
 1. If |readableSizeAlgorithm| was not passed, set it to an algorithm that returns 1.
 1. Assert: ! [$IsNonNegativeNumber$](|writableHighWaterMark|) is true.
 1. Assert: ! [$IsNonNegativeNumber$](|readableHighWaterMark|) is true.
 1. Let |stream| be a [=new=] {{TransformStream}}.
 1. Let |startPromise| be [=a new promise=].
 1. Perform ! [$InitializeTransformStream$](|stream|, |startPromise|, |writableHighWaterMark|,
    |writableSizeAlgorithm|, |readableHighWaterMark|, |readableSizeAlgorithm|).
 1. Let |controller| be a [=new=] {{TransformStreamDefaultController}}.
 1. Perform ! [$SetUpTransformStreamDefaultController$](|stream|, |controller|,
    |transformAlgorithm|, |flushAlgorithm|).
 1. Let |startResult| be the result of performing |startAlgorithm|. (This may throw an exception.)
 1. [=Resolve=] |startPromise| with |startResult|.
 1. Return |stream|.

 <p class="note">This abstract operation will throw an exception if and only if the supplied
 |startAlgorithm| throws.
</div>

<div algorithm>
 <dfn abstract-op lt="InitializeTransformStream"
 id="initialize-transform-stream">InitializeTransformStream(|stream|, |startPromise|,
 |writableHighWaterMark|, |writableSizeAlgorithm|, |readableHighWaterMark|,
 |readableSizeAlgorithm|)</dfn> performs the following steps:

 1. Let |startAlgorithm| be an algorithm that returns |startPromise|.
 1. Let |writeAlgorithm| be the following steps, taking a |chunk| argument:
  1. Return ! [$TransformStreamDefaultSinkWriteAlgorithm$](|stream|, |chunk|).
 1. Let |abortAlgorithm| be the following steps, taking a |reason| argument:
  1. Return ! [$TransformStreamDefaultSinkAbortAlgorithm$](|stream|, |reason|).
 1. Let |closeAlgorithm| be the following steps:
  1. Return ! [$TransformStreamDefaultSinkCloseAlgorithm$](|stream|).
 1. Set |stream|.[=TransformStream/[[writable]]=] to ! [$CreateWritableStream$](|startAlgorithm|,
    |writeAlgorithm|, |closeAlgorithm|, |abortAlgorithm|, |writableHighWaterMark|,
    |writableSizeAlgorithm|).
 1. Let |pullAlgorithm| be the following steps:
  1. Return ! [$TransformStreamDefaultSourcePullAlgorithm$](|stream|).
 1. Let |cancelAlgorithm| be the following steps, taking a |reason| argument:
  1. Perform ! [$TransformStreamErrorWritableAndUnblockWrite$](|stream|, |reason|).
  1. Return [=a promise resolved with=] undefined.
 1. Set |stream|.[=TransformStream/[[readable]]=] to ! [$CreateReadableStream$](|startAlgorithm|,
    |pullAlgorithm|, |cancelAlgorithm|, |readableHighWaterMark|, |readableSizeAlgorithm|).
 1. Set |stream|.[=TransformStream/[[backpressure]]=] and
    |stream|.[=TransformStream/[[backpressureChangePromise]]=] to undefined.
    <p class="note">The [=TransformStream/[[backpressure]]=] slot is set to undefined so that it can
    be initialized by [$TransformStreamSetBackpressure$]. Alternatively, implementations can use a
    strictly boolean value for [=TransformStream/[[backpressure]]=] and change the way it is
    initialized. This will not be visible to user code so long as the initialization is correctly
    completed before the transformer's {{Transformer/start|start()}} method is called.
 1. Perform ! [$TransformStreamSetBackpressure$](|stream|, true).
 1. Set |stream|.[=TransformStream/[[controller]]=] to undefined.
</div>

<div algorithm>
 <dfn abstract-op lt="TransformStreamError"
 id="transform-stream-error">TransformStreamError(|stream|, |e|)</dfn> performs the following steps:

 1. Perform ! [$ReadableStreamDefaultControllerError$](|stream|.[=TransformStream/[[readable]]=].[=ReadableStream/[[controller]]=], |e|).
 1. Perform ! [$TransformStreamErrorWritableAndUnblockWrite$](|stream|, |e|).

 <p class="note">This operation works correctly when one or both sides are already errored. As a
 result, calling algorithms do not need to check stream states when responding to an error
 condition.
</div>

<div algorithm>
 <dfn abstract-op lt="TransformStreamErrorWritableAndUnblockWrite"
 id="transform-stream-error-writable-and-unblock-write">TransformStreamErrorWritableAndUnblockWrite(|stream|,
 |e|)</dfn> performs the following steps:

 1. Perform ! [$TransformStreamDefaultControllerClearAlgorithms$](|stream|.[=TransformStream/[[controller]]=]).
 1. Perform !
    [$WritableStreamDefaultControllerErrorIfNeeded$](|stream|.[=TransformStream/[[writable]]=].[=WritableStream/[[controller]]=], |e|).
 1. If |stream|.[=TransformStream/[[backpressure]]=] is true, perform ! [$TransformStreamSetBackpressure$](|stream|,
    false).

 <p class="note">The [$TransformStreamDefaultSinkWriteAlgorithm$] abstract operation could be
 waiting for the promise stored in the [=TransformStream/[[backpressureChangePromise]]=] slot to
 resolve. The call to [$TransformStreamSetBackpressure$] ensures that the promise always resolves.
</div>

<div algorithm>
 <dfn abstract-op lt="TransformStreamSetBackpressure"
 id="transform-stream-set-backpressure">TransformStreamSetBackpressure(|stream|,
 |backpressure|)</dfn> performs the following steps:

 1. Assert: |stream|.[=TransformStream/[[backpressure]]=] is not |backpressure|.
 1. If |stream|.[=TransformStream/[[backpressureChangePromise]]=] is not undefined, [=resolve=]
    stream.[=TransformStream/[[backpressureChangePromise]]=] with undefined.
 1. Set |stream|.[=TransformStream/[[backpressureChangePromise]]=] to [=a new promise=].
 1. Set |stream|.[=TransformStream/[[backpressure]]=] to |backpressure|.
</div>

<h4 id="ts-default-controller-abstract-ops">Default controllers</h4>

The following abstract operations support the implementaiton of the
{{TransformStreamDefaultController}} class.

<div algorithm>
 <dfn abstract-op lt="SetUpTransformStreamDefaultController"
 id="set-up-transform-stream-default-controller">SetUpTransformStreamDefaultController(|stream|,
 |controller|, |transformAlgorithm|, |flushAlgorithm|)</dfn> performs the following steps:

 1. Assert: |stream| [=implements=] {{TransformStream}}.
 1. Assert: |stream|.[=TransformStream/[[controller]]=] is undefined.
 1. Set |controller|.[=TransformStreamDefaultController/[[stream]]=] to |stream|.
 1. Set |stream|.[=TransformStream/[[controller]]=] to |controller|.
 1. Set |controller|.[=TransformStreamDefaultController/[[transformAlgorithm]]=] to
    |transformAlgorithm|.
 1. Set |controller|.[=TransformStreamDefaultController/[[flushAlgorithm]]=] to |flushAlgorithm|.
</div>

<div algorithm>
 <dfn abstract-op lt="SetUpTransformStreamDefaultControllerFromTransformer"
 id="set-up-transform-stream-default-controller-from-transformer">SetUpTransformStreamDefaultControllerFromTransformer(|stream|,
 |transformer|, |transformerDict|)</dfn> performs the following steps:

 1. Let |controller| be a [=new=] {{TransformStreamDefaultController}}.
 1. Let |transformAlgorithm| be the following steps, taking a |chunk| argument:
  1. Let |result| be [$TransformStreamDefaultControllerEnqueue$](|controller|, |chunk|).
  1. If |result| is an abrupt completion, return [=a promise rejected with=] |result|.\[[Value]].
  1. Otherwise, return [=a promise resolved with=] undefined.
 1. Let |flushAlgorithm| be an algorithm which returns [=a promise resolved with=] undefined.
 1. If |transformerDict|["{{Transformer/transform}}"] [=map/exists=], set |transformAlgorithm| to an
    algorithm which takes an argument |chunk| and returns the result of [=invoking=]
    |transformerDict|["{{Transformer/transform}}"] with argument list «&nbsp;|chunk|,
    |controller|&nbsp;») and [=callback this value=] |transformer|.
 1. If |transformerDict|["{{Transformer/flush}}"] [=map/exists=], set |flushAlgorithm| to an
    algorithm which returns the result of [=invoking=] |transformerDict|["{{Transformer/flush}}"]
    with argument list «&nbsp;|controller|&nbsp;» and [=callback this value=] |transformer|.
 1. Perform ! [$SetUpTransformStreamDefaultController$](|stream|, |controller|,
    |transformAlgorithm|, |flushAlgorithm|).
</div>

<div algorithm>
 <dfn abstract-op lt="TransformStreamDefaultControllerClearAlgorithms"
 id="transform-stream-default-controller-clear-algorithms">TransformStreamDefaultControllerClearAlgorithms(|controller|)</dfn>
 is called once the stream is closed or errored and the algorithms will not be executed any more.
 By removing the algorithm references it permits the [=transformer=] object to be garbage collected
 even if the {{TransformStream}} itself is still referenced.

 <p class="note">This is observable using <a href="https://github.com/tc39/proposal-weakrefs/">weak
 references</a>. See <a
 href="https://github.com/tc39/proposal-weakrefs/issues/31">tc39/proposal-weakrefs#31</a> for more
 detail.

 It performs the following steps:

 1. Set |controller|.[=TransformStreamDefaultController/[[transformAlgorithm]]=] to undefined.
 1. Set |controller|.[=TransformStreamDefaultController/[[flushAlgorithm]]=] to undefined.
</div>

<div algorithm>
 <dfn abstract-op lt="TransformStreamDefaultControllerEnqueue"
 id="transform-stream-default-controller-enqueue"
 export>TransformStreamDefaultControllerEnqueue(|controller|, |chunk|)</dfn> is meant to be called
 by other specifications that wish to enqueue [=chunks=] in the [=readable side=], in the same way
 a developer would enqueue chunks using the stream's associated controller object. Specifications
 should <em>not</em> do this to streams or controllers they did not create.

 It performs the following steps:

 1. Let |stream| be |controller|.[=TransformStreamDefaultController/[[stream]]=].
 1. Let |readableController| be
    |stream|.[=TransformStream/[[readable]]=].[=ReadableStream/[[controller]]=].
 1. If ! [$ReadableStreamDefaultControllerCanCloseOrEnqueue$](|readableController|) is false, throw
    a {{TypeError}} exception.
 1. Let |enqueueResult| be [$ReadableStreamDefaultControllerEnqueue$](|readableController|,
    |chunk|).
 1. If |enqueueResult| is an abrupt completion,
   1. Perform ! [$TransformStreamErrorWritableAndUnblockWrite$](|stream|,
      |enqueueResult|.\[[Value]]).
   1. Throw |stream|.[=TransformStream/[[readable]]=].[=ReadableStream/[[storedError]]=].
 1. Let |backpressure| be !
    [$ReadableStreamDefaultControllerHasBackpressure$](|readableController|).
 1. If |backpressure| is not |stream|.[=TransformStream/[[backpressure]]=],
   1. Assert: |backpressure| is true.
   1. Perform ! [$TransformStreamSetBackpressure$](|stream|, true).
</div>
<div algorithm>
 <dfn abstract-op lt="TransformStreamDefaultControllerError"
 id="transform-stream-default-controller-error"
 export>TransformStreamDefaultControllerError(|controller|, |e|)</dfn> is meant to be called by
 other specifications that wish to move the transform stream to an errored state, in the same way a
 developer would error the stream using the stream's associated controller object. Specifications
 should <em>not</em> do this to streams or controllers they did not create.

 It performs the following steps:

 1. Perform ! [$TransformStreamError$](|controller|.[=TransformStreamDefaultController/[[stream]]=],
    |e|).
</div>

<div algorithm>
 <dfn abstract-op lt="TransformStreamDefaultControllerPerformTransform"
 id="transform-stream-default-controller-perform-transform">TransformStreamDefaultControllerPerformTransform(|controller|, |chunk|)</dfn>
 performs the following steps:

 1. Let |transformPromise| be the result of performing
    |controller|.[=TransformStreamDefaultController/[[transformAlgorithm]]=], passing |chunk|.
 1. Return the result of [=reacting=] to |transformPromise| with the following
    rejection steps given the argument |r|:
   1. Perform !
      [$TransformStreamError$](|controller|.[=TransformStreamDefaultController/[[stream]]=], |r|).
   1. Throw |r|.
</div>

<div algorithm>
 <dfn abstract-op lt="TransformStreamDefaultControllerTerminate"
 id="transform-stream-default-controller-terminate"
 export>TransformStreamDefaultControllerTerminate(|controller|)</dfn> is meant to be called by
 other specifications that wish to terminate the transform stream, in the same way a
 developer-created stream would be terminated by its associated controller object. Specifications
 should <em>not</em> do this to streams or controllers they did not create.

 It performs the following steps:

 1. Let |stream| be |controller|.[=TransformStreamDefaultController/[[stream]]=].
 1. Let |readableController| be
    |stream|.[=TransformStream/[[readable]]=].[=ReadableStream/[[controller]]=].
 1. Perform ! [$ReadableStreamDefaultControllerClose$](|readableController|).
 1. Let |error| be a {{TypeError}} exception indicating that the stream has been terminated.
 1. Perform ! [$TransformStreamErrorWritableAndUnblockWrite$](|stream|, |error|).
</div>

<h4 id="ts-default-sink-abstract-ops">Default sinks</h4>

The following abstract operations are used to implement the [=underlying sink=] for the [=writable
side=] of [=transform streams=].

<div algorithm>
 <dfn abstract-op lt="TransformStreamDefaultSinkWriteAlgorithm"
 id="transform-stream-default-sink-write-algorithm">TransformStreamDefaultSinkWriteAlgorithm(|stream|,
 |chunk|)</dfn> performs the following steps:

 1. Assert: |stream|.[=TransformStream/[[writable]]=].[=WritableStream/[[state]]=] is "`writable`".
 1. Let |controller| be |stream|.[=TransformStream/[[controller]]=].
 1. If |stream|.[=TransformStream/[[backpressure]]=] is true,
  1. Let |backpressureChangePromise| be |stream|.[=TransformStream/[[backpressureChangePromise]]=].
  1. Assert: |backpressureChangePromise| is not undefined.
  1. Return the result of [=reacting=] to |backpressureChangePromise| with the following fulfillment
     steps:
   1. Let |writable| be |stream|.[=TransformStream/[[writable]]=].
   1. Let |state| be |writable|.[=WritableStream/[[state]]=].
   1. If |state| is "`erroring`", throw |writable|.[=WritableStream/[[storedError]]=].
   1. Assert: |state| is "`writable`".
   1. Return ! [$TransformStreamDefaultControllerPerformTransform$](|controller|, |chunk|).
 1. Return ! [$TransformStreamDefaultControllerPerformTransform$](|controller|, |chunk|).
</div>

<div algorithm>
 <dfn abstract-op lt="TransformStreamDefaultSinkAbortAlgorithm"
 id="transform-stream-default-sink-abort-algorithm">TransformStreamDefaultSinkAbortAlgorithm(|stream|,
 |reason|)</dfn> performs the following steps:

 1. Perform ! [$TransformStreamError$](|stream|, |reason|).
 1. Return [=a promise resolved with=] undefined.
</div>

<div algorithm>
 <dfn abstract-op lt="TransformStreamDefaultSinkCloseAlgorithm"
 id="transform-stream-default-sink-close-algorithm">TransformStreamDefaultSinkCloseAlgorithm(|stream|)</dfn>
 performs the following steps:

 1. Let |readable| be |stream|.[=TransformStream/[[readable]]=].
 1. Let |controller| be |stream|.[=TransformStream/[[controller]]=].
 1. Let |flushPromise| be the result of performing
    |controller|.[=TransformStreamDefaultController/[[flushAlgorithm]]=].
 1. Perform ! [$TransformStreamDefaultControllerClearAlgorithms$](|controller|).
 1. Return the result of [=reacting=] to |flushPromise|:
  1. If |flushPromise| was fulfilled, then:
   1. If |readable|.[=ReadableStream/[[state]]=] is "`errored`", throw
      |readable|.[=ReadableStream/[[storedError]]=].
   1. Perform !
      [$ReadableStreamDefaultControllerClose$](|readable|.[=ReadableStream/[[controller]]=]).
  1. If |flushPromise| was rejected with reason |r|, then:
   1. Perform ! [$TransformStreamError$](|stream|, |r|).
   1. Throw |readable|.[=ReadableStream/[[storedError]]=].
</div>

<h4 id="ts-default-source-abstract-ops">Default sources</h4>

The following abstract operation is used to implement the [=underlying source=] for the [=readable
side=] of [=transform streams=].

<div algorithm>
 <dfn abstract-op lt="TransformStreamDefaultSourcePullAlgorithm"
 id="transform-stream-default-source-pull">TransformStreamDefaultSourcePullAlgorithm(|stream|)</dfn>
 performs the following steps:

 1. Assert: |stream|.[=TransformStream/[[backpressure]]=] is true.
 1. Assert: |stream|.[=TransformStream/[[backpressureChangePromise]]=] is not undefined.
 1. Perform ! [$TransformStreamSetBackpressure$](|stream|, false).
 1. Return |stream|.[=TransformStream/[[backpressureChangePromise]]=].
</div>

<h2 id="qs">Queuing strategies</h2>

<h3 id="qs-api">The queuing strategy API</h3>

The {{ReadableStream()}}, {{WritableStream()}}, and {{TransformStream()}} constructors all accept
at least one argument representing an appropriate [=queuing strategy=] for the stream being
created. Such objects contain the following properties:

<xmp class="idl">
dictionary QueuingStrategy {
  unrestricted double highWaterMark;
  QueuingStrategySize size;
};

callback QueuingStrategySize = unrestricted double (optional any chunk);
</xmp>

<dl>
 <dt><dfn dict-member for="QueuingStrategy">highWaterMark</dfn></dt>
 <dd>
  <p>A non-negative number indicating the [=high water mark=] of the stream using this queuing
  strategy.

 <dt><dfn dict-member for="QueuingStrategy" lt="size">size(<var ignore>chunk</var>)</dfn> (non-byte streams only)</dt>
 <dd>
  <p>A function that computes and returns the finite non-negative size of the given [=chunk=]
  value.

  <p>The result is used to determine [=backpressure=], manifesting via the appropriate
  <code>desiredSize</code>
  property: either {{ReadableStreamDefaultController/desiredSize|defaultController.desiredSize}},
  {{ReadableByteStreamController/desiredSize|byteController.desiredSize}}, or
  {{WritableStreamDefaultWriter/desiredSize|writer.desiredSize}}, depending on where the queuing
  strategy is being used. For readable streams, it also governs when the [=underlying source=]'s
  {{UnderlyingSource/pull|pull()}} method is called.

  <p>This function has to be idempotent and not cause side effects; very strange results can occur
  otherwise.

  <p>For [=readable byte streams=], this function is not used, as chunks are always measured in
  bytes.
</dl>

Any object with these properties can be used when a queuing strategy object is expected. However,
we provide two built-in queuing strategy classes that provide a common vocabulary for certain
cases: {{ByteLengthQueuingStrategy}} and {{CountQueuingStrategy}}. They both make use of the
following Web IDL fragment for their constructors:

<xmp class="idl">
dictionary QueuingStrategyInit {
  required unrestricted double highWaterMark;
};
</xmp>

<h3 id="blqs-class">The {{ByteLengthQueuingStrategy}} class</h3>

A common [=queuing strategy=] when dealing with bytes is to wait until the accumulated
<code>byteLength</code> properties of the incoming [=chunks=] reaches a specified high-water mark.
As such, this is provided as a built-in [=queuing strategy=] that can be used when constructing
streams.

<div class="example" id="example-blqs">
 When creating a [=readable stream=] or [=writable stream=], you can supply a byte-length queuing
 strategy directly:

 <xmp highlight="js">
 const stream = new ReadableStream(
   { ... },
   new ByteLengthQueuingStrategy({ highWaterMark: 16 * 1024 })
 );
 </xmp>

 In this case, 16 KiB worth of [=chunks=] can be enqueued by the readable stream's [=underlying
 source=] before the readable stream implementation starts sending [=backpressure=] signals to the
 underlying source.

 <xmp highlight="js">
 const stream = new WritableStream(
   { ... },
   new ByteLengthQueuingStrategy({ highWaterMark: 32 * 1024 })
 );
 </xmp>

 In this case, 32 KiB worth of [=chunks=] can be accumulated in the writable stream's internal
 queue, waiting for previous writes to the [=underlying sink=] to finish, before the writable
 stream starts sending [=backpressure=] signals to any [=producers=].
</div>

<p class="note">It is not necessary to use {{ByteLengthQueuingStrategy}} with [=readable byte
streams=], as they always measure chunks in bytes. Attempting to construct a byte stream with a
{{ByteLengthQueuingStrategy}} will fail.

<h4 id="blqs-class-definition">Interface definition</h4>

The Web IDL definition for the {{ByteLengthQueuingStrategy}} class is given as follows:

<xmp class="idl">
[Exposed=(Window,Worker,Worklet)]
interface ByteLengthQueuingStrategy {
  constructor(QueuingStrategyInit init);

  readonly attribute unrestricted double highWaterMark;
  readonly attribute Function size;
};
</xmp>

<h4 id="blqs-internal-slots">Internal slots</h4>

Instances of {{ByteLengthQueuingStrategy}} have a
<dfn for="ByteLengthQueuingStrategy">\[[highWaterMark]]</dfn> internal slot, storing the value given
in the constructor.

<div algorithm>
 Additionally, every [=/global object=] |globalObject| has an associated <dfn>byte length queuing
 strategy size function</dfn>, which is a {{Function}} whose value must be initialized as follows:

 1. Let |steps| be the following steps, given |chunk|:
  1. Return ? [$GetV$](|chunk|, "`byteLength`").
 1. Let |F| be ! [$CreateBuiltinFunction$](|steps|, « », |globalObject|'s [=relevant Realm=]).
 1. Perform ! [$SetFunctionName$](|F|, "`size`").
 1. Perform ! [$SetFunctionLength$](|F|, 1).
 1. Set |globalObject|'s [=byte length queuing strategy size function=] to a {{Function}} that
    represents a reference to |F|, with [=callback context=] equal to |globalObject|'s [=relevant
    settings object=].

 <p class="note">This design is somewhat historical. It is motivated by the desire to ensure that
 {{ByteLengthQueuingStrategy/size}} is a function, not a method, i.e. it does not check its
 <code>this</code> value. See <a
 href="https://github.com/whatwg/streams/issues/1005">whatwg/streams#1005</a> and <a
 href="https://github.com/heycam/webidl/issues/819">heycam/webidl#819</a> for more background.
</div>

<h4 id="blqs-prototype">Constructor and properties</h4>

<dl class="domintro non-normative">
 <dt><code><var ignore>strategy</var> = new {{ByteLengthQueuingStrategy/constructor(init)|ByteLengthQueuingStrategy}}({ {{QueuingStrategyInit/highWaterMark}} })</code>
  <dd>
   <p>Creates a new {{ByteLengthQueuingStrategy}} with the provided [=high water mark=].

   <p>Note that the provided high water mark will not be validated ahead of time. Instead, if it is
   negative, NaN, or not a number, the resulting {{ByteLengthQueuingStrategy}} will cause the
   corresponding stream constructor to throw.

 <dt><code><var ignore>highWaterMark</var> = <var ignore>strategy</var>.{{ByteLengthQueuingStrategy/highWaterMark}}</code>
 <dd>
  <p>Returns the [=high water mark=] provided to the constructor.

 <dt><code><var ignore>strategy</var>.{{ByteLengthQueuingStrategy/size}}(<var ignore>chunk</var>)</code>
 <dd>
  <p>Measures the size of <var ignore>chunk</var> by returning the value of its
  <code>byteLength</code> property.
</dl>

<div algorithm>
 The <dfn id="blqs-constructor" constructor for="ByteLengthQueuingStrategy"
 lt="ByteLengthQueuingStrategy(init)">new ByteLengthQueuingStrategy(|init|)</dfn> constructor steps
 are:

 1. Set [=this=].[=ByteLengthQueuingStrategy/[[highWaterMark]]=] to
    |init|["{{QueuingStrategyInit/highWaterMark}}"].
</div>

<div algorithm>
 The <dfn id="blqs-high-water-mark" attribute for="ByteLengthQueuingStrategy">highWaterMark</dfn>
 getter steps are:

 1. Return [=this=].[=ByteLengthQueuingStrategy/[[highWaterMark]]=].
</div>

<div algorithm>
 The <dfn id="blqs-size" attribute for="ByteLengthQueuingStrategy">size</dfn> getter steps are:

 1. Return [=this=]'s [=relevant global object=]'s [=byte length queuing strategy size function=].
</div>

<h3 id="cqs-class">The {{CountQueuingStrategy}} class</h3>

A common [=queuing strategy=] when dealing with streams of generic objects is to simply count the
number of chunks that have been accumulated so far, waiting until this number reaches a specified
high-water mark. As such, this strategy is also provided out of the box.

<div class="example" id="example-cqs">
 When creating a [=readable stream=] or [=writable stream=], you can supply a count queuing
 strategy directly:

 <xmp highlight="js">
 const stream = new ReadableStream(
   { ... },
   new CountQueuingStrategy({ highWaterMark: 10 })
 );
 </xmp>

 In this case, 10 [=chunks=] (of any kind) can be enqueued by the readable stream's [=underlying
 source=] before the readable stream implementation starts sending [=backpressure=] signals to the
 underlying source.

 <xmp highlight="js">
 const stream = new WritableStream(
   { ... },
   new CountQueuingStrategy({ highWaterMark: 5 })
 );
 </xmp>

 In this case, five [=chunks=] (of any kind) can be accumulated in the writable stream's internal
 queue, waiting for previous writes to the [=underlying sink=] to finish, before the writable
 stream starts sending [=backpressure=] signals to any [=producers=].
</div>

<h4 id="cqs-class-definition">Interface definition</h4>

The Web IDL definition for the {{CountQueuingStrategy}} class is given as follows:

<xmp class="idl">
[Exposed=(Window,Worker,Worklet)]
interface CountQueuingStrategy {
  constructor(QueuingStrategyInit init);

  readonly attribute unrestricted double highWaterMark;
  readonly attribute Function size;
};
</xmp>

<h4 id="cqs-internal-slots">Internal slots</h4>

Instances of {{CountQueuingStrategy}} have a <dfn for="CountQueuingStrategy">\[[highWaterMark]]</dfn>
internal slot, storing the value given in the constructor.

<div algorithm>
 Additionally, every [=/global object=] |globalObject| has an associated <dfn>count queuing strategy
 size function</dfn>, which is a {{Function}} whose value must be initialized as follows:

 1. Let |steps| be the following steps:
  1. Return 1.
 1. Let |F| be ! [$CreateBuiltinFunction$](|steps|, « », |globalObject|'s [=relevant Realm=]).
 1. Perform ! [$SetFunctionName$](|F|, "`size`").
 1. Perform ! [$SetFunctionLength$](|F|, 0).
 1. Set |globalObject|'s [=count queuing strategy size function=] to a {{Function}} that represents
    a reference to |F|, with [=callback context=] equal to |globalObject|'s [=relevant settings
    object=].

 <p class="note">This design is somewhat historical. It is motivated by the desire to ensure that
 {{CountQueuingStrategy/size}} is a function, not a method, i.e. it does not check its
 <code>this</code> value. See <a
 href="https://github.com/whatwg/streams/issues/1005">whatwg/streams#1005</a> and <a
 href="https://github.com/heycam/webidl/issues/819">heycam/webidl#819</a> for more background.
</div>

<h4 id="cqs-prototype">Constructor and properties</h4>

<dl class="domintro non-normative">
 <dt><code><var ignore>strategy</var> = new {{CountQueuingStrategy/constructor(init)|CountQueuingStrategy}}({ {{QueuingStrategyInit/highWaterMark}} })</code>
  <dd>
   <p>Creates a new {{CountQueuingStrategy}} with the provided [=high water mark=].

   <p>Note that the provided high water mark will not be validated ahead of time. Instead, if it is
   negative, NaN, or not a number, the resulting {{CountQueuingStrategy}} will cause the
   corresponding stream constructor to throw.

 <dt><code><var ignore>highWaterMark</var> = <var ignore>strategy</var>.{{CountQueuingStrategy/highWaterMark}}</code>
 <dd>
  <p>Returns the [=high water mark=] provided to the constructor.

 <dt><code><var ignore>strategy</var>.{{CountQueuingStrategy/size}}(<var ignore>chunk</var>)</code>
 <dd>
  <p>Measures the size of <var ignore>chunk</var> by always returning 1. This ensures that the total
  queue size is a count of the number of chunks in the queue.
</dl>

<div algorithm>
 The <dfn id="cqs-constructor" constructor for="CountQueuingStrategy"
 lt="CountQueuingStrategy(init)">new CountQueuingStrategy(|init|)</dfn> constructor steps are:

 1. Set [=this=].[=CountQueuingStrategy/[[highWaterMark]]=] to
    |init|["{{QueuingStrategyInit/highWaterMark}}"].
</div>

<div algorithm>
 The <dfn id="cqs-high-water-mark" attribute for="CountQueuingStrategy">highWaterMark</dfn>
 getter steps are:

 1. Return [=this=].[=CountQueuingStrategy/[[highWaterMark]]=].
</div>

<div algorithm>
 The <dfn id="cqs-size" attribute for="CountQueuingStrategy">size</dfn> getter steps are:

 1. Return [=this=]'s [=relevant global object=]'s [=count queuing strategy size function=].
</div>

<h3 id="qs-abstract-ops">Abstract operations</h3>

The following algorithms are used by the stream constructors to extract the relevant pieces from
a {{QueuingStrategy}} dictionary.

<div algorithm>
 <dfn abstract-op lt="ExtractHighWaterMark"
 id="validate-and-normalize-high-water-mark">ExtractHighWaterMark(|strategy|, |defaultHWM|)</dfn>
 performs the following steps:

 1. If |strategy|["{{QueuingStrategy/highWaterMark}}"] does not [=map/exist=], return |defaultHWM|.
 1. Let |highWaterMark| be |strategy|["{{QueuingStrategy/highWaterMark}}"].
 1. If |highWaterMark| is NaN or |highWaterMark| &lt; 0, throw a {{RangeError}} exception.
 1. Return |highWaterMark|.

 <p class="note">+∞ is explicitly allowed as a valid [=high water mark=]. It causes [=backpressure=]
 to never be applied.
</div>

<div algorithm>
 <dfn abstract-op lt="ExtractSizeAlgorithm"
 id="make-size-algorithm-from-size-function">ExtractSizeAlgorithm(|strategy|)</dfn>
 performs the following steps:

 1. If |strategy|["{{QueuingStrategy/size}}"] does not [=map/exist=], return an algorithm that
    returns 1.
 1. Return an algorithm that performs the following steps, taking a |chunk| argument:
  1. Return the result of [=invoke|invoking=] |strategy|["{{QueuingStrategy/size}}"] with argument
     list «&nbsp;|chunk|&nbsp;».
</div>

<h2 id="other-stuff">Supporting abstract operations</h4>

The following abstract operations each support the implementation of more than one type of stream,
and as such are not grouped under the major sections above.

<h3 id="queue-with-sizes">Queue-with-sizes</h3>

The streams in this specification use a "queue-with-sizes" data structure to store queued up
values, along with their determined sizes. Various specification objects contain a
queue-with-sizes, represented by the object having two paired internal slots, always named
\[[queue]] and \[[queueTotalSize]]. \[[queue]] is a [=list=] of [=value-with-sizes=], and
\[[queueTotalSize]] is a JavaScript {{Number}}, i.e. a double-precision floating point number.

The following abstract operations are used when operating on objects that contain
queues-with-sizes, in order to ensure that the two internal slots stay synchronized.

<p class="warning">Due to the limited precision of floating-point arithmetic, the framework
specified here, of keeping a running total in the \[[queueTotalSize]] slot, is <em>not</em>
equivalent to adding up the size of all [=chunks=] in \[[queue]]. (However, this only makes a
difference when there is a huge (~10<sup>15</sup>) variance in size between chunks, or when
trillions of chunks are enqueued.)

In what follows, a <dfn>value-with-size</dfn> is a [=struct=] with the two [=struct/items=] <dfn
for="value-with-size">value</dfn> and <dfn for="value-with-size">size</dfn>.

<div algorithm>
 <dfn abstract-op lt="DequeueValue" id="dequeue-value">DequeueValue(|container|)</dfn> performs the
 following steps:

 1. Assert: |container| has \[[queue]] and \[[queueTotalSize]] internal slots.
 1. Assert: |container|.\[[queue]] is not [=list/is empty|empty=].
 1. Let |valueWithSize| be |container|.\[[queue]][0].
 1. [=list/Remove=] |valueWithSize| from |container|.\[[queue]].
 1. Set |container|.\[[queueTotalSize]] to |container|.\[[queueTotalSize]] − |valueWithSize|'s
    [=value-with-size/size=].
 1. If |container|.\[[queueTotalSize]] &lt; 0, set |container|.\[[queueTotalSize]] to 0. (This can
    occur due to rounding errors.)
 1. Return |valueWithSize|'s [=value-with-size/value=].
</div>

<div algorithm>
 <dfn abstract-op lt="EnqueueValueWithSize"
 id="enqueue-value-with-size">EnqueueValueWithSize(|container|, |value|, |size|)</dfn> performs the
 following steps:

 1. Assert: |container| has \[[queue]] and \[[queueTotalSize]] internal slots.
 1. If ! [$IsNonNegativeNumber$](|size|) is false, throw a {{RangeError}} exception.
 1. If |size| is +∞, throw a {{RangeError}} exception.
 1. [=list/Append=] a new [=value-with-size=] with [=value-with-size/value=] |value| and
    [=value-with-size/size=] |size| to |container|.\[[queue]].
 1. Set |container|.\[[queueTotalSize]] to |container|.\[[queueTotalSize]] + |size|.
</div>

<div algorithm>
 <dfn abstract-op lt="PeekQueueValue" id="peek-queue-value">PeekQueueValue(|container|)</dfn>
 performs the following steps:

 1. Assert: |container| has \[[queue]] and \[[queueTotalSize]] internal slots.
 1. Assert: |container|.\[[queue]] is not [=list/is empty|empty=].
 1. Let |valueWithSize| be |container|.\[[queue]][0].
 1. Return |valueWithSize|'s [=value-with-size/value=].
</div>

<div algorithm>
 <dfn abstract-op lt="ResetQueue" id="reset-queue">ResetQueue(|container|)</dfn>
 performs the following steps:

 1. Assert: |container| has \[[queue]] and \[[queueTotalSize]] internal slots.
 1. Set |container|.\[[queue]] to a new empty [=list=].
 1. Set |container|.\[[queueTotalSize]] to 0.
</div>

<h3 id="transferrable-streams">Transferable streams</h3>

Transferable streams are implemented using a special kind of identity transform which has the
[=writable side=] in one [=realm=] and the [=readable side=] in another realm. The following
abstract operations are used to implement these "cross-realm transforms".

<div algorithm>
 <dfn abstract-op lt="CrossRealmTransformSendError">CrossRealmTransformSendError(|port|,
 |error|)</dfn> performs the following steps:

 1. Perform [$PackAndPostMessage$](|port|, "`error`", |error|), discarding the result.

 <p class="note">As we are already in an errored state when this abstract operation is performed, we
 cannot handle further errors, so we just discard them.</p>
</div>

<div algorithm>
 <dfn abstract-op lt="PackAndPostMessage">PackAndPostMessage(|port|, |type|, |value|)</dfn> performs
 the following steps:

 1. Let |message| be [$OrdinaryObjectCreate$](null).
 1. Perform ! [$CreateDataProperty$](|message|, "`type`", |type|).
 1. Perform ! [$CreateDataProperty$](|message|, "`value`", |value|).
 1. Let |targetPort| be the port with which |port| is entangled, if any; otherwise let it be null.
 1. Let |options| be «[ "`transfer`" → « » ]».
 1. Run the [=message port post message steps=] providing |targetPort|, |message|, and |options|.

 <p class="note">A JavaScript object is used for transfer to avoid having to duplicate the [=message
 port post message steps=]. The prototype of the object is set to null to avoid interference from
 {{%Object.prototype%}}.</p>
</div>

<div algorithm>
 <dfn abstract-op lt="PackAndPostMessageHandlingError">PackAndPostMessageHandlingError(|port|,
 |type|, |value|)</dfn> performs the following steps:

 1. Let |result| be [$PackAndPostMessage$](|port|, |type|, |value|).
 1. If |result| is an abrupt completion,
  1. Perform ! [$CrossRealmTransformSendError$](|port|, |result|.\[[Value]]).
 1. Return |result| as a completion record.
</div>

<div algorithm>
 <dfn abstract-op lt="SetUpCrossRealmTransformReadable">SetUpCrossRealmTransformReadable(|stream|,
 |port|)</dfn> performs the following steps:

 1. Perform ! [$InitializeReadableStream$](|stream|).
 1. Let |controller| be a [=new=] {{ReadableStreamDefaultController}}.
 1. Add a handler for |port|'s {{MessagePort/message}} event with the following steps:
  1. Let |data| be the data of the message.
  1. Assert: [$Type$](|data|) is Object.
  1. Let |type| be ! [$Get$](|data|, "`type`").
  1. Let |value| be ! [$Get$](|data|, "`value`").
  1. Assert: [$Type$](|type|) is String.
  1. If |type| is "`chunk`",
   1. Perform ! [$ReadableStreamDefaultControllerEnqueue$](|controller|, |value|).
  1. Otherwise, if |type| is "`close`",
    1. Perform ! [$ReadableStreamDefaultControllerClose$](|controller|).
    1. Disentangle |port|.
  1. Otherwise, if |type| is "`error`",
   1. Perform ! [$ReadableStreamDefaultControllerError$](|controller|, |value|).
   1. Disentangle |port|.
 1. Add a handler for |port|'s {{MessagePort/messageerror}} event with the following steps:
  1. Let |error| be a new "{{DataCloneError}}" {{DOMException}}.
  1. Perform ! [$CrossRealmTransformSendError$](|port|, |error|).
  1. Perform ! [$ReadableStreamDefaultControllerError$](|controller|, |error|).
  1. Disentangle |port|.
 1. Enable |port|'s [=port message queue=].
 1. Let |startAlgorithm| be an algorithm that returns undefined.
 1. Let |pullAlgorithm| be the following steps:
  1. Perform ! [$PackAndPostMessage$](|port|, "`pull`", undefined).
  1. Return [=a promise resolved with=] undefined.
 1. Let |cancelAlgorithm| be the following steps, taking a |reason| argument:
  1. Let |result| be [$PackAndPostMessageHandlingError$](|port|, "`error`", |reason|).
  1. Disentangle |port|.
  1. If |result| is an abrupt completion, return [=a promise rejected with=] |result|.\[[Value]].
  1. Otherwise, return [=a promise resolved with=] undefined.
 1. Let |sizeAlgorithm| be an algorithm that returns 1.
 1. Perform ! [$SetUpReadableStreamDefaultController$](|stream|, |controller|, |startAlgorithm|,
    |pullAlgorithm|, |cancelAlgorithm|, 0, |sizeAlgorithm|).

 <p class="note">Implementations are encouraged to explicitly handle failures from the asserts in
 this algorithm, as the input might come from an untrusted context. Failure to do so could lead to
 security issues.</p>
</div>

<div algorithm>
 <dfn abstract-op lt="SetUpCrossRealmTransformWritable">SetUpCrossRealmTransformWritable(|stream|,
 |port|)</dfn> performs the following steps:

 1. Perform ! [$InitializeWritableStream$](|stream|).
 1. Let |controller| be a [=new=] {{WritableStreamDefaultController}}.
 1. Let |backpressurePromise| be [=a new promise=].
 1. Add a handler for |port|'s {{MessagePort/message}} event with the following steps:
  1. Let |data| be the data of the message.
  1. Assert: [$Type$](|data|) is Object.
  1. Let |type| be ! [$Get$](|data|, "`type`").
  1. Let |value| be ! [$Get$](|data|, "`value`").
  1. Assert: [$Type$](|type|) is String.
  1. If |type| is "`pull`",
   1. If |backpressurePromise| is not undefined,
    1. [=Resolve=] |backpressurePromise| with undefined.
    1. Set |backpressurePromise| to undefined.
  1. Otherwise, if |type| is "`error`",
   1. Perform ! [$WritableStreamDefaultControllerErrorIfNeeded$](|controller|, |value|).
   1. If |backpressurePromise| is not undefined,
    1. [=Resolve=] |backpressurePromise| with undefined.
    1. Set |backpressurePromise| to undefined.
 1. Add a handler for |port|'s {{MessagePort/messageerror}} event with the following steps:
  1. Let |error| be a new "{{DataCloneError}}" {{DOMException}}.
  1. Perform ! [$CrossRealmTransformSendError$](|port|, |error|).
  1. Perform ! [$WritableStreamDefaultControllerError$](|controller|, |error|).
  1. Disentangle |port|.
 1. Enable |port|'s [=port message queue=].
 1. Let |startAlgorithm| be an algorithm that returns undefined.
 1. Let |writeAlgorithm| be the following steps, taking a |chunk| argument:
  1. If |backpressurePromise| is undefined, set |backpressurePromise| to
     [=a promise resolved with=] undefined.
  1. Return the result of [=reacting=] to |backpressurePromise| with the following
     fulfillment steps:
   1. Set |backpressurePromise| to [=a new promise=].
   1. Let |result| be [$PackAndPostMessageHandlingError$](|port|, "`chunk`", |chunk|).
   1. If |result| is an abrupt completion,
    1. Disentangle |port|.
    1. Return [=a promise rejected with=] |result|.\[[Value]].
   1. Otherwise, return [=a promise resolved with=] undefined.
 1. Let |closeAlgorithm| be the folowing steps:
  1. Perform ! [$PackAndPostMessage$](|port|, "`close`", undefined).
  1. Disentangle |port|.
  1. Return [=a promise resolved with=] undefined.
 1. Let |abortAlgorithm| be the following steps, taking a |reason| argument:
  1. Let |result| be [$PackAndPostMessageHandlingError$](|port|, "`error`", |reason|).
  1. Disentangle |port|.
  1. If |result| is an abrupt completion, return [=a promise rejected with=] |result|.\[[Value]].
  1. Otherwise, return [=a promise resolved with=] undefined.
 1. Let |sizeAlgorithm| be an algorithm that returns 1.
 1. Perform ! [$SetUpWritableStreamDefaultController$](|stream|, |controller|, |startAlgorithm|,
    |writeAlgorithm|, |closeAlgorithm|, |abortAlgorithm|, 1, |sizeAlgorithm|).

 <p class="note">Implementations are encouraged to explicitly handle failures from the asserts in
 this algorithm, as the input might come from an untrusted context. Failure to do so could lead to
 security issues.</p>
</div>

<h3 id="misc-abstract-ops">Miscellaneous</h4>

The following abstract operations are a grab-bag of utilities.

<div algorithm>
 <dfn abstract-op lt="IsNonNegativeNumber"
 id="is-non-negative-number">IsNonNegativeNumber(|v|)</dfn> performs the following steps:

 1. If [$Type$](|v|) is not Number, return false.
 1. If |v| is NaN, return false.
 1. If |v| &lt; 0, return false.
 1. Return true.
</div>

<div algorithm>
 <dfn abstract-op lt="TransferArrayBuffer"
 id="transfer-array-buffer">TransferArrayBuffer(|O|)</dfn> performs the following steps:

 1. Assert: [$Type$](|O|) is Object.
 1. Assert: |O| has an \[[ArrayBufferData]] internal slot.
 1. Assert: ! [$IsDetachedBuffer$](|O|) is false.
 1. Let |arrayBufferData| be |O|.\[[ArrayBufferData]].
 1. Let |arrayBufferByteLength| be |O|.\[[ArrayBufferByteLength]].
 1. Perform ! [$DetachArrayBuffer$](|O|).
 1. Return a new {{ArrayBuffer}} object, created in [=the current Realm=], whose
    \[[ArrayBufferData]] internal slot value is |arrayBufferData| and whose
    \[[ArrayBufferByteLength]] internal slot value is |arrayBufferByteLength|.
</div>

<h2 id="creating-examples">Examples of creating streams</h2>

<div class="non-normative">

<em>This section, and all its subsections, are non-normative.</em>

The previous examples throughout the standard have focused on how to use streams. Here we show how
to create a stream, using the {{ReadableStream}}, {{WritableStream}}, and {{TransformStream}}
constructors.

<h3 id="example-rs-push-no-backpressure">A readable stream with an underlying push source (no
backpressure support)</h3>

The following function creates [=readable streams=] that wrap {{WebSocket}} instances [[HTML]],
which are [=push sources=] that do not support backpressure signals. It illustrates how, when
adapting a push source, usually most of the work happens in the {{UnderlyingSource/start|start()}}
method.

<xmp highlight="js">
function makeReadableWebSocketStream(url, protocols) {
  const ws = new WebSocket(url, protocols);
  ws.binaryType = "arraybuffer";

  return new ReadableStream({
    start(controller) {
      ws.onmessage = event => controller.enqueue(event.data);
      ws.onclose = () => controller.close();
      ws.onerror = () => controller.error(new Error("The WebSocket errored!"));
    },

    cancel() {
      ws.close();
    }
  });
}
</xmp>

We can then use this function to create readable streams for a web socket, and pipe that stream to
an arbitrary writable stream:

<xmp highlight="js">
const webSocketStream = makeReadableWebSocketStream("wss://example.com:443/", "protocol");

webSocketStream.pipeTo(writableStream)
  .then(() => console.log("All data successfully written!"))
  .catch(e => console.error("Something went wrong!", e));
</xmp>

<div class="note" id="note-web-socket-wrapping-examples">
 This specific style of wrapping a web socket interprets web socket messages directly as
 [=chunks=]. This can be a convenient abstraction, for example when [=piping=] to a [=writable
 stream=] or [=transform stream=] for which each web socket message makes sense as a chunk to
 consume or transform.

 However, often when people talk about "adding streams support to web sockets", they are hoping
 instead for a new capability to send an individual web socket message in a streaming fashion, so
 that e.g. a file could be transferred in a single message without holding all of its contents in
 memory on the client side. To accomplish this goal, we'd instead want to allow individual web
 socket messages to themselves be {{ReadableStream}} instances. That isn't what we show in the
 above example.

 For more background, see <a
 href="https://github.com/w3c/webrtc-pc/issues/1732#issuecomment-358428651">this discussion</a>.
</div>

<h3 id="example-rs-push-backpressure">A readable stream with an underlying push source and
backpressure support</h3>

The following function returns [=readable streams=] that wrap "backpressure sockets," which are
hypothetical objects that have the same API as web sockets, but also provide the ability to pause
and resume the flow of data with their <code>readStop</code> and <code>readStart</code> methods. In
doing so, this example shows how to apply [=backpressure=] to [=underlying sources=] that support
it.

<xmp highlight="js">
function makeReadableBackpressureSocketStream(host, port) {
  const socket = createBackpressureSocket(host, port);

  return new ReadableStream({
    start(controller) {
      socket.ondata = event => {
        controller.enqueue(event.data);

        if (controller.desiredSize <= 0) {
          // The internal queue is full, so propagate
          // the backpressure signal to the underlying source.
          socket.readStop();
        }
      };

      socket.onend = () => controller.close();
      socket.onerror = () => controller.error(new Error("The socket errored!"));
    },

    pull() {
      // This is called if the internal queue has been emptied, but the
      // stream's consumer still wants more data. In that case, restart
      // the flow of data if we have previously paused it.
      socket.readStart();
    },

    cancel() {
      socket.close();
    }
  });
}
</xmp>

We can then use this function to create readable streams for such "backpressure sockets" in the
same way we do for web sockets. This time, however, when we pipe to a destination that cannot
accept data as fast as the socket is producing it, or if we leave the stream alone without reading
from it for some time, a backpressure signal will be sent to the socket.

<h3 id="example-rbs-push">A readable byte stream with an underlying push source (no backpressure
support)</h3>

The following function returns [=readable byte streams=] that wraps a hypothetical UDP socket API,
including a promise-returning <code>select2()</code> method that is meant to be evocative of the
POSIX select(2) system call.

Since the UDP protocol does not have any built-in backpressure support, the backpressure signal
given by {{ReadableByteStreamController/desiredSize}} is ignored, and the stream ensures that when
data is available from the socket but not yet requested by the developer, it is enqueued in the
stream's [=internal queue=], to avoid overflow of the kernel-space queue and a consequent loss of
data.

This has some interesting consequences for how [=consumers=] interact with the stream. If the
consumer does not read data as fast as the socket produces it, the [=chunks=] will remain in the
stream's [=internal queue=] indefinitely. In this case, using a [=BYOB reader=] will cause an extra
copy, to move the data from the stream's internal queue to the developer-supplied buffer. However,
if the consumer consumes the data quickly enough, a [=BYOB reader=] will allow zero-copy reading
directly into developer-supplied buffers.

(You can imagine a more complex version of this example which uses
{{ReadableByteStreamController/desiredSize}} to inform an out-of-band backpressure signaling
mechanism, for example by sending a message down the socket to adjust the rate of data being sent.
That is left as an exercise for the reader.)

<xmp highlight="js">
const DEFAULT_CHUNK_SIZE = 65536;

function makeUDPSocketStream(host, port) {
  const socket = createUDPSocket(host, port);

  return new ReadableStream({
    type: "bytes",

    start(controller) {
      readRepeatedly().catch(e => controller.error(e));

      function readRepeatedly() {
        return socket.select2().then(() => {
          // Since the socket can become readable even when there’s
          // no pending BYOB requests, we need to handle both cases.
          let bytesRead;
          if (controller.byobRequest) {
            const v = controller.byobRequest.view;
            bytesRead = socket.readInto(v.buffer, v.byteOffset, v.byteLength);
            controller.byobRequest.respond(bytesRead);
          } else {
            const buffer = new ArrayBuffer(DEFAULT_CHUNK_SIZE);
            bytesRead = socket.readInto(buffer, 0, DEFAULT_CHUNK_SIZE);
            controller.enqueue(new Uint8Array(buffer, 0, bytesRead));
          }

          if (bytesRead === 0) {
            controller.close();
            return;
          }

          return readRepeatedly();
        });
      }
    },

    cancel() {
      socket.close();
    }
  });
}
</xmp>

{{ReadableStream}} instances returned from this function can now vend [=BYOB readers=], with all of
the aforementioned benefits and caveats.

<h3 id="example-rs-pull">A readable stream with an underlying pull source</h3>

The following function returns [=readable streams=] that wrap portions of the <a
href="https://nodejs.org/api/fs.html">Node.js file system API</a> (which themselves map fairly
directly to C's <code>fopen</code>, <code>fread</code>, and <code>fclose</code> trio). Files are a
typical example of [=pull sources=]. Note how in contrast to the examples with push sources, most
of the work here happens on-demand in the {{UnderlyingSource/pull|pull()}} function, and not at
startup time in the {{UnderlyingSource/start|start()}} function.

<xmp highlight="js">
const fs = require("fs").promises;
const CHUNK_SIZE = 1024;

function makeReadableFileStream(filename) {
  let fileHandle;
  let position = 0;

  return new ReadableStream({
    async start() {
      fileHandle = await fs.open(filename, "r");
    },

    async pull(controller) {
      const buffer = new ArrayBuffer(CHUNK_SIZE);

      const { bytesRead } = await fileHandle.read(buffer, 0, CHUNK_SIZE, position);
      if (bytesRead === 0) {
        await fileHandle.close();
        controller.close();
      } else {
        position += bytesRead;
        controller.enqueue(new Uint8Array(buffer, 0, bytesRead));
      }
    },

    cancel() {
      return fileHandle.close();
    }
  });
}
</xmp>

We can then create and use readable streams for files just as we could before for sockets.

<h3 id="example-rbs-pull">A readable byte stream with an underlying pull source</h3>

The following function returns [=readable byte streams=] that allow efficient zero-copy reading of
files, again using the <a href="https://nodejs.org/api/fs.html">Node.js file system API</a>.
Instead of using a predetermined chunk size of 1024, it attempts to fill the developer-supplied
buffer, allowing full control.

<xmp highlight="js">
const fs = require("fs").promises;
const DEFAULT_CHUNK_SIZE = 1024;

function makeReadableByteFileStream(filename) {
 let fileHandle;
 let position = 0;

  return new ReadableStream({
    type: "bytes",

    async start() {
      fileHandle = await fs.open(filename, "r");
    },

    pull(controller) {
      // Even when the consumer is using the default reader, the auto-allocation
      // feature allocates a buffer and passes it to us via byobRequest.
      const v = controller.byobRequest.view;

      const { bytesRead } = await fileHandle.read(v.buffer, v.byteOffset, v.byteLength);
      if (bytesRead === 0) {
        await fileHandle.close();
        controller.close();
      } else {
        position += bytesRead;
        controller.byobRequest.respond(bytesRead);
      }
    },

    cancel() {
      return fs.close(fd);
    },

    autoAllocateChunkSize: DEFAULT_CHUNK_SIZE
  });
}
</xmp>

With this in hand, we can create and use [=BYOB readers=] for the returned {{ReadableStream}}. But
we can also create [=default readers=], using them in the same simple and generic manner as usual.
The adaptation between the low-level byte tracking of the [=underlying byte source=] shown here,
and the higher-level chunk-based consumption of a [=default reader=], is all taken care of
automatically by the streams implementation. The auto-allocation feature, via the
{{UnderlyingSource/autoAllocateChunkSize}} option, even allows us to write less code, compared to
the manual branching in [[#example-rbs-push]].

<h3 id="example-ws-no-backpressure">A writable stream with no backpressure or success signals</h3>

The following function returns a [=writable stream=] that wraps a {{WebSocket}} [[HTML]]. Web
sockets do not provide any way to tell when a given chunk of data has been successfully sent
(without awkward polling of {{WebSocket/bufferedAmount}}, which we leave as an exercise to the
reader). As such, this writable stream has no ability to communicate accurate [=backpressure=]
signals or write success/failure to its [=producers=]. That is, the promises returned by its
[=writer=]'s {{WritableStreamDefaultWriter/write()}} method and
{{WritableStreamDefaultWriter/ready}} getter will always fulfill immediately.

<xmp highlight="js">
function makeWritableWebSocketStream(url, protocols) {
  const ws = new WebSocket(url, protocols);

  return new WritableStream({
    start(controller) {
      ws.onerror = () => {
        controller.error(new Error("The WebSocket errored!"));
        ws.onclose = null;
      };
      ws.onclose = () => controller.error(new Error("The server closed the connection unexpectedly!"));
      return new Promise(resolve => ws.onopen = resolve);
    },

    write(chunk) {
      ws.send(chunk);
      // Return immediately, since the web socket gives us no easy way to tell
      // when the write completes.
    },

    close() {
      return closeWS(1000);
    },

    abort(reason) {
      return closeWS(4000, reason && reason.message);
    },
  });

  function closeWS(code, reasonString) {
    return new Promise((resolve, reject) => {
      ws.onclose = e => {
        if (e.wasClean) {
          resolve();
        } else {
          reject(new Error("The connection was not closed cleanly"));
        }
      };
      ws.close(code, reasonString);
    });
  }
}
</xmp>

We can then use this function to create writable streams for a web socket, and pipe an arbitrary
readable stream to it:

<xmp highlight="js">
const webSocketStream = makeWritableWebSocketStream("wss://example.com:443/", "protocol");

readableStream.pipeTo(webSocketStream)
  .then(() => console.log("All data successfully written!"))
  .catch(e => console.error("Something went wrong!", e));
</xmp>

<p class="note">See <a href="#note-web-socket-wrapping-examples">the earlier note</a> about this
style of wrapping web sockets into streams.

<h3 id="example-ws-backpressure">A writable stream with backpressure and success signals</h3>

The following function returns [=writable streams=] that wrap portions of the <a
href="https://nodejs.org/api/fs.html">Node.js file system API</a> (which themselves map fairly
directly to C's <code>fopen</code>, <code>fwrite</code>, and <code>fclose</code> trio). Since the
API we are wrapping provides a way to tell when a given write succeeds, this stream will be able to
communicate [=backpressure=] signals as well as whether an individual write succeeded or failed.

<xmp highlight="js">
const fs = require("fs").promises;

function makeWritableFileStream(filename) {
  let fileHandle;

  return new WritableStream({
    async start() {
      fileHandle = await fs.open(filename, "w");
    },

    write(chunk) {
      return fileHandle.write(chunk, 0, chunk.length);
    },

    close() {
      return fs.close(fd);
    },

    abort() {
      return fs.close(fd);
    }
  });
}
</xmp>

We can then use this function to create a writable stream for a file, and write individual
[=chunks=] of data to it:

<xmp highlight="js">
const fileStream = makeWritableFileStream("/example/path/on/fs.txt");
const writer = fileStream.getWriter();

writer.write("To stream, or not to stream\n");
writer.write("That is the question\n");

writer.close()
  .then(() => console.log("chunks written and stream closed successfully!"))
  .catch(e => console.error(e));
</xmp>

Note that if a particular call to <code>fileHandle.write</code> takes a longer time, the returned
promise will fulfill later. In the meantime, additional writes can be queued up, which are stored
in the stream's internal queue. The accumulation of chunks in this queue can change the stream to
return a pending promise from the {{WritableStreamDefaultWriter/ready}} getter, which is a signal
to [=producers=] that they would benefit from backing off and stopping writing, if possible.

The way in which the writable stream queues up writes is especially important in this case, since
as stated in <a
href="https://nodejs.org/api/fs.html#fs_filehandle_write_buffer_offset_length_position">the
documentation for <code>fileHandle.write</code></a>, "it is unsafe to use
<code>filehandle.write</code> multiple times on the same file without waiting for the promise." But
we don't have to worry about that when writing the <code>makeWritableFileStream</code> function,
since the stream implementation guarantees that the [=underlying sink=]'s
{{UnderlyingSink/write|write()}} method will not be called until any promises returned by previous
calls have fulfilled!

<h3 id="example-both">A { readable, writable } stream pair wrapping the same underlying
resource</h3>

The following function returns an object of the form <code>{ readable, writable }</code>, with the
<code>readable</code> property containing a readable stream and the <code>writable</code> property
containing a writable stream, where both streams wrap the same underlying web socket resource. In
essence, this combines [[#example-rs-push-no-backpressure]] and [[#example-ws-no-backpressure]].

While doing so, it illustrates how you can use JavaScript classes to create reusable underlying
sink and underlying source abstractions.

<xmp highlight="js">
function streamifyWebSocket(url, protocol) {
  const ws = new WebSocket(url, protocols);
  ws.binaryType = "arraybuffer";

  return {
    readable: new ReadableStream(new WebSocketSource(ws)),
    writable: new WritableStream(new WebSocketSink(ws))
  };
}

class WebSocketSource {
  constructor(ws) {
    this._ws = ws;
  }

  start(controller) {
    this._ws.onmessage = event => controller.enqueue(event.data);
    this._ws.onclose = () => controller.close();

    this._ws.addEventListener("error", () => {
      controller.error(new Error("The WebSocket errored!"));
    });
  }

  cancel() {
    this._ws.close();
  }
}

class WebSocketSink {
  constructor(ws) {
    this._ws = ws;
  }

  start(controller) {
    this._ws.onclose = () => controller.error(new Error("The server closed the connection unexpectedly!"));
    this._ws.addEventListener("error", () => {
      controller.error(new Error("The WebSocket errored!"));
      this._ws.onclose = null;
    });

    return new Promise(resolve => this._ws.onopen = resolve);
  }

  write(chunk) {
    this._ws.send(chunk);
  }

  close() {
    return this._closeWS(1000);
  }

  abort(reason) {
    return this._closeWS(4000, reason && reason.message);
  }

  _closeWS(code, reasonString) {
    return new Promise((resolve, reject) => {
      this._ws.onclose = e => {
        if (e.wasClean) {
          resolve();
        } else {
          reject(new Error("The connection was not closed cleanly"));
        }
      };
      this._ws.close(code, reasonString);
    });
  }
}
</xmp>

We can then use the objects created by this function to communicate with a remote web socket, using
the standard stream APIs:

<xmp highlight="js">
const streamyWS = streamifyWebSocket("wss://example.com:443/", "protocol");
const writer = streamyWS.writable.getWriter();
const reader = streamyWS.readable.getReader();

writer.write("Hello");
writer.write("web socket!");

reader.read().then(({ value, done }) => {
  console.log("The web socket says: ", value);
});
</xmp>

Note how in this setup canceling the <code>readable</code> side will implicitly close the
<code>writable</code> side, and similarly, closing or aborting the <code>writable</code> side will
implicitly close the <code>readable</code> side.

<p class="note">See <a href="#note-web-socket-wrapping-examples">the earlier note</a> about this
style of wrapping web sockets into streams.

</div>

<h3 id="example-ts-lipfuzz">A transform stream that replaces template tags</h3>

It's often useful to substitute tags with variables on a stream of data, where the parts that need
to be replaced are small compared to the overall data size. This example presents a simple way to
do that. It maps strings to strings, transforming a template like <code>"Time: \{{time}} Message:
\{{message}}"</code> to <code>"Time: 15:36 Message: hello"</code> assuming that <code>{ time:
"15:36", message: "hello" }</code> was passed in the <code>substitutions</code> parameter to
<code>LipFuzzTransformer</code>.

This example also demonstrates one way to deal with a situation where a chunk contains partial data
that cannot be transformed until more data is received. In this case, a partial template tag will
be accumulated in the <code>partialChunk</code> property until either the end of the tag is found or
the end of the stream is reached.

<xmp highlight="js">
class LipFuzzTransformer {
  constructor(substitutions) {
    this.substitutions = substitutions;
    this.partialChunk = "";
    this.lastIndex = undefined;
  }

  transform(chunk, controller) {
    chunk = this.partialChunk + chunk;
    this.partialChunk = "";
    // lastIndex is the index of the first character after the last substitution.
    this.lastIndex = 0;
    chunk = chunk.replace(/\{\{([a-zA-Z0-9_-]+)\}\}/g, this.replaceTag.bind(this));
    // Regular expression for an incomplete template at the end of a string.
    const partialAtEndRegexp = /\{(\{([a-zA-Z0-9_-]+(\})?)?)?$/g;
    // Avoid looking at any characters that have already been substituted.
    partialAtEndRegexp.lastIndex = this.lastIndex;
    this.lastIndex = undefined;
    const match = partialAtEndRegexp.exec(chunk);
    if (match) {
      this.partialChunk = chunk.substring(match.index);
      chunk = chunk.substring(0, match.index);
    }
    controller.enqueue(chunk);
  }

  flush(controller) {
    if (this.partialChunk.length > 0) {
      controller.enqueue(this.partialChunk);
    }
  }

  replaceTag(match, p1, offset) {
    let replacement = this.substitutions[p1];
    if (replacement === undefined) {
      replacement = "";
    }
    this.lastIndex = offset + replacement.length;
    return replacement;
  }
}
</xmp>

In this case we define the [=transformer=] to be passed to the {{TransformStream}} constructor as a
class. This is useful when there is instance data to track.

The class would be used in code like:

<xmp highlight="js">
const data = { userName, displayName, icon, date };
const ts = new TransformStream(new LipFuzzTransformer(data));

fetchEvent.respondWith(
  fetch(fetchEvent.request.url).then(response => {
    const transformedBody = response.body
      // Decode the binary-encoded response to string
      .pipeThrough(new TextDecoderStream())
      // Apply the LipFuzzTransformer
      .pipeThrough(ts)
      // Encode the transformed string
      .pipeThrough(new TextEncoderStream());
    return new Response(transformedBody);
  })
);
</xmp>

<p class="warning">For simplicity, <code>LipFuzzTransformer</code> performs unescaped text
substitutions. In real applications, a template system that performs context-aware escaping is good
practice for security and robustness.

<h3 id="example-ts-sync-mapper">A transform stream created from a sync mapper function</h3>

The following function allows creating new {{TransformStream}} instances from synchronous "mapper"
functions, of the type you would normally pass to {{Array.prototype/map|Array.prototype.map}}. It
demonstrates that the API is concise even for trivial transforms.

<xmp highlight="js">
function mapperTransformStream(mapperFunction) {
  return new TransformStream({
    transform(chunk, controller) {
      controller.enqueue(mapperFunction(chunk));
    }
  });
}
</xmp>

This function can then be used to create a {{TransformStream}} that uppercases all its inputs:

<xmp highlight="js">
const ts = mapperTransformStream(chunk => chunk.toUpperCase());
const writer = ts.writable.getWriter();
const reader = ts.readable.getReader();

writer.write("No need to shout");

// Logs "NO NEED TO SHOUT":
reader.read().then(({ value }) => console.log(value));
</xmp>

Although a synchronous transform never causes backpressure itself, it will only transform chunks as
long as there is no backpressure, so resources will not be wasted.

Exceptions error the stream in a natural way:

<xmp highlight="js">
const ts = mapperTransformStream(chunk => JSON.parse(chunk));
const writer = ts.writable.getWriter();
const reader = ts.readable.getReader();

writer.write("[1, ");

// Logs a SyntaxError, twice:
reader.read().catch(e => console.error(e));
writer.write("{}").catch(e => console.error(e));
</xmp>

<h2 id="acks" class="no-num">Acknowledgments</h2>

The editors would like to thank
Anne van Kesteren,
AnthumChris,
Arthur Langereis,
Ben Kelly,
Bert Belder,
Brian di Palma,
Calvin Metcalf,
Dominic Tarr,
Ed Hager,
Forbes Lindesay,
Forrest Norvell,
Gary Blackwood,
Gorgi Kosev,
Gus Caplan,
贺师俊 (hax),
Isaac Schlueter,
isonmad,
Jake Archibald,
Jake Verbaten,
Janessa Det,
Jason Orendorff,
Jens Nockert,
Lennart Grahl,
Mangala Sadhu Sangeet Singh Khalsa,
Marcos Caceres,
Marvin Hagemeister,
Mattias Buelens,
Michael Mior,
Mihai Potra,
Romain Bellessort, <!-- rombel on GitHub -->
Simon Menke,
Stephen Sugden,
Surma,
Tab Atkins,
Tanguy Krotoff,
Thorsten Lorenz,
Till Schneidereit,
Tim Caswell,
Trevor Norris,
tzik,
Will Chan,
Youenn Fablet,
平野裕 (Yutaka Hirano),
and
Xabier Rodríguez
for their contributions to this specification. Community involvement in this specification has been
above and beyond; we couldn't have done it without you.

This standard is written by Adam Rice (<a href="https://google.com">Google</a>, <a
href="mailto:ricea@chromium.org">ricea@chromium.org</a>), <a href="https://domenic.me/">Domenic
Denicola</a> (<a href="https://google.com">Google</a>, <a
href="mailto:d@domenic.me">d@domenic.me</a>), and 吉野剛史 (Takeshi Yoshino, <a
href="https://google.com">Google</a>, <a
href="mailto:tyoshino@chromium.org">tyoshino@chromium.org</a>).
